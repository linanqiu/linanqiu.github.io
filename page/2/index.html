<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Page 2 | Pandamonium | Musings of a Panda</title>
  <meta name="author" content="Linan Qiu">
  
  <meta name="description" content="Linan&#39;s Blog">
  
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:site_name" content="Pandamonium"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Pandamonium" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div id="page" class="site">
  <div id="primary" class="content-area">

    <header id="header" class="inner"><div class="site-branding">
  <h1 class="site-title">
    <a href="/">Pandamonium</a>
  </h1>
  <p class="site-description">Musings of a Panda</p>
</div>
<nav id="site-navigation" class="main-navigation" role="navigation">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
</nav></header>

    <article id="content" class="site-content">
      <main id="main" class="site-main posts-loop" role="main">
        
  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/10/07/word2vec-sentiment/"><span>Sentiment Analysis Using Doc2Vec</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/07/word2vec-sentiment/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-07T18:51:24.000Z">
          2015-10-07
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h1 id="Sentiment-Analysis-using-Doc2Vec"><a href="#Sentiment-Analysis-using-Doc2Vec" class="headerlink" title="Sentiment Analysis using Doc2Vec"></a>Sentiment Analysis using Doc2Vec</h1><p>Word2Vec is dope. In short, it takes in a corpus, and churns out vectors for each of those words. What’s so special about these vectors you ask? Well, similar words are near each other. Furthermore, these vectors represent how we use the words. For example, <code>v_man - v_woman</code> is approximately equal to <code>v_king - v_queen</code>, illustrating the relationship that “man is to woman as king is to queen”. This process, in NLP voodoo, is called <strong>word embedding</strong>. These representations have been applied widely. This is made even more awesome with the introduction of Doc2Vec that represents not only words, but entire sentences and documents. Imagine being able to represent an entire sentence using a fixed-length vector and proceeding to run all your standard classification algorithms. Isn’t that amazing?</p>
<p>However, Word2Vec documentation is shit. The C-code is nigh unreadable (700 lines of highly optimized, and sometimes weirdly optimized code). I personally spent a lot of time untangling Doc2Vec and crashing into ~50% accuracies due to implementation mistakes. This tutorial aims to help other users get off the ground using Word2Vec for their own research. We use Word2Vec for <strong>sentiment analysis</strong> by attempting to classify the Cornell IMDB movie review corpus (<a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/" target="_blank" rel="external">http://www.cs.cornell.edu/people/pabo/movie-review-data/</a>).</p>
<p>The source code used in this demo can be found at <a href="https://github.com/linanqiu/word2vec-sentiments" target="_blank" rel="external">https://github.com/linanqiu/word2vec-sentiments</a></p>
<h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><h3 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h3><p>We use <code>gensim</code>, since <code>gensim</code> has a much more readable implementation of Word2Vec (and Doc2Vec). Bless those guys. We also use <code>numpy</code> for general array manipulation, and <code>sklearn</code> for Logistic Regression classifier.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gensim modules</span></span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> LabeledSentence</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Doc2Vec</span><br><span class="line"></span><br><span class="line"><span class="comment"># numpy</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"><span class="comment"># random</span></span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle</span><br><span class="line"></span><br><span class="line"><span class="comment"># classifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br></pre></td></tr></table></figure>
<h3 id="Input-Format"><a href="#Input-Format" class="headerlink" title="Input Format"></a>Input Format</h3><p>We can’t input the raw reviews from the Cornell movie review data repository. Instead, we clean them up by converting everything to lower case and removing punctuation. I did this via bash, and you can do this easily via Python, JS, or your favorite poison. This step is trivial.</p>
<p>The result is to have five documents:</p>
<ul>
<li><code>test-neg.txt</code>: 12500 negative movie reviews from the test data</li>
<li><code>test-pos.txt</code>: 12500 positive movie reviews from the test data</li>
<li><code>train-neg.txt</code>: 12500 negative movie reviews from the training data</li>
<li><code>train-pos.txt</code>: 12500 positive movie reviews from the training data</li>
<li><code>train-unsup.txt</code>: 50000 Unlabelled movie reviews</li>
</ul>
<p>Each of the reviews should be formatted as such:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">once again mr costner has dragged out a movie for far longer than necessary aside from the terrific sea rescue sequences of which there are very few i just did not care about any of the characters most of us have ghosts in the closet and costner s character are realized early on and then forgotten until much later by which time i did not care the character we should really care about is a very cocky overconfident ashton kutcher the problem is he comes off as kid who thinks he s better than anyone else around him and shows no signs of a cluttered closet his only obstacle appears to be winning over costner finally when we are well past the half way point of this stinker costner tells us all about kutcher s ghosts we are told why kutcher is driven to be the best with no prior inkling or foreshadowing no magic here it was all i could do to keep from turning it off an hour in</span><br><span class="line">this is an example of why the majority of action films are the same generic and boring there s really nothing worth watching here a complete waste of the then barely tapped talents of ice t and ice cube who ve each proven many times over that they are capable of acting and acting well don t bother with this one go see new jack city ricochet or watch new york undercover for ice t or boyz n the hood higher learning or friday for ice cube and see the real deal ice t s horribly cliched dialogue alone makes this film grate at the teeth and i m still wondering what the heck bill paxton was doing in this film and why the heck does he always play the exact same character from aliens onward every film i ve seen with bill paxton has him playing the exact same irritating character and at least in aliens his character died which made it somewhat gratifying overall this is second rate action trash there are countless better films to see and if you really want to see this one watch judgement night which is practically a carbon copy but has better acting and a better script the only thing that made this at all worth watching was a decent hand on the camera the cinematography was almost refreshing which comes close to making up for the horrible film itself but not quite</span><br></pre></td></tr></table></figure>
<p>The sample up there contains two movie reviews, each one taking up one entire line. Yes, <strong>each document should be on one line, separated by new lines</strong>. This is extremely important, because our parser depends on this to identify sentences.</p>
<h3 id="Feeding-Data-to-Doc2Vec"><a href="#Feeding-Data-to-Doc2Vec" class="headerlink" title="Feeding Data to Doc2Vec"></a>Feeding Data to Doc2Vec</h3><p>Doc2Vec (the portion of <code>gensim</code> that implements the Doc2Vec algorithm) does a great job at word embedding, but a terrible job at reading in files. It only takes in <code>LabeledLineSentence</code> classes which basically yields <code>LabeledSentence</code>, a class from <code>gensim.models.doc2vec</code> representing a single sentence. Why the “Labeled” word? Well, here’s how Doc2Vec differs from Word2Vec.</p>
<p>Word2Vec simply converts a word into a vector.</p>
<p>Doc2Vec not only does that, but also aggregates all the words in a sentence into a vector. To do that, it simply treats a sentence label as a special word, and does some voodoo on that special word. Hence, that special word is a label for a sentence. </p>
<p>So we have to format sentences into</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="string">'word1'</span>, <span class="string">'word2'</span>, <span class="string">'word3'</span>, <span class="string">'lastword'</span>], [<span class="string">'label1'</span>]]</span><br></pre></td></tr></table></figure>
<p><code>LabeledSentence</code> is simply a tidier way to do that. It contains a list of words, and a label for the sentence. We don’t really need to care about how <code>LabeledSentence</code> works exactly, we just have to know that it stores those two things – a list of words and a label.</p>
<p>However, we need a way to convert our new line separated corpus into a collection of <code>LabeledSentence</code>s. The default constructor for the default <code>LabeledLineSentence</code> class in Doc2Vec can do that for a single text file, but can’t do that for multiple files. In classification tasks however, we usually deal with multiple documents (test, training, positive, negative etc). Ain’t that annoying?</p>
<p>So we write our own <code>LabeledLineSentence</code> class. The constructor takes in a dictionary that defines the files to read and the label prefixes sentences from that document should take on. Then, Doc2Vec can either read the collection directly via the iterator, or we can access the array directly. We also need a function to return a permutated version of the array of <code>LabeledSentence</code>s. We’ll see why later on.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabeledLineSentence</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sources)</span>:</span></span><br><span class="line">        self.sources = sources</span><br><span class="line">        </span><br><span class="line">        flipped = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># make sure that keys are unique</span></span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> sources.items():</span><br><span class="line">            <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> flipped:</span><br><span class="line">                flipped[value] = [key]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">'Non-unique prefix encountered'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> source, prefix <span class="keyword">in</span> self.sources.items():</span><br><span class="line">            <span class="keyword">with</span> utils.smart_open(source) <span class="keyword">as</span> fin:</span><br><span class="line">                <span class="keyword">for</span> item_no, line <span class="keyword">in</span> enumerate(fin):</span><br><span class="line">                    <span class="keyword">yield</span> LabeledSentence(utils.to_unicode(line).split(), [prefix + <span class="string">'_%s'</span> % item_no])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_array</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.sentences = []</span><br><span class="line">        <span class="keyword">for</span> source, prefix <span class="keyword">in</span> self.sources.items():</span><br><span class="line">            <span class="keyword">with</span> utils.smart_open(source) <span class="keyword">as</span> fin:</span><br><span class="line">                <span class="keyword">for</span> item_no, line <span class="keyword">in</span> enumerate(fin):</span><br><span class="line">                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + <span class="string">'_%s'</span> % item_no]))</span><br><span class="line">        <span class="keyword">return</span> self.sentences</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sentences_perm</span><span class="params">(self)</span>:</span></span><br><span class="line">        shuffle(self.sentences)</span><br><span class="line">        <span class="keyword">return</span> self.sentences</span><br></pre></td></tr></table></figure>
<p>Now we can feed the data files to <code>LabeledLineSentence</code>. As we mentioned earlier, <code>LabeledLineSentence</code> simply takes a dictionary with keys as the file names and values the special prefixes for sentences from that document. The prefixes need to be unique, so that there is no ambiguitiy for sentences from different documents.</p>
<p>The prefixes will have a counter appended to them to label individual sentences in the documetns.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sources = &#123;<span class="string">'test-neg.txt'</span>:<span class="string">'TEST_NEG'</span>, <span class="string">'test-pos.txt'</span>:<span class="string">'TEST_POS'</span>, <span class="string">'train-neg.txt'</span>:<span class="string">'TRAIN_NEG'</span>, <span class="string">'train-pos.txt'</span>:<span class="string">'TRAIN_POS'</span>, <span class="string">'train-unsup.txt'</span>:<span class="string">'TRAIN_UNS'</span>&#125;</span><br><span class="line"></span><br><span class="line">sentences = LabeledLineSentence(sources)</span><br></pre></td></tr></table></figure>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Building-the-Vocabulary-Table"><a href="#Building-the-Vocabulary-Table" class="headerlink" title="Building the Vocabulary Table"></a>Building the Vocabulary Table</h3><p>Doc2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them). So we feed it the array of sentences. <code>model.build_vocab</code> takes an array of <code>LabeledLineSentence</code>, hence our <code>to_array</code> function in the <code>LabeledLineSentences</code> class. </p>
<p>If you’re curious about the parameters, do read the Word2Vec documentation. Otherwise, here’s a quick rundown:</p>
<ul>
<li><code>min_count</code>: ignore all words with total frequency lower than this. You have to set this to 1, since the sentence labels only appear once. Setting it any higher than 1 will miss out on the sentences.</li>
<li><code>window</code>: the maximum distance between the current and predicted word within a sentence. Word2Vec uses a skip-gram model, and this is simply the window size of the skip-gram model.</li>
<li><code>size</code>: dimensionality of the feature vectors in output. 100 is a good number. If you’re extreme, you can go up to around 400.</li>
<li><code>sample</code>: threshold for configuring which higher-frequency words are randomly downsampled</li>
<li><code>workers</code>: use this many worker threads to train the model </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Doc2Vec(min_count=<span class="number">1</span>, window=<span class="number">10</span>, size=<span class="number">100</span>, sample=<span class="number">1e-4</span>, negative=<span class="number">5</span>, workers=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">model.build_vocab(sentences.to_array())</span><br></pre></td></tr></table></figure>
<h3 id="Training-Doc2Vec"><a href="#Training-Doc2Vec" class="headerlink" title="Training Doc2Vec"></a>Training Doc2Vec</h3><p>Now we train the model. The model is better trained if <strong>in each training epoch, the sequence of sentences fed to the model is randomized</strong>. This is important: missing out on this steps gives you really shitty results. This is the reason for the <code>sentences_perm</code> method in our <code>LabeledLineSentences</code> class.</p>
<p>We train it for 10 epochs. If I had more time, I’d have done 20.</p>
<p>This process takes around 10 mins, so go grab some coffee.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    model.train(sentences.sentences_perm())</span><br></pre></td></tr></table></figure>
<h3 id="Saving-and-Loading-Models"><a href="#Saving-and-Loading-Models" class="headerlink" title="Saving and Loading Models"></a>Saving and Loading Models</h3><p>To avoid training the model again, we can save it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'./imdb.d2v'</span>)</span><br></pre></td></tr></table></figure>
<p>And load it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = Doc2Vec.load(<span class="string">'./imdb.d2v'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Inspecting-the-Model"><a href="#Inspecting-the-Model" class="headerlink" title="Inspecting the Model"></a>Inspecting the Model</h3><p>Let’s see what our model gives. It seems that it has kind of understood the word <code>good</code>, since the most similar words to good are <code>glamorous</code>, <code>spectacular</code>, <code>astounding</code> etc. This is really awesome (and important), since we are doing sentiment analysis.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'good'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;excellent&apos;, 0.49283793568611145),
 (u&apos;rudolfs&apos;, 0.43693652749061584),
 (u&apos;chattanooga&apos;, 0.4162406325340271),
 (u&apos;dodgy&apos;, 0.4156044125556946),
 (u&apos;hurts&apos;, 0.4120287299156189),
 (u&apos;maytime&apos;, 0.4106871485710144),
 (u&apos;problematic&apos;, 0.4097048342227936),
 (u&apos;lousy&apos;, 0.40627604722976685),
 (u&apos;humanization&apos;, 0.40399202704429626),
 (u&apos;detaches&apos;, 0.40335381031036377)]
</code></pre><p>We can also prop the hood open and see what the model actually contains. This is each of the vectors of the words and sentences in the model. We can access all of them using <code>model.syn0</code> (for the geekier ones among you, <code>syn0</code> is simply the output layer of the shallow neural network). However, we don’t want to use the entire <code>syn0</code> since that contains the vectors for the words as well, but we are only interested in the ones for sentences.</p>
<p>Here’s a sample vector for the first sentence in the training set for negative reviews:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model[<span class="string">'TRAIN_NEG_0'</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([-0.29009071, -0.12225933,  0.31921104,  0.12690307, -0.78038144,
        0.22722125,  0.20833154,  0.43868524,  0.23561548, -0.36413202,
       -0.15643257,  0.00461203,  0.08018852, -0.08258788, -0.2760058 ,
        0.10478264, -0.08799575, -0.37180164, -0.33013585,  0.18241297,
        0.88061708,  0.31900761,  0.23834513, -0.10049706,  0.28829831,
       -0.10783304,  0.0262799 ,  0.14395693, -0.10469725, -0.52104455,
       -0.65519089,  0.55344343,  0.01129826,  0.04632513, -0.15539262,
       -0.28914869,  0.33816752, -0.62154663, -0.02470196,  0.62869382,
        0.11478873, -0.25910828, -0.08567604, -0.02737088, -0.07904764,
       -1.01183033, -0.17131189,  0.04178049, -0.25471294, -0.42550623,
       -0.58592063, -0.31924966,  0.17547569,  0.20776786, -0.34506091,
        0.00154094,  0.30706513,  0.09242618,  0.02120452, -0.09602273,
       -0.40714192,  0.47554722,  0.36416441,  0.01952979,  0.6814065 ,
       -0.15965664, -0.22644502, -0.24989423,  0.40612498,  0.27820811,
       -0.35662967,  0.27260619,  0.07444458, -0.40855888,  0.09954116,
        0.11635212, -0.13925125,  0.18950833,  0.10479139, -0.17033359,
        0.06540342, -0.01675605,  0.00690889, -0.06219884,  0.13443422,
        0.05676769, -0.19048406, -0.08656956,  0.16460682, -0.18292029,
        0.42254189,  0.23022693, -0.10003133, -0.52825296,  0.18979053,
       -0.10800292,  0.01646511, -0.00504603,  0.173182  ,  0.19618541], dtype=float32)
</code></pre><h2 id="Classifying-Sentiments"><a href="#Classifying-Sentiments" class="headerlink" title="Classifying Sentiments"></a>Classifying Sentiments</h2><h3 id="Training-Vectors"><a href="#Training-Vectors" class="headerlink" title="Training Vectors"></a>Training Vectors</h3><p>Now let’s use these vectors to train a classifier. First, we must extract the training vectors. Remember that we have a total of 25000 training reviews, with equal numbers of positive and negative ones (12500 positive, 12500 negative).</p>
<p>Hence, we create a <code>numpy</code> array (since the classifier we use only takes numpy arrays. There are two parallel arrays, one containing the vectors (<code>train_arrays</code>) and the other containing the labels (<code>train_labels</code>).</p>
<p>We simply put the positive ones at the first half of the array, and the negative ones at the second half.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_arrays = numpy.zeros((<span class="number">25000</span>, <span class="number">100</span>))</span><br><span class="line">train_labels = numpy.zeros(<span class="number">25000</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12500</span>):</span><br><span class="line">    prefix_train_pos = <span class="string">'TRAIN_POS_'</span> + str(i)</span><br><span class="line">    prefix_train_neg = <span class="string">'TRAIN_NEG_'</span> + str(i)</span><br><span class="line">    train_arrays[i] = model[prefix_train_pos]</span><br><span class="line">    train_arrays[<span class="number">12500</span> + i] = model[prefix_train_neg]</span><br><span class="line">    train_labels[i] = <span class="number">1</span></span><br><span class="line">    train_labels[<span class="number">12500</span> + i] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>The training array looks like this: rows and rows of vectors representing each sentence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> train_arrays</span><br></pre></td></tr></table></figure>
<pre><code>[[ 0.18376358  0.14441976  0.09568384 ..., -0.28158343  0.29901281
   0.30613518]
 [-0.24681839  0.71076155 -0.40998992 ...,  0.39490703 -0.0812839
   0.21507834]
 [-0.05608005  0.48018554  0.35442445 ...,  0.28135905 -0.3482835
   0.23772541]
 ..., 
 [-0.23058473  0.03048714  0.8894285  ..., -0.5808149   0.18430299
  -0.08481987]
 [ 0.33824882  0.32103017 -0.24168059 ..., -0.55988938  0.61781228
  -0.4085339 ]
 [ 0.3712599  -0.18826039  0.30162022 ..., -0.21118143  0.00217488
  -0.4914557 ]]
</code></pre><p>The labels are simply category labels for the sentence vectors – 1 representing positive and 0 for negative.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> train_labels</span><br></pre></td></tr></table></figure>
<pre><code>[ 1.  1.  1. ...,  0.  0.  0.]
</code></pre><h3 id="Testing-Vectors"><a href="#Testing-Vectors" class="headerlink" title="Testing Vectors"></a>Testing Vectors</h3><p>We do the same for testing data – data that we are going to feed to the classifier after we’ve trained it using the training data. This allows us to evaluate our results. The process is pretty much the same as extracting the results for the training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">test_arrays = numpy.zeros((<span class="number">25000</span>, <span class="number">100</span>))</span><br><span class="line">test_labels = numpy.zeros(<span class="number">25000</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12500</span>):</span><br><span class="line">    prefix_test_pos = <span class="string">'TEST_POS_'</span> + str(i)</span><br><span class="line">    prefix_test_neg = <span class="string">'TEST_NEG_'</span> + str(i)</span><br><span class="line">    test_arrays[i] = model[prefix_test_pos]</span><br><span class="line">    test_arrays[<span class="number">12500</span> + i] = model[prefix_test_neg]</span><br><span class="line">    test_labels[i] = <span class="number">1</span></span><br><span class="line">    test_labels[<span class="number">12500</span> + i] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><p>Now we train a logistic regression classifier using the training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = LogisticRegression()</span><br><span class="line">classifier.fit(train_arrays, train_labels)</span><br></pre></td></tr></table></figure>
<pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, penalty=&apos;l2&apos;, random_state=None, tol=0.0001)
</code></pre><p>And find that we have achieved near 87% accuracy for sentiment analysis. This is rather incredible, given that we are only using a linear SVM and a very shallow neural network.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifier.score(test_arrays, test_labels)</span><br></pre></td></tr></table></figure>
<pre><code>0.87312000000000001
</code></pre><p>Isn’t this fantastic? Hope I saved you some time!</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li>Doc2vec: <a href="https://radimrehurek.com/gensim/models/doc2vec.html" target="_blank" rel="external">https://radimrehurek.com/gensim/models/doc2vec.html</a></li>
<li>Paper that inspired this: <a href="http://arxiv.org/abs/1405.4053" target="_blank" rel="external">http://arxiv.org/abs/1405.4053</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/08/21/Using-CircleCI-to-Grade-Java-Assignments/"><span>Using CircleCI to Grade Java Assignments</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/08/21/Using-CircleCI-to-Grade-Java-Assignments/" rel="bookmark">
        <time class="entry-date published" datetime="2015-08-21T18:51:24.000Z">
          2015-08-21
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>It’s ridiculous we don’t have a proper solution that uses Continuous Integration (CI) to grade homeworks hosted on GitHub.</p>
<p>CI, in short, is just a server that runs unit tests on your code every time you commit it. That means instead of you having to run unit tests before your commit your code (or manually run them after you commit them), a little robot checks your code against your unit tests every time you commit the code. That little robot never gets tired, doesn’t need to be fed. In short, these little robots are way better than human Teaching Assistants (TAs) (who in contrast, need to be fed pizza).</p>
<p>Given that I’ll be Head TAing a class with nearly 300 students this fall, I can’t afford enough pizzas to keep my team running. Or maybe I can, but I prefer not to. So why not get CI servers to grade homeworks? That requires two things:</p>
<ol>
<li>Getting students on GitHub (and submitting homeworks via GitHub)</li>
<li>Grading those homeworks on GitHub</li>
</ol>
<p>I’ll talk about (1) in a later post when I have the system fully set up, but basically it involves playing nice to GitHub and getting a team with lots and lots of private repositories. Then you give each student one private repository (so that they can’t copy. But then again, since they’re all on GitHub, it should be easy to implement a cheat check. That’s for next time).</p>
<h2 id="Homework-Assignment"><a href="#Homework-Assignment" class="headerlink" title="Homework Assignment"></a>Homework Assignment</h2><p>Let’s say that the student is supposed to write an assignment like this:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FibonacciRecursive</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(fibonacci(<span class="number">5</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">fibonacci</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// this is the method that student codes up</span></span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (n == <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> fibonacci(n - <span class="number">1</span>) + fibonacci(n - <span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>This happens in a file called <code>FibonacciRecursive.java</code>. (Wow surprise).</p>
<p>This is usually one of the first assignments in a data structures class or a last assignment in an intro programming class. Whatever it is, we can be sure of the following:</p>
<ol>
<li>You do not want to introduce unnecessary files into the homework package that the student works with. This confuses a student easily, and no good packaging software exists for Java which is as simple and intuitive as Grunt or NPM in JavaScript. You probably don’t want to use Maven or Ant.</li>
<li>You probably want to avoid unit tests, since they make it difficult for you to score the entire assignment, run asynchronously, and produce rather ugly output.</li>
</ol>
<p>Given those two limitations, you are set back by quite a bit, since most CI servers only run well on those systems. Give it Java with Maven and CircleCI (one of the larger CI services out there that provide free CI) will work like magic. However, give it non standard stuff and it coughs blood. Unfortunately, that bloody puddle is what we have to work with.</p>
<h2 id="Setting-up-CircleCI"><a href="#Setting-up-CircleCI" class="headerlink" title="Setting up CircleCI"></a>Setting up CircleCI</h2><p>(Side note: I chose CircleCI not TravisCI because Circle allows for private repositories while Travis insists on public).</p>
<p>Without a single unit test command, we have to be a little hacky with CircleCI. Now here’s how CircleCI runs in a nutshell:</p>
<ol>
<li>CircleCI reads off <code>circle.yml</code> in your repository. If it finds that file, it follows the instructions in that file. Otherwise, it tries to infer your environment (be it some Ruby thingum, Maven for Java, or Grunt for JS).</li>
<li>It runs the commands in <code>circle.yml</code> or the inferred commands.</li>
<li>Specifically, in the unit test portion, it runs every command in the unit test portion. If all of them produces an exit code of 0 (that means everything’s good), the unit tests pass. If any of them produce a non-0 exit code, unit tests fail, you get an error.</li>
<li>The results of these get emailed to you.</li>
</ol>
<p>That sounds cool right? So let’s start appropriating that system for homework grading.</p>
<h2 id="Game-Plan"><a href="#Game-Plan" class="headerlink" title="Game Plan"></a>Game Plan</h2><p>Your directory will end up containing</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- FibonacciRecursive.java</span><br><span class="line">- Grader.java</span><br><span class="line">- build.sh</span><br><span class="line">- circle.yml</span><br></pre></td></tr></table></figure>
<p>Here’s how everything works:</p>
<ol>
<li>CircleCI reads <code>circle.yml</code> which tells the server to run <code>build.sh</code> instead of running standard unit tests</li>
<li><code>build.sh</code> does the following<ol>
<li>It tries to compile <code>FibonacciRecursive.java</code> and <code>Grader.java</code></li>
<li>It runs Grader (now compiled as a class). Grader runs a series of tests on FibonacciRecursive, printing out the score that the student receives along each step. Depending on the score, Grader returns with an exit code of either 0 or 1.</li>
</ol>
</li>
<li><code>build.sh</code> returns whatever exit code Grader returns.</li>
<li>CircleCI consumes that exit code.</li>
</ol>
<p>And this is how we’ll abuse CircleCI to grade homeworks.</p>
<h2 id="Overriding-circle-yml"><a href="#Overriding-circle-yml" class="headerlink" title="Overriding circle.yml"></a>Overriding <code>circle.yml</code></h2><p>We know that we have to override <code>circle.yml</code> to not try and run Maven / Ant / freeze up and die when we run our custom Java stuff. What’s simpler than making it run a <code>.sh</code> script?</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Customize the test machine</span></span><br><span class="line"><span class="attr">machine:</span></span><br><span class="line">  <span class="comment"># Version of java to use</span></span><br><span class="line"><span class="attr">  java:</span></span><br><span class="line"><span class="attr">    version:</span> oraclejdk8</span><br><span class="line"></span><br><span class="line"><span class="comment">## Customize test commands</span></span><br><span class="line"><span class="attr">test:</span></span><br><span class="line"><span class="attr">  override:</span></span><br><span class="line"><span class="bullet">    -</span> sh build.sh</span><br></pre></td></tr></table></figure>
<p>That’s all that should go into your <code>circle.yml</code>.</p>
<h2 id="Creating-build-sh"><a href="#Creating-build-sh" class="headerlink" title="Creating build.sh"></a>Creating <code>build.sh</code></h2><p>Now your <code>build.sh</code> should just compile every <code>.java</code> file in your directory and run Grader. So that’s exactly what it does:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">javac *.java</span><br><span class="line">java Grader</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<h2 id="Creating-a-Grader-Tool-in-Java"><a href="#Creating-a-Grader-Tool-in-Java" class="headerlink" title="Creating a Grader Tool in Java"></a>Creating a Grader Tool in Java</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Grader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> score = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> scoreMax = <span class="number">50</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Fibonacci</span></span><br><span class="line">        <span class="comment">// Test 0</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 1 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 1</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 2 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 5</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">5</span>) == <span class="number">5</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 3 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 10</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">10</span>) == <span class="number">55</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 4 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test -1</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(-<span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 5 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (score != scoreMax) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>This should be rather self explanatory – you’re basically making a series of “assertions”, but tabulating scores at the same time.</p>
<h2 id="Pushing-to-GitHub"><a href="#Pushing-to-GitHub" class="headerlink" title="Pushing to GitHub"></a>Pushing to GitHub</h2><p>We push all this code to a GitHub repository:</p>
<p><a href="https://github.com/linanqiu/circle-ci-java-assignment-grading" target="_blank" rel="external">https://github.com/linanqiu/circle-ci-java-assignment-grading</a></p>
<h2 id="Setting-up-CircleCI-1"><a href="#Setting-up-CircleCI-1" class="headerlink" title="Setting up CircleCI"></a>Setting up CircleCI</h2><p>Add your repository on CircleCI after you’ve set up an account.</p>
<p><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci1.png" alt=""></p>
<p><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci2.png" alt=""></p>
<p>You’ll see that the build has started.</p>
<p><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci3.png" alt=""></p>
<p>And you should get the results of <code>Grader.java</code> being run on <code>FibonacciRecursive.java</code> as a result of <code>build.sh</code> being run as told by <code>circle.yml</code> (Phew)</p>
<p><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci4.png" alt=""></p>
<h2 id="Grade-On-Commit"><a href="#Grade-On-Commit" class="headerlink" title="Grade On Commit"></a>Grade On Commit</h2><p>It shows that we’ve failed the assignment and didn’t get full marks. Well obviously, since we made <code>Test 5</code> in the Grader an errorneous test. It should be producing 0 instead of 1. Let’s change that line:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Grader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> score = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> scoreMax = <span class="number">50</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Fibonacci</span></span><br><span class="line">        <span class="comment">// Test 0</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 1 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 1</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 2 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 5</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">5</span>) == <span class="number">5</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 3 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 10</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">10</span>) == <span class="number">55</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 4 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test -1</span></span><br><span class="line">        <span class="comment">// Modified</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(-<span class="number">1</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 5 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (score != scoreMax) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>We make this modification, and submit. We see that CircleCI has already seen the new commit and started building it:</p>
<p><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci5.png" alt=""></p>
<p>Seems like the problem has been fixed! And this happened without us intervening (and no pizzas involved).</p>
<p><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci6.png" alt=""></p>
<p>Isn’t this awesome? Even awesome-er, CircleCI has a great API. That means you can use this to create a live scoreboard for your students / email notifications every time they submit code.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/07/09/greece-cash/"><span>If Greece Ran on Digital Currency</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/07/09/greece-cash/" rel="bookmark">
        <time class="entry-date published" datetime="2015-07-09T04:10:41.000Z">
          2015-07-09
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>If the Greeks had no physical cash and only digital cash (in banks), they won’t be able to stash paper cash to wait out the conversion and drachma devaluation. Capital control would be easy and effective. Then, everyone would receive a haircut, and since the rumored haircut right now stands at anything above €8000, this would probably affect rich people disproportionately.<br>So we end up getting a currency conversion that is hugely progressive tax from a crisis.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/06/17/ec2-numpy/"><span>Getting Numpy on EC2</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/06/17/ec2-numpy/" rel="bookmark">
        <time class="entry-date published" datetime="2015-06-17T04:48:14.000Z">
          2015-06-17
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>After spending around half an hour trying to install <code>numpy</code> on Amazon Linux EC2, this <a href="http://stackoverflow.com/a/25456990" target="_blank" rel="external">StackOverflow answer</a> saved me</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install gcc-c++ python27-devel atlas-sse3-devel lapack-devel</span><br><span class="line">wget https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.2.tar.gz</span><br><span class="line">tar xzf virtualenv-1.11.2.tar.gz </span><br><span class="line">python27 virtualenv-1.11.2/virtualenv.py sk-learn</span><br><span class="line">. sk-learn/bin/activate</span><br><span class="line">pip install numpy</span><br></pre></td></tr></table></figure>
<p>Simply run and grab coffee.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/05/20/class-score-analysis/"><span>Class Score Analysis for CS 3134 Data Structures</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/05/20/class-score-analysis/" rel="bookmark">
        <time class="entry-date published" datetime="2015-05-20T04:48:14.000Z">
          2015-05-20
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>After TA-ing COMS W3134 Data Structures for a semester, I was left with a sizable amount of data from the homeworks, exams, and piazza usage. So I decided to make some pretty graphs out of them. This stemmed from my frustration at previous classes – why only give students a mean and standard deviation if there are so many more dimensions to the data? And perhaps this may even inspire a student or two to like statistics (which unfortunately, given the way it is taught in Columbia, is hardly inspiring).</p>
<p>So here’s some data porn.</p>
<p>To make sense of it all, I’m going to invoke an imaginary student called George. George is that annoying student at the front of the class that questions the professor non-stop regarding the nitty gritty details of the course. Yes there’s always George.</p>
<h2 id="Overall-Distributions"><a href="#Overall-Distributions" class="headerlink" title="Overall Distributions"></a>Overall Distributions</h2><p><em>George: What’s the mean and standard deviation for each homework, the midterm, and the final? Are they normal? You know I have this hypothesis that homeworks are bimodal…”</em></p>
<p>Now now George. Here’s all the info you need:</p>
<p><img src="/images/class-score-analysis/homework-exam-summary.png" alt=""></p>
<p>The mode of some homeworks tend to be around full marks, which is rather unsurprising given the nature of homeworks. Some fulfil all requirements, while others simply throw their hands in the air and well…not do them. This also reflects the content of the homeworks. Homework 3 and 4 tend to have many small (unrelated) parts hence it is entirely possible to score well in one and not others. The rest of them tend to have a larger single programming component.</p>
<h2 id="Homework-Covariance"><a href="#Homework-Covariance" class="headerlink" title="Homework Covariance"></a>Homework Covariance</h2><p><em>George: Do students do consistenly well / bad in all the homeworks or do they tend to vary quite a bit?</em></p>
<p>Great question George! Let’s see. Here we are interested if homework grades, when taken as a whole, move together. That means if Student A scores well in Homework 1, 2, and 3, does he score well in Homework 4 and 5 as well? What about Student B? What about other homeworks?</p>
<p>Turns out the easiest way to answer this is: what is the <strong>correlation</strong> of the homework scores.</p>
<p><img src="/images/class-score-analysis/corrplot.png" alt=""></p>
<p>Turns out most of them are moderately correlated. We can quantify this further by using <strong>Principal Component Analysis</strong> (PCA). Intuitively, PCA is a method that distills a common “factor” for all the data. After running PCA on the data, we have the following results:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Loadings:</span><br><span class="line">         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5</span><br><span class="line">data.hw1 -0.324 -0.103  0.139         0.927</span><br><span class="line">data.hw2 -0.410 -0.433  0.686  0.317 -0.270</span><br><span class="line">data.hw3 -0.612        -0.653  0.428       </span><br><span class="line">data.hw4 -0.510               -0.825 -0.240</span><br><span class="line">data.hw5 -0.304  0.892  0.286  0.172</span><br></pre></td></tr></table></figure>
<p>This means that the PCA reduced our data from 5 dimensions (since we had 5 datasets), the first of which is the homeworks moving in the same direction. But how much of the actual change is represented by that dimension? Turns out, quite a lot!</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Importance of components:</span><br><span class="line">                           Comp.1     Comp.2     Comp.3     Comp.4     Comp.5</span><br><span class="line">Standard deviation     40.9058984 25.1014708 23.9316752 20.2610806 19.4151851</span><br><span class="line">Proportion of Variance  0.4567392  0.1719867  0.1563301  0.1120525  0.1028915</span><br><span class="line">Cumulative Proportion   0.4567392  0.6287259  0.7850560  0.8971085  1.0000000</span><br></pre></td></tr></table></figure>
<p>The first dimension when all 5 homeworks are moving in the same direction accounts for around 41% of the total amount of variation. That means a common “force” that moves all the homeworks in the same direction accounts for around half the changes in homeworks from student to student.</p>
<p>This means that students’ homeworks are covaried to a pretty large extent. So George, students who do well in some homeworks tend to do well in others as well.</p>
<h2 id="Homework-and-Exams"><a href="#Homework-and-Exams" class="headerlink" title="Homework and Exams"></a>Homework and Exams</h2><p><em>George: What about the age old idiom that students who do well in homeworks tend to do better in exams? I was told by my elementary school teacher that…</em></p>
<p>Calm your tits George.</p>
<p>Let’s run a linear regression of homework against midterm and finals. Intuitively, this answers the question: if a question scores one point better on homeworks, how much better does he score on midterms / finals?</p>
<p>Let’s look at midterms first:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept) 39.82253    4.52721   8.796 7.88e-16 ***</span><br><span class="line">data$hw      0.07482    0.01105   6.768 1.52e-10 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><br><span class="line"></span><br><span class="line">Residual standard error: 13.79 on 193 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.1918,    Adjusted R-squared:  0.1876 </span><br><span class="line">F-statistic: 45.81 on 1 and 193 DF,  p-value: 1.523e-10</span><br></pre></td></tr></table></figure>
<p>Turns out homeworks correlate <em>pretty</em> well with midterm. A 1 point increase in homework (remember homeworks are graded out of 500, since I excluded homework 6 which we are still grading at the time of writing) translates into a 0.075 point increase in midterms. This is a pretty significant effect, but the R-squared is rather low, meaning that this does not hold for all students very strictly.</p>
<p>Let’s look at finals now:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept)  25.3966     4.7103   5.392 2.02e-07 ***</span><br><span class="line">data$hw       0.1108     0.0115   9.637  &lt; 2e-16 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><br><span class="line"></span><br><span class="line">Residual standard error: 14.35 on 193 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3249,    Adjusted R-squared:  0.3214 </span><br><span class="line">F-statistic: 92.87 on 1 and 193 DF,  p-value: &lt; 2.2e-16</span><br></pre></td></tr></table></figure>
<p>Homeworks correlate a lot better with finals than midterms. Again, a 1 point increase in homework translates into a 0.11 point increase in finals, and we have a higher R-squared here.</p>
<p><img src="/images/class-score-analysis/homework-midterm-final.png" alt=""></p>
<p>These two correlations are visualized in the scatter plot above.</p>
<h2 id="Piazza"><a href="#Piazza" class="headerlink" title="Piazza"></a>Piazza</h2><p><em>George: So I’ve been contributing a lot on piazza. My grades are awesome. Does that relationship hold?</em></p>
<p>Finally, I always tell students that the more they use piazza, the better they are able to learn. Asking question gets you answers, which makes you better. Answering answers makes you even better, since you learn way more by teaching than just being spoon-fed.</p>
<p>Well, you can answer these for yourself here.</p>
<p><img src="/images/class-score-analysis/piazza-homework.png" alt=""></p>
<p><img src="/images/class-score-analysis/piazza-midterm.png" alt=""></p>
<p><img src="/images/class-score-analysis/piazza-final.png" alt=""></p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>




<nav class="pagination">
  
  <a href="/" class="pagination-prev">Prev</a>
  
  
</nav>
      </main>
    </article>

    <footer id="colophon" class="site-footer" role="contentinfo"><p class="site-info">
  Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
  Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
  </br>
  
  &copy; 2016 Linan Qiu
  
</p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-66827435-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</body>
</html>
