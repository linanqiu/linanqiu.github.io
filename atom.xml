<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Pandamonium</title>
  
  <subtitle>Musings of a Panda</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://linanqiu.github.io/"/>
  <updated>2018-08-15T02:08:52.243Z</updated>
  <id>http://linanqiu.github.io/</id>
  
  <author>
    <name>Linan Qiu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Cheap Rides</title>
    <link href="http://linanqiu.github.io/2018/08/14/Cheap-Rides/"/>
    <id>http://linanqiu.github.io/2018/08/14/Cheap-Rides/</id>
    <published>2018-08-15T01:20:41.000Z</published>
    <updated>2018-08-15T02:08:52.243Z</updated>
    
    <content type="html"><![CDATA[<p>This notebook is available here: <a href="https://gist.github.com/linanqiu/87a0c708b3f7383fc56c2eb87ab8b087" class="uri" target="_blank" rel="noopener">https://gist.github.com/linanqiu/87a0c708b3f7383fc56c2eb87ab8b087</a></p><h1 id="cheap-rides">Cheap Rides</h1><p>My friend came up to me with a startup idea.</p><blockquote><p>“Hey what if you could compare Uber and Lyft prices and get the cheapest one? What if you make that a service? …<em>more pitching</em>…”</p></blockquote><p>Beyond the clear terms of agreement violation (Uber API literally has a clause saying that you aren’t allowed to do that) and the fact that Google Maps already has something like this, I was curious how easy / hard this was via the Uber / Lyft APIs. Turns out this can be done in like half an hour. Both had insanely clearly documented APIs and developer interfaces.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pint</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br></pre></td></tr></table></figure><p>Get your <code>CLIENT_TOKEN</code>s from Uber and Lyft APIs. It’s literally less than 5 clicks each.</p><p>Now let’s try to compare prices for a sample trip: <strong>Columbia University</strong> to <strong>Wow Karaoke on 34th St in Manhattan</strong>, a trip that I should probably have taken less when I was a student (and a perfect use case for this, given that I make most of these trips drunk and unable to navigate two apps). Use Google Maps to get the coordinates.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">payload = &#123;</span><br><span class="line">    <span class="string">'start_lat'</span>: <span class="number">40.8075395</span>,</span><br><span class="line">    <span class="string">'start_lng'</span>: <span class="number">-73.964761417</span>,</span><br><span class="line">    <span class="string">'end_lat'</span>: <span class="number">40.7473683</span>,</span><br><span class="line">    <span class="string">'end_lng'</span>: <span class="number">-73.988627417</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We grab both payloads from the APIs. They have really similar API endpoints – it’s almost like as if they’re poaching engineers from each other. Or just following really good API standards. I won’t know – I come from the finance industry where the last thing everyone agreed on was <a href="https://en.wikipedia.org/wiki/Financial_Information_eXchange" target="_blank" rel="noopener">FIX</a> and it’s absolute manure.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">payload_lyft = dict(payload)</span><br><span class="line"></span><br><span class="line">headers_lyft = &#123;</span><br><span class="line">    <span class="string">'Authorization'</span>: <span class="string">'Bearer %s'</span> % CLIENT_TOKEN_LYFT,</span><br><span class="line">    <span class="string">'Content-type'</span>: <span class="string">'application/json'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">estimate_lyft = requests.get(<span class="string">'https://api.lyft.com/v1/cost'</span>, params=payload_lyft, headers=headers_lyft)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">payload_uber = dict(((k.replace(<span class="string">'lat'</span>, <span class="string">'latitude'</span>).replace(<span class="string">'lng'</span>, <span class="string">'longitude'</span>), v) <span class="keyword">for</span> k, v <span class="keyword">in</span> payload.items()))</span><br><span class="line"></span><br><span class="line">headers_uber = &#123;</span><br><span class="line">    <span class="string">'Authorization'</span>: <span class="string">'Bearer %s'</span> % CLIENT_TOKEN_UBER,</span><br><span class="line">    <span class="string">'Content-type'</span>: <span class="string">'application/json'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">estimate_uber = requests.get(<span class="string">'https://api.uber.com/v1.2/estimates/price'</span>, params=payload_uber, headers=headers_uber)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(estimate_lyft.content)</span><br><span class="line">print(estimate_uber.content)</span><br></pre></td></tr></table></figure><pre><code>b&#39;{&quot;cost_estimates&quot;: [{&quot;currency&quot;: &quot;USD&quot;, &quot;ride_type&quot;: &quot;lyft_line&quot;, &quot;display_name&quot;: &quot;Shared&quot;, &quot;primetime_percentage&quot;: &quot;0%&quot;, &quot;primetime_confirmation_token&quot;: null, &quot;cost_token&quot;: null, &quot;price_quote_id&quot;: &quot;ENq21tjTLA==&quot;, &quot;is_valid_estimate&quot;: true, &quot;estimated_duration_seconds&quot;: 1498, &quot;estimated_distance_miles&quot;: 6.25, &quot;estimated_cost_cents_min&quot;: 900, &quot;estimated_cost_cents_max&quot;: 1200, &quot;can_request_ride&quot;: true}, {&quot;currency&quot;: &quot;USD&quot;, &quot;ride_type&quot;: &quot;lyft&quot;, &quot;display_name&quot;: &quot;Lyft&quot;, &quot;primetime_percentage&quot;: &quot;0%&quot;, &quot;primetime_confirmation_token&quot;: null, &quot;cost_token&quot;: null, &quot;price_quote_id&quot;: &quot;ENq21tjTLA==&quot;, &quot;is_valid_estimate&quot;: true, &quot;estimated_duration_seconds&quot;: 1498, &quot;estimated_distance_miles&quot;: 6.25, &quot;estimated_cost_cents_min&quot;: 2000, &quot;estimated_cost_cents_max&quot;: 2500, &quot;can_request_ride&quot;: true}, {&quot;currency&quot;: &quot;USD&quot;, &quot;ride_type&quot;: &quot;lyft_plus&quot;, &quot;display_name&quot;: &quot;Lyft XL&quot;, &quot;primetime_percentage&quot;: &quot;0%&quot;, &quot;primetime_confirmation_token&quot;: null, &quot;cost_token&quot;: null, &quot;price_quote_id&quot;: &quot;ENq21tjTLA==&quot;, &quot;is_valid_estimate&quot;: true, &quot;estimated_duration_seconds&quot;: 1498, &quot;estimated_distance_miles&quot;: 6.25, &quot;estimated_cost_cents_min&quot;: 3000, &quot;estimated_cost_cents_max&quot;: 3500, &quot;can_request_ride&quot;: true}, {&quot;currency&quot;: &quot;USD&quot;, &quot;ride_type&quot;: &quot;lyft_lux&quot;, &quot;display_name&quot;: &quot;Lux Black&quot;, &quot;primetime_percentage&quot;: &quot;0%&quot;, &quot;primetime_confirmation_token&quot;: null, &quot;cost_token&quot;: null, &quot;price_quote_id&quot;: &quot;ENq21tjTLA==&quot;, &quot;is_valid_estimate&quot;: true, &quot;estimated_duration_seconds&quot;: 1498, &quot;estimated_distance_miles&quot;: 6.25, &quot;estimated_cost_cents_min&quot;: 4200, &quot;estimated_cost_cents_max&quot;: 4900, &quot;can_request_ride&quot;: true}, {&quot;currency&quot;: &quot;USD&quot;, &quot;ride_type&quot;: &quot;lyft_luxsuv&quot;, &quot;display_name&quot;: &quot;Lux Black XL&quot;, &quot;primetime_percentage&quot;: &quot;0%&quot;, &quot;primetime_confirmation_token&quot;: null, &quot;cost_token&quot;: null, &quot;price_quote_id&quot;: &quot;ENq21tjTLA==&quot;, &quot;is_valid_estimate&quot;: true, &quot;estimated_duration_seconds&quot;: 1498, &quot;estimated_distance_miles&quot;: 6.25, &quot;estimated_cost_cents_min&quot;: 6000, &quot;estimated_cost_cents_max&quot;: 7000, &quot;can_request_ride&quot;: true}]}\n&#39;b&#39;{&quot;prices&quot;:[{&quot;localized_display_name&quot;:&quot;UberPool&quot;,&quot;distance&quot;:5.62,&quot;display_name&quot;:&quot;UberPool&quot;,&quot;product_id&quot;:&quot;929fcc19-8cb4-4007-a54f-3ab34473700f&quot;,&quot;high_estimate&quot;:16.0,&quot;low_estimate&quot;:11.0,&quot;duration&quot;:1380,&quot;estimate&quot;:&quot;$11-15&quot;,&quot;currency_code&quot;:&quot;USD&quot;},{&quot;localized_display_name&quot;:&quot;UberXL&quot;,&quot;distance&quot;:5.62,&quot;display_name&quot;:&quot;UberXL&quot;,&quot;product_id&quot;:&quot;1e0ce2df-4a1e-4333-86dd-dc0c67aaabe1&quot;,&quot;high_estimate&quot;:36.0,&quot;low_estimate&quot;:29.0,&quot;duration&quot;:1380,&quot;estimate&quot;:&quot;$29-36&quot;,&quot;currency_code&quot;:&quot;USD&quot;},{&quot;localized_display_name&quot;:&quot;UberX&quot;,&quot;distance&quot;:5.62,&quot;display_name&quot;:&quot;UberX&quot;,&quot;product_id&quot;:&quot;b8e5c464-5de2-4539-a35a-986d6e58f186&quot;,&quot;high_estimate&quot;:28.0,&quot;low_estimate&quot;:22.0,&quot;duration&quot;:1380,&quot;estimate&quot;:&quot;$22-28&quot;,&quot;currency_code&quot;:&quot;USD&quot;},{&quot;localized_display_name&quot;:&quot;Car Seat&quot;,&quot;distance&quot;:5.62,&quot;display_name&quot;:&quot;Car Seat&quot;,&quot;product_id&quot;:&quot;d6d6d7ad-67f9-43ef-a8de-86bd6224613a&quot;,&quot;high_estimate&quot;:39.0,&quot;low_estimate&quot;:31.0,&quot;duration&quot;:1380,&quot;estimate&quot;:&quot;$31-39&quot;,&quot;currency_code&quot;:&quot;USD&quot;},{&quot;localized_display_name&quot;:&quot;Black&quot;,&quot;distance&quot;:5.62,&quot;display_name&quot;:&quot;Black&quot;,&quot;product_id&quot;:&quot;0e9d8dd3-ffec-4c2b-9714-537e6174bb88&quot;,&quot;high_estimate&quot;:50.0,&quot;low_estimate&quot;:40.0,&quot;duration&quot;:1380,&quot;estimate&quot;:&quot;$40-50&quot;,&quot;currency_code&quot;:&quot;USD&quot;},{&quot;localized_display_name&quot;:&quot;Black SUV&quot;,&quot;distance&quot;:5.62,&quot;display_name&quot;:&quot;Black SUV&quot;,&quot;product_id&quot;:&quot;56487469-0d3d-4f19-b662-234b7576a562&quot;,&quot;high_estimate&quot;:66.0,&quot;low_estimate&quot;:53.0,&quot;duration&quot;:1380,&quot;estimate&quot;:&quot;$53-66&quot;,&quot;currency_code&quot;:&quot;USD&quot;}]}&#39;</code></pre><p>Now we can normalize these JSON blobs into a canonical form I care about: the <code>id</code> for a quote, the <code>app</code> of origin of the quote, the <code>ride_type</code> (e.g. Lyft Line vs Uber XL), <code>distance</code>, <code>cost_min</code>, <code>cost_max</code> and the currency of the quote <code>cost_currency</code>. These information exist in both return contents, but in different formats (be it time, currency, or distance). I use the <code>pint</code> package to represent units instead of doing stupid integer math on my own. <strong>Strong typing ftw. Even in <code>Python</code></strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">ureg = pint.UnitRegistry()</span><br><span class="line"></span><br><span class="line">estimate_lyft_obj = estimate_lyft.json()</span><br><span class="line">estimate_lyft_norm = (&#123;</span><br><span class="line">    <span class="string">'id'</span>: est[<span class="string">'price_quote_id'</span>],</span><br><span class="line">    <span class="string">'app'</span>: <span class="string">'lyft'</span>,</span><br><span class="line">    <span class="string">'ride_type'</span>: est[<span class="string">'ride_type'</span>],</span><br><span class="line">    <span class="string">'distance'</span>: est[<span class="string">'estimated_distance_miles'</span>] * ureg.mile,</span><br><span class="line">    <span class="string">'duration'</span>: est[<span class="string">'estimated_duration_seconds'</span>] * ureg.second,</span><br><span class="line">    <span class="string">'cost_min'</span>: est[<span class="string">'estimated_cost_cents_min'</span>] / <span class="number">100</span>,</span><br><span class="line">    <span class="string">'cost_max'</span>: est[<span class="string">'estimated_cost_cents_max'</span>] / <span class="number">100</span>,</span><br><span class="line">    <span class="string">'cost_currency'</span>: est[<span class="string">'currency'</span>]</span><br><span class="line">&#125; <span class="keyword">for</span> est <span class="keyword">in</span> estimate_lyft_obj[<span class="string">'cost_estimates'</span>])</span><br><span class="line"></span><br><span class="line">estimate_uber_obj = estimate_uber.json()</span><br><span class="line">estimate_uber_norm = (&#123;</span><br><span class="line">    <span class="string">'id'</span>: est[<span class="string">'product_id'</span>],</span><br><span class="line">    <span class="string">'app'</span>: <span class="string">'uber'</span>,</span><br><span class="line">    <span class="string">'ride_type'</span>: est[<span class="string">'display_name'</span>],</span><br><span class="line">    <span class="string">'distance'</span>: est[<span class="string">'distance'</span>] * ureg.mile,</span><br><span class="line">    <span class="string">'duration'</span>: est[<span class="string">'duration'</span>] * ureg.second,</span><br><span class="line">    <span class="string">'cost_min'</span>: est[<span class="string">'low_estimate'</span>],</span><br><span class="line">    <span class="string">'cost_max'</span>: est[<span class="string">'high_estimate'</span>],</span><br><span class="line">    <span class="string">'cost_currency'</span>: est[<span class="string">'currency_code'</span>]</span><br><span class="line">&#125; <span class="keyword">for</span> est <span class="keyword">in</span> estimate_uber_obj[<span class="string">'prices'</span>])</span><br><span class="line"></span><br><span class="line">estimate_norm = list(itertools.chain(estimate_lyft_norm, estimate_uber_norm))</span><br></pre></td></tr></table></figure><p>Now let’s see what lovely data we have. Turns out we have tons of that.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">estimate_df = pandas.DataFrame(estimate_norm)</span><br><span class="line">estimate_df</span><br></pre></td></tr></table></figure><table style="width:44%;"><colgroup><col width="5%"><col width="5%"><col width="5%"><col width="5%"><col width="5%"><col width="5%"><col width="5%"><col width="5%"></colgroup><thead><tr class="header"><th>app</th><th>cost_currency</th><th>cost_max</th><th>cost_min</th><th>distance</th><th>duration</th><th>id</th><th>ride_type</th></tr></thead><tbody><tr class="odd"><td>lyft</td><td>USD</td><td>12.0</td><td>9.0</td><td>6.25 mile</td><td>1498 second</td><td>ENq21tjTLA==</td><td>lyft_line</td></tr><tr class="even"><td>lyft</td><td>USD</td><td>25.0</td><td>20.0</td><td>6.25 mile</td><td>1498 second</td><td>ENq21tjTLA==</td><td>lyft</td></tr><tr class="odd"><td>lyft</td><td>USD</td><td>35.0</td><td>30.0</td><td>6.25 mile</td><td>1498 second</td><td>ENq21tjTLA==</td><td>lyft_plus</td></tr><tr class="even"><td>lyft</td><td>USD</td><td>49.0</td><td>42.0</td><td>6.25 mile</td><td>1498 second</td><td>ENq21tjTLA==</td><td>lyft_lux</td></tr><tr class="odd"><td>lyft</td><td>USD</td><td>70.0</td><td>60.0</td><td>6.25 mile</td><td>1498 second</td><td>ENq21tjTLA==</td><td>lyft_luxsuv</td></tr><tr class="even"><td>uber</td><td>USD</td><td>16.0</td><td>11.0</td><td>5.62 mile</td><td>1380 second</td><td>929fcc19-8cb4-4007-a54f-3ab34473700f</td><td>UberPool</td></tr><tr class="odd"><td>uber</td><td>USD</td><td>36.0</td><td>29.0</td><td>5.62 mile</td><td>1380 second</td><td>1e0ce2df-4a1e-4333-86dd-dc0c67aaabe1</td><td>UberXL</td></tr><tr class="even"><td>uber</td><td>USD</td><td>28.0</td><td>22.0</td><td>5.62 mile</td><td>1380 second</td><td>b8e5c464-5de2-4539-a35a-986d6e58f186</td><td>UberX</td></tr><tr class="odd"><td>uber</td><td>USD</td><td>39.0</td><td>31.0</td><td>5.62 mile</td><td>1380 second</td><td>d6d6d7ad-67f9-43ef-a8de-86bd6224613a</td><td>Car Seat</td></tr><tr class="even"><td>uber</td><td>USD</td><td>50.0</td><td>40.0</td><td>5.62 mile</td><td>1380 second</td><td>0e9d8dd3-ffec-4c2b-9714-537e6174bb88</td><td>Black</td></tr><tr class="odd"><td>uber</td><td>USD</td><td>66.0</td><td>53.0</td><td>5.62 mile</td><td>1380 second</td><td>56487469-0d3d-4f19-b662-234b7576a562</td><td>Black SUV</td></tr></tbody></table><p>We get pretty interesting observations: right now, Uber’s more expensive than Lyft by two whole bucks. That’s interesting! No? Yes? Whatever.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"><span class="comment"># sorry for ugly indents. fucking python.</span></span><br><span class="line">estimate_df[</span><br><span class="line">    [<span class="string">'app'</span>, <span class="string">'ride_type'</span>, <span class="string">'cost_min'</span>, <span class="string">'cost_max'</span>]</span><br><span class="line">].set_index(</span><br><span class="line">    [<span class="string">'app'</span>, <span class="string">'ride_type'</span>]</span><br><span class="line">).sort_values(</span><br><span class="line">    [<span class="string">'app'</span>, <span class="string">'cost_min'</span>, <span class="string">'cost_max'</span>]</span><br><span class="line">).plot(kind=<span class="string">'bar'</span>, ax=ax)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/cheap-rides/output_14_0.svg"></div><p>I showed this to my roommate and he’s still convinced this is a great startup idea.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This notebook is available here: &lt;a href=&quot;https://gist.github.com/linanqiu/87a0c708b3f7383fc56c2eb87ab8b087&quot; class=&quot;uri&quot; target=&quot;_blank&quot; 
      
    
    </summary>
    
    
      <category term="data" scheme="http://linanqiu.github.io/tags/data/"/>
    
      <category term="api" scheme="http://linanqiu.github.io/tags/api/"/>
    
      <category term="software" scheme="http://linanqiu.github.io/tags/software/"/>
    
  </entry>
  
  <entry>
    <title>Wedding Seat Optimization</title>
    <link href="http://linanqiu.github.io/2018/03/05/Wedding-Seat-Optimization/"/>
    <id>http://linanqiu.github.io/2018/03/05/Wedding-Seat-Optimization/</id>
    <published>2018-03-05T23:10:00.000Z</published>
    <updated>2018-08-15T02:09:15.562Z</updated>
    
    <content type="html"><![CDATA[<h1 id="wedding-seat-optimization-using-simulated-annealing">Wedding Seat Optimization using Simulated Annealing</h1><p><em>Or what I do when I go back to Singapore for one friend’s wedding (congratulations Crystalbel and Kenneth!) and find that all but three of my friends are married / engaged.</em></p><p>Turns out they all have a similar problem: wedding dinner planning. In particular, seat planning is a nightmare. It doesn’t take much imagination for one to picture one’s favorite relative specifying seating arrangements to the most minute detail. (“eh my sister’s uncle’s brother cannot sit with my brother’s cousin because they don’t see each other eye to eye.”) You probably don’t want to seat ex-es together as well. Same goes for ex-colleagues who may be awkward with each other. Whatever the reason is, seating arrangement is tricky.</p><p>Thankfully, I’m not the first person to come across this problem. There’s a <a href="https://www.improbable.com/news/2012/Optimal-seating-chart.pdf" target="_blank" rel="noopener">very nice paper here by Bellows and Peterson</a> on this exact problem. This paper provided a neat framework to think about this problem, but aimed for the global optimal via mixed-integer linear optimization. I find that probably too overkill, and an approximate method that sufficient avoids the local minima trap should suffice. The paper also uses a proprietary solver which is a huge turn-off, and no one wants that for a wedding. Heh. Finally, I also wanted to learn some simulated annealing. So here’s a very short script that accomplishes that.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure><h2 id="framing-this-as-a-combinatorial-optimization-problem">Framing This as a Combinatorial Optimization Problem</h2><p>Going back to the problem statement, we can think about this as an combinatorial optimization problem. Essentially, seating preferences can be expressed as a series of weights between two parties. For example, if Linan hates sitting with Spongebob, I can assign the event that they sit together a <strong>positive cost</strong> of 50. If Gabriel and Kristie are a couple, and they would very much want to sit together, then them sitting together would incur a <strong>negative cost</strong> of -50. If Spongebob don’t want to sit with Squidward but won’t die if they do end up sit together, I can assign them a slightly lower positive cost (e.g. 20).</p><p>Then, my overall goal is to minimize the cost of an arrangement. For example, if I had an arrangement that made Gabriel sit together with Kristie, Linan sit with Spongebob, and Spongebob sit with Squidward, the overall cost would be <code>-50 + 50 + 20 = 20</code>. However, if I moved Spongebob to a different table such that Gabriel, Kristie, Linan, and Squiward are at the same table, the cost for the arrangement becomes <code>-50</code> and that would be a way more preferable arrangement compared to the original. We assume of course that unspecified pairs (e.g. Gabriel and Squidward, Kristie and Linan) have a cost of 0 i.e. they don’t care if they do sit together or not.</p><p>You can think of this as a graph problem with nodes being the dinner participants and edges being the costs.</p><p>So let’s set up the problem. Assume that we have 10 guests initially and they hate / love each other in the following manner. Assume that each table seats 5 people, so we have two tables. Admire how creative the guest names are and how I have to import a whole damn package for that.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">guest_list = list(string.ascii_uppercase)[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># negative is good (those two like each other), positive is bad (those two hate each other)</span></span><br><span class="line">relationships_edges = &#123;</span><br><span class="line">    (<span class="string">'A'</span>, <span class="string">'B'</span>): <span class="number">-50</span>,</span><br><span class="line">    (<span class="string">'C'</span>, <span class="string">'D'</span>): <span class="number">-50</span>,</span><br><span class="line">    (<span class="string">'A'</span>, <span class="string">'D'</span>): <span class="number">50</span>,</span><br><span class="line">    (<span class="string">'E'</span>, <span class="string">'F'</span>): <span class="number">25</span>,</span><br><span class="line">    (<span class="string">'F'</span>, <span class="string">'G'</span>): <span class="number">-50</span>,</span><br><span class="line">    (<span class="string">'H'</span>, <span class="string">'I'</span>): <span class="number">-50</span>,</span><br><span class="line">&#125;</span><br><span class="line">table_size = <span class="number">5</span></span><br><span class="line">table_count = len(guest_list) // table_size</span><br><span class="line"></span><br><span class="line">print(guest_list)</span><br></pre></td></tr></table></figure><pre><code>[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;]</code></pre><p>Given <code>relationships_edges</code>, I want to convert them into a symmetric cost matrix so that matrix operations become easier (and faster! thanks <code>numpy</code>). To do this, I use the <code>networkx</code>.</p><p>I also normalize the costs by a factor of <code>100</code> so that it plays nice with the cost and acceptance probability later.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">temp_graph = nx.Graph()</span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> relationships_edges.items():</span><br><span class="line">    temp_graph.add_edge(k[<span class="number">0</span>], k[<span class="number">1</span>], weight=v)</span><br><span class="line">relationships_mat_unnormed = nx.to_numpy_matrix(temp_graph.to_undirected(), nodelist=guest_list)</span><br><span class="line"></span><br><span class="line">relationships_mat = relationships_mat_unnormed / <span class="number">100</span></span><br><span class="line"></span><br><span class="line">print(relationships_mat)</span><br></pre></td></tr></table></figure><pre><code>[[ 0.   -0.5   0.    0.5   0.    0.    0.    0.    0.    0.  ] [-0.5   0.    0.    0.    0.    0.    0.    0.    0.    0.  ] [ 0.    0.    0.   -0.5   0.    0.    0.    0.    0.    0.  ] [ 0.5   0.   -0.5   0.    0.    0.    0.    0.    0.    0.  ] [ 0.    0.    0.    0.    0.    0.25  0.    0.    0.    0.  ] [ 0.    0.    0.    0.    0.25  0.   -0.5   0.    0.    0.  ] [ 0.    0.    0.    0.    0.   -0.5   0.    0.    0.    0.  ] [ 0.    0.    0.    0.    0.    0.    0.    0.   -0.5   0.  ] [ 0.    0.    0.    0.    0.    0.    0.   -0.5   0.    0.  ] [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">relationships_mat[<span class="number">0</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><pre><code>-0.5</code></pre><p>Now we have a symmetric matrix of costs. An element at <code>relationships_mat[i, j]</code> describes the cost of putting guest <code>i</code> and guest <code>j</code> together in the same table. For example, <code>guest_list[0] = 'A'</code> and <code>guest_list[1] = 'B'</code>. The cost of putting <code>A</code> and <code>B</code> together at the same table is <code>-50</code> (i.e. they love each other! yay!). <code>relationships_mat[0, 1]</code> gives us the normalized cost of <code>-50 / 100 = -0.5</code> as expected.</p><p>Notice how <code>networkx</code> converted a <code>nodelist</code> of <code>guest_list</code> into positional integers for me. Isn’t that neat?</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">table_0_seats = np.matrix([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line">print(table_0_seats)</span><br></pre></td></tr></table></figure><pre><code>[[1 0 1 0 0 1 1 1 0 0]]</code></pre><p>We can express a single “table” as a row in a matrix by marking guests present at the table with a <code>1</code> and those not present as <code>0</code> for the positional integer that represents them. For example, a table that contains <code>'A', 'C', 'F', 'G', 'H'</code> can be expressed using the <code>table_0_seats</code> above.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">table_0_seats = np.matrix([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line">print(table_0_seats * relationships_mat * table_0_seats.T)</span><br></pre></td></tr></table></figure><pre><code>[[-1.]]</code></pre><p>We then observe the interesting (okay probably not interesting) property that <span class="math inline">\(SRS^T\)</span> where <span class="math inline">\(S\)</span> is the seats matrix, <span class="math inline">\(R\)</span> is the relationships cost matrix <code>relationships_mat</code> and <span class="math inline">\(S^T\)</span> is the transpose of the seats matrix gives us the cost of a particular arrangement (or more precisely, the total cost incurred per person. e.g. since <code>F</code> and <code>G</code> are sitting at the same table, the cost incurred by each of them is <code>-0.5</code>, so the total cost for the table is <code>-1</code>).</p><p>Using <code>table_0_seats</code> as an example, the result of doing the quadratic multiplication is:</p><p><span class="math display">\[SRS^T = \sum^{guests}_{i=0} \sum^{guests}_{j=0} S_{1,i} \times R_{i,j} \times S^T_{j,1} \]</span></p><p>Now this is just the formulation for a single table. We can easily imagine each row of <span class="math inline">\(S\)</span> as a single table. In that case, we get:</p><p><span class="math display">\[SRS^T = C\]</span></p><p><span class="math display">\[C_{k, l} = \sum^{guests}_{i=0} \sum^{guests}_{j=0} S_{k,i} \times R_{i,j} \times S^T_{j,l} \]</span></p><p>for all tables <span class="math inline">\(k\)</span> and <span class="math inline">\(l\)</span></p><p>This is what we do below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">table_seats_a = np.matrix([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">])</span><br><span class="line">table_costs_a = table_seats_a * relationships_mat * table_seats_a.T</span><br><span class="line">print(table_costs_a)</span><br><span class="line">print(np.trace(table_costs_a))</span><br></pre></td></tr></table></figure><pre><code>[[-1.   -0.75] [-0.75  0.  ]]-1.0</code></pre><p>Then, the diagonal of <span class="math inline">\(C\)</span> should give the cost of tables where <span class="math inline">\(k=l\)</span> i.e. our actual costs. The sum of the diagonal (or the <em>trace</em>) gives us the total cost of a given arrangement.</p><p><span class="math display">\[Cost = \sum^{tables}_{m} C_{m,m}\]</span></p><p>Using the example above, <code>table_seats_a</code> puts <code>'A', 'C', 'F', 'G', 'H'</code> in one table and <code>'B', 'D', 'E', 'I', 'J'</code> in another. <code>F</code> loves <code>G</code>, so each incurs a normalized negative cost of <code>-0.5</code>. So <code>np.trace(table_costs_a)</code> gives us <code>-1</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">table_seats_b = np.matrix([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">])</span><br><span class="line">table_costs_b = table_seats_b * relationships_mat * table_seats_b.T</span><br><span class="line">print(table_costs_b)</span><br><span class="line">print(np.trace(table_costs_b))</span><br></pre></td></tr></table></figure><pre><code>[[-1.    0.25] [ 0.25 -2.  ]]-3.0</code></pre><p>We can probably do better than that. So let’s try putting <code>'A', 'B', 'C', 'E', 'J'</code> in one table and <code>'D', 'F', 'G', 'H', 'I'</code> in the other. In this case, our first table gives us a cost of <code>-1</code> because of <code>A</code> and <code>B</code>. The second table gives us <code>-2</code> due to <code>F</code> <code>G</code> and <code>H</code> <code>I</code>. This leaves us with a total cost of <code>np.trace(table_costs_b) = -3</code>.</p><p>The advantage of defining our cost calculation in terms of a matrix quadratic operation is that <strong><code>numpy</code> is fucking fast</strong> and tons of optimizations are built around those things. Plus it’s kind of elegant heh.</p><h2 id="constraints-requirements-and-strategy">Constraints, Requirements, and Strategy</h2><p>Now we just need to minimize <span class="math inline">\(C\)</span> subject to some constraints:</p><ul><li>The number of people in each table should not change.</li><li>As a corollary (and if you defined the starting point correctly), the total number of guests with seats should not change and hence everyone should be seated (otherwise one solution where people only hate each other and there’s no love is to keep removing people).</li><li>Avoiding local minima is very important for obvious reasons.</li><li>Finding the absolute best answer is not that important. Having an approximate answer’s probably good enough.</li></ul><p>I chose <a href="https://www.wikiwand.com/en/Simulated_annealing" target="_blank" rel="noopener">simulated annealing</a> because I’ve been wanting to learn that for quite a while. (thanks Quan!) It also gives me a really simple way to solve a pretty intractable problem (wedding dinners often contain 200 or more guests) while satisfying all the requirements I have above – especially the one on local minimum.</p><p>If you want a good introduction to simulated annealing, I suggest you read this: <a href="http://katrinaeg.com/simulated-annealing.html" class="uri" target="_blank" rel="noopener">http://katrinaeg.com/simulated-annealing.html</a>. It’s a really good tutorial, and she kicks ass at explaining simulated annealing. If you’re too lazy to read that, I stole the best part of the article that sums up simulated annealing nicely:</p><blockquote><ol style="list-style-type: decimal"><li>First, generate a random solution</li><li>Calculate its cost using some cost function you’ve defined</li><li>Generate a random neighboring solution</li><li>Calculate the new solution’s cost</li><li>Compare them:<ul><li>If <code>c_new</code> &lt; <code>c_old</code>: move to the new solution</li><li>If <code>c_new</code> &gt; <code>c_old</code>: maybe move to the new solution. <strong>Be more eager to move initially, and less eager to move later</strong></li></ul></li><li>Repeat steps 3-5 above until an acceptable solution is found or you reach some maximum number of iterations.</li></ol></blockquote><p>Seriously though, go read the article. It’s awesomesauce.</p><h2 id="simulated-annealing-functions">Simulated Annealing Functions</h2><p>First we build our seat reshaping function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_to_table_seats</span><span class="params">(x)</span>:</span></span><br><span class="line">    table_seats = x.reshape(table_count, len(guest_list))</span><br><span class="line">    <span class="keyword">return</span> table_seats</span><br></pre></td></tr></table></figure><p><code>reshape</code> is a constant time operation that <code>numpy</code> provides that’s good for matrix heavy code. Helps you keep track of where you are and avoid cryptic bugs. I want my seat matrix <span class="math inline">\(S\)</span> to be of the shape <code>(table_count, guests)</code> so that the <span class="math inline">\(SRS^T\)</span> operation can be done easily.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(x)</span>:</span></span><br><span class="line">    table_seats = reshape_to_table_seats(x)</span><br><span class="line">    table_costs = table_seats * relationships_mat * table_seats.T</span><br><span class="line">    table_cost = np.trace(table_costs)</span><br><span class="line">    <span class="keyword">return</span> table_cost</span><br></pre></td></tr></table></figure><p>Then we define the cost function. This should be nothing new. It is basically the trace of the cost matrix as mentioned earlier. It calculates the cost for a given seating arrangement using the relationship cost matrix.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">take_step</span><span class="params">(x)</span>:</span></span><br><span class="line">    table_seats = reshape_to_table_seats(np.matrix(x, copy=<span class="keyword">True</span>))</span><br><span class="line">    <span class="comment"># randomly swap two guests</span></span><br><span class="line">    table_from, table_to = np.random.choice(table_count, <span class="number">2</span>, replace=<span class="keyword">False</span>)</span><br><span class="line">    </span><br><span class="line">    table_from_guests = np.where(table_seats[table_from] == <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    table_to_guests = np.where(table_seats[table_to] == <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    table_from_guest = np.random.choice(table_from_guests)</span><br><span class="line">    table_to_guest = np.random.choice(table_to_guests)</span><br><span class="line">    </span><br><span class="line">    table_seats[table_from, table_from_guest] = <span class="number">0</span></span><br><span class="line">    table_seats[table_from, table_to_guest] = <span class="number">1</span></span><br><span class="line">    table_seats[table_to, table_to_guest] = <span class="number">0</span></span><br><span class="line">    table_seats[table_to, table_from_guest] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> table_seats</span><br></pre></td></tr></table></figure><p>The <code>take_step</code> function does step 3: generate a random neighboring solution. It does so by picking two random tables and swapping two random guests from the two tables. This has the very nice property of:</p><ul><li>Being random (no seriously this is important. If you’re proceeding in a definite direction ala <a href="https://www.wikiwand.com/en/Gradient_descent" target="_blank" rel="noopener">gradient descent</a> you’ll find yourself in a local minimum pretty quickly. You’ll also limit your space exploration tremendously if you’re not random.</li><li>Never changing the number of guests per table. This affords us tons of flexibility, including specifying tables with different number of guests (a common problem for odd ballrooms)</li><li>Similarly, not seating the same guest at two tables / having empty table etc.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prob_accept</span><span class="params">(cost_old, cost_new, temp)</span>:</span></span><br><span class="line">    a = <span class="number">1</span> <span class="keyword">if</span> cost_new &lt; cost_old <span class="keyword">else</span> np.exp((cost_old - cost_new) / temp)</span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><p>Finally, <code>prob_accept</code> is the function that gives the probability of us moving from the current position to the neighboring position. If the neighboring position is indeed better (i.e. <code>cost_new &lt; cost_old</code>) we move (i.e. probabilty is 1). Otherwise, we “may” move using the function <code>np.exp((cost_old - cost_new) / temp)</code> where <code>temp</code> is a decreasing function of the number of iterations. This means that our probability for taking a worse neighboring position over the current position</p><ul><li>Decreases the shittier the new position is. (i.e. our neighboring position is already going to be worse than our current position because otherwise, we would have returned probability 1. Given that it is worse than our current position, we are more willing to move to a position that is less shitty than a position that is more shitty.) This is expressed in <code>cost_old - cost_new</code>. Since <code>cost_old &lt; cost_new</code>, <code>(cost_old - cost_new) &lt; 0</code>. The more negative <code>(cost_old - cost_new)</code> is, the lower <code>np.exp((cost_old - cost_new) / temp)</code> is and hence the lower the probability.</li><li>Decreases as we do more iteration (i.e. we become more conservative as we run more iterations). This is expressed in the <code>temp</code> denominator. Since the numerator <code>(cost_old - cost_new)</code> is negative, having an increasingly smaller <code>temp</code> would make <code>(cost_old - cost_new) / temp</code> more negative, hence the probability lower.</li></ul><p>The four functions are reproduced below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reshape_to_table_seats</span><span class="params">(x)</span>:</span></span><br><span class="line">    table_seats = x.reshape(table_count, len(guest_list))</span><br><span class="line">    <span class="keyword">return</span> table_seats</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(x)</span>:</span></span><br><span class="line">    table_seats = reshape_to_table_seats(x)</span><br><span class="line">    table_costs = table_seats * relationships_mat * table_seats.T</span><br><span class="line">    table_cost = np.trace(table_costs)</span><br><span class="line">    <span class="keyword">return</span> table_cost</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">take_step</span><span class="params">(x)</span>:</span></span><br><span class="line">    table_seats = reshape_to_table_seats(np.matrix(x, copy=<span class="keyword">True</span>))</span><br><span class="line">    <span class="comment"># randomly swap two guests</span></span><br><span class="line">    table_from, table_to = np.random.choice(table_count, <span class="number">2</span>, replace=<span class="keyword">False</span>)</span><br><span class="line">    </span><br><span class="line">    table_from_guests = np.where(table_seats[table_from] == <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    table_to_guests = np.where(table_seats[table_to] == <span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    table_from_guest = np.random.choice(table_from_guests)</span><br><span class="line">    table_to_guest = np.random.choice(table_to_guests)</span><br><span class="line">    </span><br><span class="line">    table_seats[table_from, table_from_guest] = <span class="number">0</span></span><br><span class="line">    table_seats[table_from, table_to_guest] = <span class="number">1</span></span><br><span class="line">    table_seats[table_to, table_to_guest] = <span class="number">0</span></span><br><span class="line">    table_seats[table_to, table_from_guest] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> table_seats</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prob_accept</span><span class="params">(cost_old, cost_new, temp)</span>:</span></span><br><span class="line">    a = <span class="number">1</span> <span class="keyword">if</span> cost_new &lt; cost_old <span class="keyword">else</span> np.exp((cost_old - cost_new) / temp)</span><br><span class="line">    <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure><h2 id="annealing">Annealing</h2><p>Now we get to the <code>anneal</code> function that runs the whole damn thing. We basically keep iterating until we reach a minimum temperature. The code should be pretty self explanatory and maps 1:1 to the pseudocode earlier. Essentially, it:</p><ul><li>Starts with an initial position</li><li>While the current temperature is above the minimum temperature,<ul><li>For <code>n_iter</code> steps,<ul><li>Calculate a neighboring position (<code>pos_new</code>)</li><li>Calculate the cost of the neighboring position (<code>cost_new</code>)</li><li>Calculate the acceptance probability (<code>p_accept</code>) for the neighboring position</li><li>“Maybe” move to the neighboring position</li></ul></li><li>Reduce current temperature by a given multiple (default value of <code>alpha=0.9</code>)</li></ul></li></ul><p><code>audit_trail</code> lets me plot pretty graphs.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">anneal</span><span class="params">(pos_current, temp=<span class="number">1.0</span>, temp_min=<span class="number">0.00001</span>, alpha=<span class="number">0.9</span>, n_iter=<span class="number">100</span>, audit=False)</span>:</span></span><br><span class="line">    cost_old = cost(pos_current)</span><br><span class="line">    </span><br><span class="line">    audit_trail = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> temp &gt; temp_min:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, n_iter):</span><br><span class="line">            pos_new = take_step(pos_current)</span><br><span class="line">            cost_new = cost(pos_new)</span><br><span class="line">            p_accept = prob_accept(cost_old, cost_new, temp)</span><br><span class="line">            <span class="keyword">if</span> p_accept &gt; np.random.random():</span><br><span class="line">                pos_current = pos_new</span><br><span class="line">                cost_old = cost_new</span><br><span class="line">            <span class="keyword">if</span> audit:</span><br><span class="line">                audit_trail.append((cost_new, cost_old, temp, p_accept))</span><br><span class="line">        temp *= alpha</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> pos_current, cost_old, audit_trail</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = anneal(table_seats_b, audit=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(result[<span class="number">0</span>])</span><br><span class="line">print(cost(result[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>[[0 0 1 1 1 0 0 1 1 0] [1 1 0 0 0 1 1 0 0 1]]-4.0</code></pre><p>And voila! We get our result. Turns out an optimal arrangement is to put <code>'C', 'D', 'E', 'H', 'I'</code> in one table and <code>'A', 'B', 'F', 'G', 'J'</code> in the other. The first table makes use of <code>C</code> <code>D</code> and <code>H</code> <code>I</code>. The second table makes use of <code>A</code> <code>B</code> and <code>F</code> <code>G</code>. That’s all the negative weights we have specified. Furthermore, it has avoided the positive weight combinations (<code>A</code> <code>D</code> and <code>E</code> <code>F</code>).</p><p>To see the journey we took to get here, we can use the <code>audit_trail</code> data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">audit_df = pd.DataFrame(result[<span class="number">2</span>], columns=[<span class="string">'cost_new'</span>, <span class="string">'cost_old'</span>, <span class="string">'temp'</span>, <span class="string">'p_accept'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">audit_df[[<span class="string">'cost_old'</span>]].plot()</span><br><span class="line">audit_df[[<span class="string">'temp'</span>]].plot()</span><br><span class="line">audit_df[[<span class="string">'p_accept'</span>]].plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x118a97748&gt;</code></pre><div class="figure"><img src="/images/Wedding-Seat-Optimization/output_32_1.svg"></div><div class="figure"><img src="/images/Wedding-Seat-Optimization/output_32_2.svg"></div><div class="figure"><img src="/images/Wedding-Seat-Optimization/output_32_3.svg"></div><p>We see that</p><ul><li><code>cost_old</code> decreases with random spikes initially due to us (adventurously!) exploring neighboring solutions.</li><li><code>temp</code> decreases (duh)</li><li><code>p_accept</code> decreases along with <code>temp</code> unless we find better solutions (in which case we set <code>p_accept</code> to 1)</li></ul><p>This is fucking awesome <code>:D</code></p><h2 id="questions">Questions?</h2><p><strong>Why are all your friends getting married?</strong></p><p>Because they’re on a mission to repopulate Singapore and reduce our dependency on foreign talents like me. They’re also probably more charming than me.</p><p><strong>When’s yours?</strong></p><p>Fuck off.</p><p><strong>I noticed you used <code>table_count = len(guest_list) // table_size</code>. That means all tables have to be of the same size right? What if I want different table sizes?</strong></p><p>Ah! Yes. Great question. There’s actually no such assumption. You just need to have a constant number of tables. We take neighboring steps by swapping two guests in two random tables. That means we don’t actually change the number of guests in each other. So even if in our example (using 10 guests) we have one table with 1 guest and the other with 9 guests, this would still work.</p><p>However, the number of tables would need to be constant. In other words, the table configuration (i.e. number of tables and number of people per table) need to be fixed. If you want to optimize over that, you’ll have to do multiple runs of this algorithm.</p><p><strong>Why did you scale by <code>100</code> for the cost matrix and not use the cost matrix directly?</strong></p><p>Because the way <code>p_accept</code> is defined (<code>np.exp((cost_old - cost_new) / temp)</code>) causes strange things to occur if <code>cost_old</code> is way too different from <code>cost_new</code>. You’d end up getting either 0 or 1 probabilities, which is not useful. Just observe the graph of <span class="math inline">\(f(x) = e^x\)</span> in the region of <span class="math inline">\(f(x) \leq 1\)</span>.</p><p><strong>Won’t performance suffer when you start having a 100 tables or thousands of guests?</strong></p><p>Yes! Great question again. Given that our cost computation is <span class="math inline">\(SRS^T\)</span> where <span class="math inline">\(S\)</span> is of the shape <code>(table_count, guest count)</code> and <span class="math inline">\(R\)</span> is a symmetric matrix of the shape <code>(guest_count, guest_count)</code>, our cost computation can get pretty intensive. Fortunately, we can exploit certain properties of the matrices, namely:</p><ul><li><span class="math inline">\(S\)</span> is going to be super sparse. Each row of <span class="math inline">\(S\)</span> represents a table, and it contains <code>1</code>s for the guests that are at the table and <code>0</code>s for the other guests. That means a single row will be predominantly <code>0</code>s. That means <span class="math inline">\(S\)</span> itself will be super sparse. <code>scipy</code> has an implementation of a matrix that optimizes for sparse performance. We can use that when things start to slow down.</li><li><span class="math inline">\(R\)</span> is a symmetric matrix (as with most undirected cost matrices). Again, <code>scipy</code> to the rescue – <code>scipy</code> has an implementation of a symmetric matrix that we can use.</li></ul><p>Fortunately, <code>numpy</code> is already blazing fast and I haven’t ran into any performance problems for the larger tests I’ve ran (up to 100 guests). We can also farm out the large matrix operations to GPUs (especially if we modify the operations to be in place so that we don’t have to keep loading and unloading memory into the GPU’s RAM).</p><p>For now, YAGNI. No performance problems yet, and we know squeezing performance can be easy.</p><p><strong>Are you going to make this into a website / command line app / app</strong></p><p>Maybe. The fun’s all gone once the solution’s here though. I solved this three weeks ago and procrastinated writing this post for that long. Is this even worth making? I don’t know. Maybe more friends should get married.</p><p><strong>Speaking of that, you should get married…</strong></p><p>Fuck off.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;wedding-seat-optimization-using-simulated-annealing&quot;&gt;Wedding Seat Optimization using Simulated Annealing&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Or what I do wh
      
    
    </summary>
    
    
      <category term="data" scheme="http://linanqiu.github.io/tags/data/"/>
    
      <category term="algos" scheme="http://linanqiu.github.io/tags/algos/"/>
    
      <category term="optimization" scheme="http://linanqiu.github.io/tags/optimization/"/>
    
      <category term="life" scheme="http://linanqiu.github.io/tags/life/"/>
    
      <category term="wedding" scheme="http://linanqiu.github.io/tags/wedding/"/>
    
  </entry>
  
  <entry>
    <title>Disposable Background Tasks in C#</title>
    <link href="http://linanqiu.github.io/2017/10/10/Disposable-Background-Tasks-in-C/"/>
    <id>http://linanqiu.github.io/2017/10/10/Disposable-Background-Tasks-in-C/</id>
    <published>2017-10-11T02:18:33.000Z</published>
    <updated>2017-10-11T02:33:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>I wanted a clean way to spin up a looping task in C# and do things while the task is running.</p><p>Conceptually, I want</p><ol style="list-style-type: decimal"><li>Start the “service”</li><li>Run procedure</li><li>Stop the “service”</li></ol><p>This would be simple if the “service” had a start / stop button. However, the “service” runs like <strong>dead man’s switch</strong>: unless it’s pinged every now and then, it dies. When it’s first pinged, it starts up. Specifically, what I had was:</p><ul><li>A “service” that dies if I don’t ping it every 10 seconds</li><li>A procedure that need to be run against the “service” while it’s alive</li></ul><p>I needed a clean way to write my routine without resorting to <code>Thread.Sleep</code> and <code>for</code> loop hell. The obvious answer’s threading – put the timer and ping on a background thread, run the procedure, then kill the thread. This is probably simple using the <a href="https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/task-parallel-library-tpl" target="_blank" rel="noopener">Task Parallel Library</a> in C#. However, I did not want to do so imperatively and start / stop the thread explicitly; doing so results in uglier / less readable code.</p><p>Turns out <code>IDisposable</code> gives me a clean way to do this:</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"><span class="keyword">using</span> System.Threading;</span><br><span class="line"><span class="keyword">using</span> System.Threading.Tasks;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">DisposableThread</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">internal</span> <span class="keyword">class</span> <span class="title">Program</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="keyword">string</span>[] args</span>)</span></span><br><span class="line"><span class="function">        </span>&#123;</span><br><span class="line">            <span class="keyword">using</span> (<span class="keyword">new</span> DisposableThread(() =&gt; Console.WriteLine(<span class="string">"DisposableThread running"</span>), <span class="number">100</span>))</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)</span><br><span class="line">                &#123;</span><br><span class="line">                    Console.WriteLine(<span class="string">"Main running"</span>);</span><br><span class="line">                    Thread.Sleep(<span class="number">350</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">DisposableThread</span> : <span class="title">IDisposable</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">readonly</span> CancellationTokenSource _cancellationTokenSource;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">readonly</span> Task _task;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">DisposableThread</span>(<span class="params">Action action, <span class="keyword">int</span> delayMilliseconds</span>)</span></span><br><span class="line"><span class="function">        </span>&#123;</span><br><span class="line">            Console.WriteLine(<span class="string">"DisposableThread started"</span>);</span><br><span class="line"></span><br><span class="line">            _cancellationTokenSource = <span class="keyword">new</span> CancellationTokenSource();</span><br><span class="line">            <span class="keyword">var</span> token = _cancellationTokenSource.Token;</span><br><span class="line"></span><br><span class="line">            _task = Task.Run(<span class="keyword">async</span> () =&gt;</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">while</span> (!token.IsCancellationRequested)</span><br><span class="line">                &#123;</span><br><span class="line">                    action();</span><br><span class="line">                    <span class="keyword">await</span> Task.Delay(delayMilliseconds, token);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;, token);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Dispose</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function">        </span>&#123;</span><br><span class="line">            _cancellationTokenSource.Cancel();</span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                _task.Wait();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">catch</span> (AggregateException)</span><br><span class="line">            &#123;</span><br><span class="line">                Console.WriteLine(<span class="string">"DisposableThread task canceled"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            Console.WriteLine(<span class="string">"DisposableThread disposed"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This produces the output:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">DisposableThread started</span><br><span class="line">Main running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">Main running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">Main running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">Main running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread running</span><br><span class="line">DisposableThread task canceled</span><br><span class="line">DisposableThread disposed</span><br></pre></td></tr></table></figure><p>Essentially, I wrapped the action I needed to do (in this case, a simple print to console <code>() =&gt; Console.WriteLine(&quot;DisposableThread running&quot;</code>) in a task:</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> () =&gt;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> (!token.IsCancellationRequested)</span><br><span class="line">    &#123;</span><br><span class="line">        action();</span><br><span class="line">        <span class="keyword">await</span> Task.Delay(delayMilliseconds, token);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>If you extract this lambda into its own method, it would return a <code>Task</code> encapsulating encapsulating the multiple possible <code>await</code>s. The lambda holds on to the cancellation token <code>token</code> that allows us to act on cancellation requests (which can then be issued by the <code>Dispose()</code> method of <code>IDisposable</code>).</p><p>Additionally, it’s important that we use <code>Task.Delay(delayMilliseconds, token)</code> instead of <code>Thread.Sleep(delayMilliseconds)</code>. This allows us to react to cancellations during the delay instead of after the delay.</p><p>Finally, the dispose method needs to call <code>Task</code>’s <code>Wait()</code>:</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Dispose</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    _cancellationTokenSource.Cancel();</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        _task.Wait();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (AggregateException)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">"DisposableThread task canceled"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Console.WriteLine(<span class="string">"DisposableThread disposed"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>When we call <code>_cancellationTokenSource.Cancel()</code>, we are cancelling the task(s) that hold on to the token. Each of the tasks then throws a <code>TaskCanceledException</code>. This exception is not thrown in the main thread until it’s either handled explicitly or the garbage collector collects and finalizes the object. That means if the <code>TaskCanceledException</code> isn’t handled explicitly and the main thread goes on long enough, we may encounter an exception out of nowhere. Hence, we force the exception (which, like all <code>Task</code> exceptions, gets rolled into an <code>AggregateException</code>) by calling <code>_task.Wait()</code> and catch the exception explicitly.</p><p>This allows me to write better looking code like this:</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> (SessionFactory.PingedSession())</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// interact with session</span></span><br><span class="line">    <span class="comment">// interact more with session</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>without worrying about starting and stopping the background pinging thread.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I wanted a clean way to spin up a looping task in C# and do things while the task is running.&lt;/p&gt;
&lt;p&gt;Conceptually, I want&lt;/p&gt;
&lt;ol style=&quot;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Crude Oil Inventory and Intraday Oil Price Movements</title>
    <link href="http://linanqiu.github.io/2016/06/09/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/"/>
    <id>http://linanqiu.github.io/2016/06/09/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/</id>
    <published>2016-06-10T02:21:50.000Z</published>
    <updated>2016-06-10T02:36:21.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br></pre></td></tr></table></figure><h1 id="motivation">Motivation</h1><p><a href="http://www.wsj.com/articles/oil-at-seven-month-high-as-u-s-stockpiles-drop-1464168624" target="_blank" rel="noopener">News</a> <a href="http://www.marketwatch.com/story/oil-prices-march-past-50-amid-signs-of-us-inventory-falls-2016-06-08" target="_blank" rel="noopener">articles</a> love citing the crude inventory as reasons for movements in oil prices. Quoting from the WSJ:</p><blockquote><p>U.S. inventories are closely watched by traders as the first indicator of the global supply-and-demand balance. Stockpiles have fallen in recent weeks from their highest level in more than 80 years, boosting expectations that the global glut of crude that has weighed on prices for nearly two years is now receding.</p></blockquote><blockquote><p>The U.S. Energy Information Administration said U.S. crude stockpiles fell 4.2 million barrels last week, while analysts polled by The Wall Street Journal had expected a decrease of 2.5 million barrels.</p></blockquote><p>So this got me really curious. How good is the Energy Information Administration (EIA) figure as a predictor of crude oil prices? To test this, I decided to use the following data:</p><ol style="list-style-type: decimal"><li>EIA US Crude Inventory ex-SPR (Strategic Petroleum Reserve). This data (basically the one that WSJ quoted on top) is <strong>usually released every Wednesday afternoon</strong>. This data is going to be a single number for every week.</li><li>US Oil Fund (USO), an ETF that tracks the front month West Texas Intermediate (WTI) futures. This is going to be a set of numbers daily describing the <strong>open, high, low, close</strong> (OHLC) prices. We are most interested in the extent of movement from the beginning of the day (before EIA data is released) to the end of the day (after EIA data is released). Hence, we define <strong>intraday return</strong> as <strong>(close - open) / close</strong> for a specific day. Furthermore, we are probably interested in this figure for <strong>Wednesdays</strong> given that EIA data is released every Wednesday.</li></ol><h1 id="data">Data</h1><p>I pull the data from Thomson Datastream using this <a href="https://github.com/vfilimonov/pydatastream" target="_blank" rel="noopener">wonderful Python interface</a>. If you want to replicate this, you’d need to get yourself some Datastream credentials. Ask your school librarian very nicely. :)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pydatastream</span><br><span class="line"><span class="keyword">from</span> pydatastream <span class="keyword">import</span> Datastream</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> statsmodels.graphics.tsaplots <span class="keyword">as</span> tsaplots</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">credentials = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'credentials.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> credentials_file:</span><br><span class="line">    line = credentials_file.readline().split(<span class="string">','</span>)</span><br><span class="line">    credentials[<span class="string">'username'</span>] = line[<span class="number">0</span>]</span><br><span class="line">    credentials[<span class="string">'password'</span>] = line[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">DWE = Datastream(username=credentials[<span class="string">'username'</span>], password=credentials[<span class="string">'password'</span>])</span><br><span class="line">DWE.raise_on_error = <span class="keyword">False</span></span><br></pre></td></tr></table></figure><p>The crude oil inventory data has the datastream mnemonic <code>EIA2007</code> (trust me it took me like 2 hours to find it.) Then I plot it to inject some pictures into this post (otherwise you’d find it boring right?) Besides everyone likes pictures.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crude_oil_stock = DWE.fetch([<span class="string">'EIA2007'</span>], date_from=<span class="string">'2000-01-01'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line">uso = DWE.get_OHLC(<span class="string">'U:USO'</span>, date_from=<span class="string">'2000-01-01'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crude_oil_stock.plot()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_6_1.svg" alt="svg"><p class="caption">svg</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uso.plot()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_7_1.svg" alt="svg"><p class="caption">svg</p></div><p>Uh oh looks like we don’t have complete data before late 2009. Oh well. We just truncate our analysis then.</p><p>Now let’s subdivide our data into each of the days of the week: Monday till Friday.</p><p>Also, Thomson Datastream’s crude oil stock data seems to be lagged by 2 days. That is, Wednesday’s data seems to only be in the system by Friday. Hence, I shift the inventory data by <code>-2</code> days.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">data = crude_oil_stock.merge(uso, left_index=<span class="keyword">True</span>, right_index=<span class="keyword">True</span>)</span><br><span class="line">data.columns=[<span class="string">'crude_oil_stock'</span>, <span class="string">'uso_close'</span>, <span class="string">'uso_high'</span>, <span class="string">'uso_low'</span>, <span class="string">'uso_open'</span>]</span><br><span class="line">data[<span class="string">'dayofweek'</span>] = data.index.dayofweek</span><br><span class="line">data[<span class="string">'crude_oil_stock'</span>] = data[<span class="string">'crude_oil_stock'</span>].shift(<span class="number">-2</span>)</span><br><span class="line">data = data.dropna()</span><br><span class="line"></span><br><span class="line">data_daily = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    data_daily[dayofweek] = data[data.index.dayofweek == dayofweek]</span><br><span class="line">    data_daily[dayofweek][<span class="string">'uso_intraday_return'</span>] = (data_daily[dayofweek][<span class="string">'uso_close'</span>] - data_daily[dayofweek][<span class="string">'uso_open'</span>]) / data_daily[dayofweek][<span class="string">'uso_open'</span>]</span><br><span class="line">    data_daily[dayofweek][<span class="string">'crude_oil_stock_pct'</span>] = data_daily[dayofweek][<span class="string">'crude_oil_stock'</span>].pct_change()</span><br><span class="line">    data_daily[dayofweek][<span class="string">'crude_oil_stock_diff'</span>] = data_daily[dayofweek][<span class="string">'crude_oil_stock'</span>].diff()</span><br><span class="line">    data_daily[dayofweek] = data_daily[dayofweek].dropna()</span><br></pre></td></tr></table></figure><p>We have all the fields that we need for our analysis. They should be pretty self explanatory.</p><h1 id="analysis">Analysis</h1><p>First we do scatter plots of <code>crude_oil_stock_pct</code>, the percent change of this week’s crude inventory stock on last week’s inventory stock, on <code>uso_intraday_return</code>, the intraday return. Turns out not much of a relationship exists:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    data_daily[dayofweek].plot(kind=<span class="string">'scatter'</span>, x=<span class="string">'crude_oil_stock_pct'</span>, y=<span class="string">'uso_intraday_return'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_0.svg" alt="svg"><p class="caption">svg</p></div><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_1.svg" alt="svg"><p class="caption">svg</p></div><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_2.svg" alt="svg"><p class="caption">svg</p></div><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_3.svg" alt="svg"><p class="caption">svg</p></div><div class="figure"><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_4.svg" alt="svg"><p class="caption">svg</p></div><p>When I ran OLS regressions on each of them, not only are the R-squared pathetic, the slopes are in entirely wrong direction as well. For example, the slope for Wednesdays is 0.734359432686, which means that oil prices tend to increase intraday when the inventory increases.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    model = sm.ols(formula=<span class="string">'uso_intraday_return ~ crude_oil_stock_pct'</span>, data=data_daily[dayofweek])</span><br><span class="line">    results = model.fit()</span><br><span class="line">    print(<span class="string">'Day Of Week '</span> + str(dayofweek))</span><br><span class="line">    print(<span class="string">'Slope '</span> + str(results.params.crude_oil_stock_pct))</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Day Of Week 0</span><br><span class="line">Slope 0.0959621772799</span><br><span class="line">Day Of Week 1</span><br><span class="line">Slope -0.202762367053</span><br><span class="line">Day Of Week 2</span><br><span class="line">Slope 0.734359432686</span><br><span class="line">Day Of Week 3</span><br><span class="line">Slope 0.482402080895</span><br><span class="line">Day Of Week 4</span><br><span class="line">Slope 0.179556901751</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    model = sm.ols(formula=<span class="string">'uso_intraday_return ~ crude_oil_stock_pct'</span>, data=data_daily[dayofweek])</span><br><span class="line">    results = model.fit()</span><br><span class="line">    print(<span class="string">'Day Of Week '</span> + str(dayofweek))</span><br><span class="line">    print(<span class="string">''</span>)</span><br><span class="line">    print(results.summary())</span><br></pre></td></tr></table></figure><pre><code>Day Of Week 0                             OLS Regression Results                            ===============================================================================Dep. Variable:     uso_intraday_return   R-squared:                       0.001Model:                             OLS   Adj. R-squared:                 -0.002Method:                  Least Squares   F-statistic:                    0.2613Date:                 Thu, 09 Jun 2016   Prob (F-statistic):              0.610Time:                         22:34:39   Log-Likelihood:                 932.68No. Observations:                  329   AIC:                            -1861.Df Residuals:                      327   BIC:                            -1854.Df Model:                            1                                         Covariance Type:             nonrobust                                         =======================================================================================                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]---------------------------------------------------------------------------------------Intercept              -0.0001      0.001     -0.177      0.859        -0.002     0.001crude_oil_stock_pct     0.0960      0.188      0.511      0.610        -0.273     0.465==============================================================================Omnibus:                       46.601   Durbin-Watson:                   1.846Prob(Omnibus):                  0.000   Jarque-Bera (JB):              268.062Skew:                           0.364   Prob(JB):                     6.18e-59Kurtosis:                       7.362   Cond. No.                         239.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.Day Of Week 1                             OLS Regression Results                            ===============================================================================Dep. Variable:     uso_intraday_return   R-squared:                       0.003Model:                             OLS   Adj. R-squared:                  0.000Method:                  Least Squares   F-statistic:                     1.144Date:                 Thu, 09 Jun 2016   Prob (F-statistic):              0.285Time:                         22:34:39   Log-Likelihood:                 1035.4No. Observations:                  359   AIC:                            -2067.Df Residuals:                      357   BIC:                            -2059.Df Model:                            1                                         Covariance Type:             nonrobust                                         =======================================================================================                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]---------------------------------------------------------------------------------------Intercept               0.0002      0.001      0.302      0.763        -0.001     0.002crude_oil_stock_pct    -0.2028      0.190     -1.070      0.285        -0.576     0.170==============================================================================Omnibus:                        8.913   Durbin-Watson:                   1.929Prob(Omnibus):                  0.012   Jarque-Bera (JB):               14.310Skew:                          -0.117   Prob(JB):                     0.000781Kurtosis:                       3.950   Cond. No.                         265.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.Day Of Week 2                             OLS Regression Results                            ===============================================================================Dep. Variable:     uso_intraday_return   R-squared:                       0.028Model:                             OLS   Adj. R-squared:                  0.026Method:                  Least Squares   F-statistic:                     10.44Date:                 Thu, 09 Jun 2016   Prob (F-statistic):            0.00134Time:                         22:34:39   Log-Likelihood:                 963.67No. Observations:                  359   AIC:                            -1923.Df Residuals:                      357   BIC:                            -1916.Df Model:                            1                                         Covariance Type:             nonrobust                                         =======================================================================================                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]---------------------------------------------------------------------------------------Intercept            4.491e-05      0.001      0.051      0.959        -0.002     0.002crude_oil_stock_pct     0.7344      0.227      3.232      0.001         0.287     1.181==============================================================================Omnibus:                       18.131   Durbin-Watson:                   2.048Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.969Skew:                           0.335   Prob(JB):                     3.11e-07Kurtosis:                       4.247   Cond. No.                         260.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.Day Of Week 3                             OLS Regression Results                            ===============================================================================Dep. Variable:     uso_intraday_return   R-squared:                       0.014Model:                             OLS   Adj. R-squared:                  0.012Method:                  Least Squares   F-statistic:                     5.126Date:                 Thu, 09 Jun 2016   Prob (F-statistic):             0.0242Time:                         22:34:39   Log-Likelihood:                 968.11No. Observations:                  352   AIC:                            -1932.Df Residuals:                      350   BIC:                            -1924.Df Model:                            1                                         Covariance Type:             nonrobust                                         =======================================================================================                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]---------------------------------------------------------------------------------------Intercept              -0.0004      0.001     -0.500      0.618        -0.002     0.001crude_oil_stock_pct     0.4824      0.213      2.264      0.024         0.063     0.901==============================================================================Omnibus:                       32.562   Durbin-Watson:                   2.031Prob(Omnibus):                  0.000   Jarque-Bera (JB):              120.200Skew:                          -0.274   Prob(JB):                     7.92e-27Kurtosis:                       5.810   Cond. No.                         258.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.Day Of Week 4                             OLS Regression Results                            ===============================================================================Dep. Variable:     uso_intraday_return   R-squared:                       0.003Model:                             OLS   Adj. R-squared:                 -0.000Method:                  Least Squares   F-statistic:                    0.8663Date:                 Thu, 09 Jun 2016   Prob (F-statistic):              0.353Time:                         22:34:39   Log-Likelihood:                 991.29No. Observations:                  347   AIC:                            -1979.Df Residuals:                      345   BIC:                            -1971.Df Model:                            1                                         Covariance Type:             nonrobust                                         =======================================================================================                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]---------------------------------------------------------------------------------------Intercept               0.0009      0.001      1.153      0.250        -0.001     0.002crude_oil_stock_pct     0.1796      0.193      0.931      0.353        -0.200     0.559==============================================================================Omnibus:                       56.151   Durbin-Watson:                   2.035Prob(Omnibus):                  0.000   Jarque-Bera (JB):              254.440Skew:                           0.577   Prob(JB):                     5.61e-56Kurtosis:                       7.033   Cond. No.                         258.==============================================================================Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><h1 id="conclusion">Conclusion</h1><p>EIA inventory data is probably a weak predictor in and of itself. We can add more factors (momentum, etc) but the correlation’s definitely not as clear cut as most news agencies would like to claim.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>OPT I-765 Processing Time</title>
    <link href="http://linanqiu.github.io/2016/05/24/OPT-I-765-Processing-Time/"/>
    <id>http://linanqiu.github.io/2016/05/24/OPT-I-765-Processing-Time/</id>
    <published>2016-05-24T18:51:45.000Z</published>
    <updated>2016-05-24T18:58:58.000Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br></pre></td></tr></table></figure><h1 id="overview">Overview</h1><p>Students under the F-1 visa usually apply for Optional Practical Training (OPT) to get work authorization from US Citizenship and Immigration Services (USCIS) for internships / jobs. It is also the ultimate test of one’s patience. Even after one has braved the inane paperworks and countless trips to advisors / international student offices, one would still have to wait up to 90 days for the authorization approval. <strong>What makes this wait worse is the lack of updates during the wait.</strong> When one applies for OPT (and the application is received by USCIS), one gets a receipt number. Using this receipt number to check one’s progress (at <a href="https://egov.uscis.gov/casestatus/mycasestatus.do" class="uri" target="_blank" rel="noopener">https://egov.uscis.gov/casestatus/mycasestatus.do</a>) is highly unsatisfying. Until the work authorization is approved (or God forbid rejected / put on hold for additional evidence), one is faced with rather useless description that reads something like this:</p><blockquote><p>‘On February 22, 2016, we received your Form I-765, Application for Employment Authorization , Receipt Number EAC1690120079, and sent you the receipt notice that describes how we will process your case. Please follow the instructions in the notice. If you do not receive your receipt notice by March 23, 2016, please call Customer Service at 1-800-375-5283. If you move, go to www.uscis.gov/addresschange to give us your new mailing address.’</p></blockquote><p>USCIS does a really bad job of keeping one updated on the progress of a case and in general how far along they are going with the entire year’s batch of students.</p><p><strong>Fortunately, we can do better.</strong></p><h1 id="receipt-numbers">Receipt Numbers</h1><p>USCIS issues receipt numbers in chronological order. That means if I submitted my application on March 1, 2016 and I got the number YSC1690079958, the next person to submit his application gets the number YSC169007995<strong>9</strong>. The person before me gets the number YSC169007995<strong>7</strong>. Using this fact, I can see how people before and after me are doing. USCIS also states that the cases are processed in a first-come-first-serve order.</p><ul><li>If a huge proportion of people before (and possibly after) me have their OPTs approved, I should have mine processed soon.</li><li>However, if the people who submitted around my date are stil waiting for their approval, I can expect to wait a long time.</li></ul><p>However, doing so manually at [https://egov.uscis.gov/casestatus/mycasestatus.do(https://egov.uscis.gov/casestatus/mycasestatus.do) is a slow and tiring process. Instead, I can write a script to “scrape” the website for the 50,000 or so cases before and after my own number.</p><blockquote><p>Additional note: This year, there are two USCIS centers processing OPT applications – the Vermont office and the Potomac office. The Potomac office opened later in the cycle (around March) to help with the application volume. <a href="https://www.uscis.gov/news/potomac-service-center-now-processing-certain-form-i-765-cases" class="uri" target="_blank" rel="noopener">https://www.uscis.gov/news/potomac-service-center-now-processing-certain-form-i-765-cases</a>. Applications that are sent to the Vermont office first have the prefix <code>EAC</code>. Those may be then routed to the Potomac office. Applications that are sent in late March and later are sent directly to the Potomac office, giving them the prefix <code>YSC</code>. This means that when I scrape the pages for data, I have to account for both prefixes.</p></blockquote><p>I planned to scrape receipt numbers <code>EAC1690120000</code> to <code>EAC1690180000</code> and <code>YSC1690040000</code> to <code>YSC1690080000</code>. This should give me a good sense of applications submitted in the February to April period.</p><h1 id="scraping">Scraping</h1><h2 id="ip-blocking">IP Blocking</h2><p>I first wrote a simple <code>Node.JS</code> script to do this. I didn’t use <code>python</code> because <code>async</code> in <code>python</code> is a pain in the ass.</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">'cheerio'</span>);</span><br><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">'request'</span>);</span><br><span class="line"><span class="keyword">var</span> <span class="keyword">async</span> = <span class="built_in">require</span>(<span class="string">'async'</span>);</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"><span class="keyword">var</span> stringify = <span class="built_in">require</span>(<span class="string">'csv-stringify'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> URL = <span class="string">'https://egov.uscis.gov/casestatus/mycasestatus.do?appReceiptNum=RECEIPT_NUM'</span>;</span><br><span class="line"><span class="keyword">var</span> PREFIX = <span class="string">'EAC'</span>;</span><br><span class="line"><span class="keyword">var</span> START_NUMBER = <span class="number">1690120000</span>;</span><br><span class="line"><span class="keyword">var</span> END_NUMBER = <span class="number">1690180000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> receiptNumbers = [];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = START_NUMBER; i &lt; END_NUMBER; i++) &#123;</span><br><span class="line">  receiptNumbers.push(PREFIX + i);</span><br><span class="line">&#125;</span><br><span class="line">fs.writeFileSync(<span class="string">'raw_data.csv'</span>, <span class="string">'receipt,title,text\n'</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">retrieveReceiptNumber</span>(<span class="params">receiptNumber, callback</span>) </span>&#123;</span><br><span class="line">  request(&#123;</span><br><span class="line">      url: URL.replace(<span class="string">'RECEIPT_NUM'</span>, receiptNumber),</span><br><span class="line">      rejectUnauthorized: <span class="literal">false</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="keyword">function</span> (<span class="params">err, resp, body</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="built_in">console</span>.error(err);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(body);</span><br><span class="line">      <span class="keyword">var</span> title = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'h1'</span>).text();</span><br><span class="line">      <span class="keyword">var</span> description = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'p'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> violation = $(<span class="string">'label[for=accessviolation]'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (title.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (violation.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="built_in">console</span>.log(<span class="string">'access violation'</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        callback();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> row = [</span><br><span class="line">          [receiptNumber, title, description]</span><br><span class="line">        ];</span><br><span class="line"></span><br><span class="line">        stringify(row, <span class="function"><span class="keyword">function</span> (<span class="params">err, output</span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (err) &#123;</span><br><span class="line">            <span class="built_in">console</span>.error(err);</span><br><span class="line">          &#125;</span><br><span class="line">          fs.appendFile(<span class="string">'raw_data.csv'</span>, output, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (err) &#123;</span><br><span class="line">              <span class="built_in">console</span>.error(err);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">console</span>.log(receiptNumber + <span class="string">' written'</span>);</span><br><span class="line">            callback();</span><br><span class="line">          &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span>.eachLimit(receiptNumbers, <span class="number">100</span>, retrieveReceiptNumber, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'DONE'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="scrapoxy">Scrapoxy</h2><p>USCIS (unsurprisingly) blocked my IP after around 2,000 queries. So I needed a way to get around the IP blocking. Fortunately, an easy solution was available: <a href="http://scrapoxy.io/" class="uri" target="_blank" rel="noopener">http://scrapoxy.io/</a>. Scrapoxy manages a pool of EC2 / DigitalOcean instances for you (afte some setting up) and provides a single local port for you as a proxy. This allows you to route your requests through the multiple cloud instances. This lowers the likelihood of a single IP getting blocked. (Even if one gets blocked, you can simply kill the instance and restart it. I didn’t have to do this, sine none of the cloud instances got blocked). After setting up Scrapoxy and running the proxy at <code>http://localhost:8888</code>, I can pass this easily to the <code>request</code> module in my script:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">'cheerio'</span>);</span><br><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">'request'</span>);</span><br><span class="line"><span class="keyword">var</span> <span class="keyword">async</span> = <span class="built_in">require</span>(<span class="string">'async'</span>);</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"><span class="keyword">var</span> stringify = <span class="built_in">require</span>(<span class="string">'csv-stringify'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> URL = <span class="string">'https://egov.uscis.gov/casestatus/mycasestatus.do?appReceiptNum=RECEIPT_NUM'</span>;</span><br><span class="line"><span class="keyword">var</span> PREFIX = <span class="string">'EAC'</span>;</span><br><span class="line"><span class="keyword">var</span> START_NUMBER = <span class="number">1690149000</span>;</span><br><span class="line"><span class="keyword">var</span> END_NUMBER = <span class="number">1690180000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> receiptNumbers = [];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = START_NUMBER; i &lt; END_NUMBER; i++) &#123;</span><br><span class="line">  receiptNumbers.push(PREFIX + i);</span><br><span class="line">&#125;</span><br><span class="line">fs.writeFileSync(<span class="string">'raw_data.csv'</span>, <span class="string">'receipt,title,text\n'</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">retrieveReceiptNumber</span>(<span class="params">receiptNumber, callback</span>) </span>&#123;</span><br><span class="line">  request(&#123;</span><br><span class="line">      url: URL.replace(<span class="string">'RECEIPT_NUM'</span>, receiptNumber),</span><br><span class="line">      rejectUnauthorized: <span class="literal">false</span>,</span><br><span class="line">      proxy: <span class="string">'http://localhost:8888'</span>,</span><br><span class="line">      tunnel: <span class="literal">false</span> <span class="comment">// remember to set tunnel to false</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="keyword">function</span> (<span class="params">err, resp, body</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="built_in">console</span>.error(err);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(body);</span><br><span class="line">      <span class="keyword">var</span> title = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'h1'</span>).text();</span><br><span class="line">      <span class="keyword">var</span> description = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'p'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> violation = $(<span class="string">'label[for=accessviolation]'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (title.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (violation.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="built_in">console</span>.log(<span class="string">'access violation'</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        callback();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> row = [</span><br><span class="line">          [receiptNumber, title, description]</span><br><span class="line">        ];</span><br><span class="line"></span><br><span class="line">        stringify(row, <span class="function"><span class="keyword">function</span> (<span class="params">err, output</span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (err) &#123;</span><br><span class="line">            <span class="built_in">console</span>.error(err);</span><br><span class="line">          &#125;</span><br><span class="line">          fs.appendFile(<span class="string">'raw_data.csv'</span>, output, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (err) &#123;</span><br><span class="line">              <span class="built_in">console</span>.error(err);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">console</span>.log(receiptNumber + <span class="string">' written'</span>);</span><br><span class="line">            callback();</span><br><span class="line">          &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span>.eachLimit(receiptNumbers, <span class="number">100</span>, retrieveReceiptNumber, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'DONE'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>The changes are in the options object passed to <code>request</code>:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  url: URL.replace(<span class="string">'RECEIPT_NUM'</span>, receiptNumber),</span><br><span class="line">  rejectUnauthorized: <span class="literal">false</span>,</span><br><span class="line">  proxy: <span class="string">'http://localhost:8888'</span>,</span><br><span class="line">  tunnel: <span class="literal">false</span> <span class="comment">// remember to set tunnel to false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This allows me to scrape the receipt numbers very quickly within the hour. (see the <code>eachLimit</code> for <code>async</code>? I’m making 100 requests at any time through the proxy). I collected the scraped results into <code>raw_data_eac.csv</code> and <code>raw_data_ysc.csv</code> for the two prefixes.</p><p>Now let’s analyze them.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> pandas</span><br></pre></td></tr></table></figure><h1 id="parsing-data">Parsing Data</h1><p>Earlier, I only scraped the raw data from the pages. Hence, I only have the <code>receipt</code> (receipt number), <code>title</code> (the short line of text displayed at the top of each case status) and <code>text</code> (the full text of the case status). This is hardly useful.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_eac = pandas.read_csv(<span class="string">'raw_data_eac.csv'</span>)</span><br><span class="line">data_ysc = pandas.read_csv(<span class="string">'raw_data_ysc.csv'</span>)</span><br><span class="line">data = data_eac.append(data_ysc)</span><br></pre></td></tr></table></figure><p>I can use this information to create a <code>status</code> for each receipt number. I’m using a lot of simplifying assupmtions here and disregarding a lot of corner cases (USCIS sometimes requests additional evidence, does weird thing with cases etc.) In fact, let’s take a look at the vaious case <code>title</code>s:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(data.groupby(<span class="string">'title'</span>).count()[<span class="string">'receipt'</span>])</span><br></pre></td></tr></table></figure><pre><code>titleAmended Notice Was Mailed                                                             8Appeal Was Dismissed                                                                  9Card Is Being Returned to USCIS by Post Office                                       10Card Returned Undeliverable                                                           4Card Was Delivered To Me By The Post Office                                       11434Card Was Determined As Undeliverable By The Post Office                              26Card Was Mailed To Me                                                              2045Card Was Picked Up By The United States Postal Service                              162Card Was Received By USCIS Along With My Letter                                       4Card Was Returned And USCIS Is Holding It For One Year                               20Card Was Returned To USCIS By Post Office                                             7Case Is Pending at a Local Office                                                   449Case Rejected Because I Sent An Incorrect Fee                                      1942Case Rejected Because The Version Of The Form I Sent Is No Longer Accepted           64Case Rejected For Form Not Signed And Incorrect Form Version                         38Case Rejected For Incorrect Fee And Form Not Signed                                  94Case Rejected For Incorrect Fee, Payment Not Signed And Incorrect Form Version       10Case Terminated Benefit Received By Other Means                                      35Case Transferred And New Office Has Jurisdiction                                      1Case Transferred To Another Office                                                 1068Case Was Approved                                                                  4558Case Was Received                                                                 63510Case Was Received At My Local Office                                               6210Case Was Rejected                                                                    81Case Was Rejected Because I Did Not Sign My Form                                    836Case Was Rejected Because It Was Improperly Filed                                  1291Case Was Reopened                                                                    11Case Was Reopened For Reconsideration                                                 1Case Was Sent To The Department of State                                          10569Case Was Transferred And A New Office Has Jurisdiction                            14926Case Was Transferred To An Asylum Office                                              1Case Was Transferred To Schedule An Interview                                         1Correspondence Was Received And USCIS Is Reviewing It                               133Date of Birth Was Updated                                                           236Decision Notice Mailed                                                              169Document Was Mailed To Me                                                             2Duplicate Notice Was Mailed                                                          15Fee Refund Was Mailed                                                                 2Fee Was Not Corrected                                                                 1Fee Will Be Refunded                                                                  2Fees Were Waived                                                                    249Fingerprint Fee Has Issues That Need To Be Fixed                                      8Fingerprint Fee Was Received                                                        577Name Was Updated                                                                   1245New Card Is Being Produced                                                         1862Notice Explaining USCIS&#39; Actions Was Mailed                                         179Notice Was Returned To USCIS Because The Post Office Could Not Deliver It           365Payment Fee Was Returned For Insufficient Funds                                      41Receipt Notice Was Changed                                                           58Request for Additional Evidence Was Mailed                                          861Request for Initial Evidence Was Mailed                                            3262Response To USCIS&#39; Request For Evidence Was Received                                940Withdrawal Acknowledgement Notice Was Sent                                           24Name: receipt, dtype: int64</code></pre><p>I ignore most of the corner cases and only look at a few larger categories:</p><ul><li>If the word <code>I-765</code> appears in the <code>text</code> of a case (since we are only looking at OPT cases), and <code>Case Was Received</code> is in the <code>title</code>, then the case is still processing. This happens when USCIS receives the case. Most people enduring the long 60 to 90 day wait will see this.</li><li>If the word <code>I-765</code> appears in the <code>text</code> of a case, and <code>Case Was Transferred</code> is in the <code>title</code>, then the case was probably submitted to the Vermont office first then routed to the Potomac office. This is still <code>processing</code> as well.</li><li>If the word <code>I-765</code> appears in the <code>text</code> of a case, and <code>Case Was Rejected</code>, well sucks for you. The case is rejected.</li><li>If the word <code>I-765</code> appears in the <code>text</code> of a case and <code>Case Was Approved</code>, congratulations! Your case is approved.</li><li>Even better, if a card is made and being delieverd, you’d have the <code>Card Was Delivered To Me By The Post Office</code> in the <code>title</code> of the case.</li></ul><p>I make a silly function for this and iterate over each row of the dataframe.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_status</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Received'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'processing'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Transferred'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'processing'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Rejected'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'rejected'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Approved'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'approved'</span></span><br><span class="line">    <span class="keyword">if</span> row[<span class="string">'title'</span>] == <span class="string">'Card Was Delivered To Me By The Post Office'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'approved'</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line">data[<span class="string">'status'</span>] = data.apply(gen_status, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>Now here’s a slightly harder part. Only in the <code>Case Was Received</code> cases do we have a <strong>submission date</strong> for the OPT application. For the others (approved or rejected) the case status <code>text</code> only contains the date that the case was approved (which I am really not interested in for now). I want to know when those cases are <strong>submitted</strong>. Fortunately, I can again exploit the fact that the numbers are in increasing order. When the date of a case cannot be determined, I simply look backwards (to earlier receipt numbers) to the last known date of a still processing case. This gives me a good approximation of the submission dates of approved / rejected cases.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line">pattern = re.compile(<span class="string">'On ([A-z]+ [0-9]+, [0-9]+),'</span>)</span><br><span class="line"></span><br><span class="line">last_date = <span class="keyword">None</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_date</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> row[<span class="string">'status'</span>] == <span class="string">'processing'</span>:</span><br><span class="line">        m = pattern.search(row[<span class="string">'text'</span>])</span><br><span class="line">        <span class="keyword">global</span> last_date</span><br><span class="line">        last_date = numpy.datetime64(pandas.Timestamp(m.group(<span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">return</span> last_date</span><br><span class="line">    <span class="keyword">return</span> last_date</span><br><span class="line"></span><br><span class="line">data[<span class="string">'date'</span>] = data.apply(extract_date, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h1 id="results">Results</h1><p>Now I can look at the results. First, I group the data by the <code>date</code> column. Cases (rows) with the same date will be grouped together. Then, for each date, I count the number of <code>processing</code>, <code>approved</code>, and <code>rejected</code> cases.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = pandas.DataFrame(data[data[<span class="string">'status'</span>] == <span class="string">'processing'</span>].groupby(<span class="string">'date'</span>)[<span class="string">'receipt'</span>].count())</span><br><span class="line">result[<span class="string">'approved'</span>] = data[data[<span class="string">'status'</span>] == <span class="string">'approved'</span>].groupby(<span class="string">'date'</span>)[<span class="string">'receipt'</span>].count()</span><br><span class="line">result[<span class="string">'rejected'</span>] = data[data[<span class="string">'status'</span>] == <span class="string">'rejected'</span>].groupby(<span class="string">'date'</span>)[<span class="string">'receipt'</span>].count()</span><br><span class="line">result.columns = [<span class="string">'Processing'</span>, <span class="string">'Approved'</span>, <span class="string">'Rejected'</span>]</span><br></pre></td></tr></table></figure><p>And I make a silly plot.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x111202358&gt;</code></pre><div class="figure"><img src="/images/OPT-I-765-Processing-Time/output_17_1.svg" alt="svg"><p class="caption">svg</p></div><p>Here’s how to interpret this data. I can see that most of the cases submitted in February and early March are already processed. The ones submitted in later March are around 50% processed. The ones submitted in late March (like mine) are beginning to get approved.</p><p>For each date, I can see the number of cases approved, rejected, processing etc.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.loc[<span class="string">'2016-03-30'</span>]</span><br></pre></td></tr></table></figure><pre><code>Processing    2069.0Approved       328.0Rejected         5.0Name: 2016-03-30 00:00:00, dtype: float64</code></pre><p>I can make this more readable by dividing the number of approved cases by the total number of processing, approved, and rejected cases.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result[<span class="string">'Total'</span>] = result[<span class="string">'Processing'</span>] + result[<span class="string">'Approved'</span>] + result[<span class="string">'Rejected'</span>]</span><br><span class="line">result[<span class="string">'Approved Proportion'</span>] = result[<span class="string">'Approved'</span>] / result[<span class="string">'Total'</span>]</span><br><span class="line">result[<span class="string">'Approved Proportion'</span>].plot()</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11131ee10&gt;</code></pre><div class="figure"><img src="/images/OPT-I-765-Processing-Time/output_21_1.svg" alt="svg"><p class="caption">svg</p></div><p>I really don’t understand why USCIS would not release this data (since it will help calm the nerves of so many international students). I do hope that this will help calm your nerves though as it did calm mine.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
    
      <category term="data" scheme="http://linanqiu.github.io/tags/data/"/>
    
      <category term="opt" scheme="http://linanqiu.github.io/tags/opt/"/>
    
      <category term="uscis" scheme="http://linanqiu.github.io/tags/uscis/"/>
    
      <category term="scraping" scheme="http://linanqiu.github.io/tags/scraping/"/>
    
  </entry>
  
  <entry>
    <title>Running Word Embedding on Piazza Posts</title>
    <link href="http://linanqiu.github.io/2016/04/22/Running-Word-Embedding-on-Piazza-Posts/"/>
    <id>http://linanqiu.github.io/2016/04/22/Running-Word-Embedding-on-Piazza-Posts/</id>
    <published>2016-04-22T07:08:07.000Z</published>
    <updated>2016-04-22T07:24:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>Word embedding (very bad explanation follows) is translating each word in a corpus into a D dimension vector. These vectors are supposed to preserve semantic properties and are commonly used in NLP. For example, in a large corpus of words (say the google news corpus), the vector point for man <span class="math inline">\(v\_{king}\)</span> should be near the vector point for <span class="math inline">\(v\_{queen}\)</span>. Furthermore, meaning such as “king is to man as queen is to woman” is preserved via <span class="math inline">\(v\_{king} - v\_{queen} \approx v\_{man} - v\_{queen}\)</span>. These embeddings are generated via neural networks and a common tool for doing this is Word2Vec produced by <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Mikolov et al</a>. A fast implementation of Word2Vec is available in gensim.</p><p>For more reading, read <a href="https://www.wikiwand.com/en/Word2vec" target="_blank" rel="noopener">the wiki</a> or the paper itself. For interesting experiments, read these:</p><ul><li><a href="http://instagram-engineering.tumblr.com/post/117889701472/emojineering-part-1-machine-learning-for-emoji" target="_blank" rel="noopener">Running Word2Vec on Instagram Emojis</a></li><li><a href="http://textminingonline.com/training-word2vec-model-on-english-wikipedia-by-gensim" target="_blank" rel="noopener">Word2Vec on English Wiki</a></li><li>And, shamelessly, my favorite because I wrote it <a href="https://github.com/linanqiu/word2vec-sentiments" target="_blank" rel="noopener">Sentiment Analysis using Word2Vec</a></li></ul><p>Won’t it be fun to run this on Piazza posts? I’m a TA for data structures this semester (for Prof Blaer and Prof Bauer) and we have a Piazza containing 800 posts (ripe with answers, followups, etc). Speaking of that, we have an average response time of 5min. Find me another team of TAs that can beat this hurhhurh.</p><h1 id="creating-corpus">Creating Corpus</h1><p>Turns out Piazza does not have an official API. However, there is an unofficial API. <a href="https://github.com/hfaran/piazza-api" class="uri" target="_blank" rel="noopener">https://github.com/hfaran/piazza-api</a> That’s good enough for us.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> piazza_api <span class="keyword">import</span> Piazza</span><br><span class="line">piazza = Piazza()</span><br><span class="line">piazza.user_login()</span><br></pre></td></tr></table></figure><pre><code>Email: lq2137@columbia.edu········</code></pre><p>Now let’s grab all the posts as <code>.json</code>s.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">course = piazza.network(<span class="string">'ijfyurrye2g1oc'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">posts = course.iter_all_posts()</span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> post <span class="keyword">in</span> posts:</span><br><span class="line">    <span class="keyword">if</span> count % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Downloading post %d'</span> % count</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'%d.json'</span> % count, <span class="string">'w'</span>) <span class="keyword">as</span> csv_file:</span><br><span class="line">        csv_file.write(json.dumps(post))</span><br><span class="line">    count += <span class="number">1</span></span><br></pre></td></tr></table></figure><pre><code>Downloading post 0Downloading post 100Downloading post 200Downloading post 300Downloading post 400Downloading post 500Downloading post 600Downloading post 700Downloading post 800</code></pre><p>Then we parse the <code>.json</code>s into a giant <code>.txt</code> by unscrambling the messy <code>.json</code> that the API provides. We also tokenize and perform some basic cleaning (mash everything to lower case). This is a very blunt tool, but should suffice for now.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> word_tokenize</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grab_children</span><span class="params">(post)</span>:</span></span><br><span class="line">    content_children = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">traverse</span><span class="params">(children)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> children:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'history'</span> <span class="keyword">in</span> child:</span><br><span class="line">                history = child[<span class="string">'history'</span>]</span><br><span class="line">                content_children.extend([history_item[<span class="string">'content'</span>] <span class="keyword">for</span> history_item <span class="keyword">in</span> history])</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'children'</span> <span class="keyword">in</span> child:</span><br><span class="line">                traverse(child[<span class="string">'children'</span>])</span><br><span class="line">    traverse(post[<span class="string">'children'</span>])</span><br><span class="line">    <span class="keyword">return</span> content_children</span><br><span class="line"></span><br><span class="line">corpus = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> glob_file <span class="keyword">in</span> glob.glob(<span class="string">'*.json'</span>):</span><br><span class="line">    <span class="keyword">with</span> open(glob_file, <span class="string">'r'</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        post = json.load(json_file)</span><br><span class="line">        content = [history[<span class="string">'content'</span>] <span class="keyword">for</span> history <span class="keyword">in</span> post[<span class="string">'history'</span>]]</span><br><span class="line">        content.extend(grab_children(post))</span><br><span class="line">        content = [BeautifulSoup(text, <span class="string">'html.parser'</span>).get_text() <span class="keyword">for</span> text <span class="keyword">in</span> content]</span><br><span class="line">        content = [word_tokenize(text.lower()) <span class="keyword">for</span> text <span class="keyword">in</span> content]</span><br><span class="line">        corpus.extend(content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'corpus.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> corpus_file:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> corpus:</span><br><span class="line">        corpus_file.write(<span class="string">'%s\n'</span> % <span class="string">' '</span>.join(line).strip().encode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure><h1 id="training-the-model">Training the Model</h1><p>Now let’s train the model using <code>gensim</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gensim.models.word2vec <span class="keyword">as</span> word2vec</span><br></pre></td></tr></table></figure><p>Turns out <code>gensim</code> has a nice reader that iterates over a text file with one sentence a line. That’s exactly what we produced in the corpus section.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentences = word2vec.LineSentence(<span class="string">'corpus.txt'</span>)</span><br></pre></td></tr></table></figure><p>Now let’s train the model on this corpus. These are some hyperparameters that I found to be good. I shan’t explain them too much, but if you want a little more detail we are essentially using the Skip-Gram with Negative Sampling portion of Word2Vec over 100 iterations and a Skip-Gram window of 15. We also discard all words that occur few than 5 times.</p><p>This should take no more than a minute since the corpus is tiny (which theoretically should give us crappy results but let’s see.)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = word2vec.Word2Vec(sentences, min_count=<span class="number">5</span>, workers=<span class="number">8</span>, iter=<span class="number">100</span>, window=<span class="number">15</span>, size=<span class="number">300</span>, negative=<span class="number">25</span>)</span><br></pre></td></tr></table></figure><h1 id="results">Results</h1><p>Now let’s look at some results.</p><p>The <code>most_similar</code> method takes in a word, converts it to its vector representation, and finds the other words that are closest to it by cosine distance. These similar words should have been used in a similar context with the original word. Let’s find some interesting results.</p><p>First, let’s do a sanity check using the word <code>homework</code>. Turns out <code>homework</code> is indeed associated with words we’d expect to be associated with <code>homework</code>: <code>solutions</code>, <code>grade</code>, <code>email</code>, and even <code>latex</code>. That’s good.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'homework'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;solutions&#39;, 0.3142701983451843), (u&#39;grade&#39;, 0.3114492893218994), (u&#39;email&#39;, 0.3077431321144104), (u&#39;inserted&#39;, 0.3056461215019226), (u&#39;description&#39;, 0.2953464388847351), (u&#39;programming&#39;, 0.2912822961807251), (u&#39;latex&#39;, 0.2862958312034607), (u&#39;theorem&#39;, 0.28351300954818726), (u&#39;signature&#39;, 0.2821905314922333), (u&#39;posts&#39;, 0.28168296813964844)]</code></pre><p>Now for something more advanced. Let’s try the word <code>heap</code>. Turns out we have words that are pretty related to the <code>heap</code> concept:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'heap'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;build&#39;, 0.30242919921875), (u&#39;percolatedown&#39;, 0.2909688353538513), (u&#39;one-by-one&#39;, 0.28867167234420776), (u&#39;deletion&#39;, 0.2867096960544586), (u&#39;k&#39;, 0.28530699014663696), (u&#39;discussed&#39;, 0.2748313546180725), (u&#39;linear&#39;, 0.26605361700057983), (u&#39;increasing&#39;, 0.2620879113674164), (u&#39;quicksort&#39;, 0.25420695543289185), (u&#39;instructions&#39;, 0.2464582324028015)]</code></pre><p>Now for the most awesome result ever. What concepts are associated with <code>good</code>? Turns out I’m one of them.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'good'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;great&#39;, 0.35192880034446716), (u&#39;very&#39;, 0.3159177303314209), (u&#39;almost&#39;, 0.30515187978744507), (u&#39;concepts&#39;, 0.3004434108734131), (u&#39;linan&#39;, 0.2995752990245819), (u&#39;too&#39;, 0.2964840829372406), (u&#39;basic&#39;, 0.2916448712348938), (u&#39;fit&#39;, 0.28502458333969116), (u&#39;useful&#39;, 0.2824944257736206), (u&#39;answered&#39;, 0.28173112869262695)]</code></pre><div class="figure"><img src="https://cdn.thinglink.me/api/image/727110550026190849/1240/10/scaletowidth" alt="doge"><p class="caption">doge</p></div><p>Let’s see what’s similar to the profs. Turns out Prof Blaer’s love for <code>ocaml</code> is well noted.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'blaer'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;professor&#39;, 0.7219115495681763), (u&#39;prof.&#39;, 0.6643839478492737), (u&#39;bauer&#39;, 0.4823228120803833), (u&#39;today&#39;, 0.44543683528900146), (u&#39;went&#39;, 0.4129117727279663), (u&#39;pm&#39;, 0.4097597897052765), (u&#39;session&#39;, 0.40625864267349243), (u&#39;mentioned&#39;, 0.4010222554206848), (u&#39;ocaml&#39;, 0.3884058892726898), (u&#39;tonight&#39;, 0.38226139545440674)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'bauer'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;professor&#39;, 0.6429691314697266), (u&#39;slides&#39;, 0.5277301669120789), (u&#39;prof.&#39;, 0.5086715221405029), (u&#39;lecture&#39;, 0.4928019642829895), (u&#39;blaer&#39;, 0.4823228120803833), (u&#39;sign&#39;, 0.4362599849700928), (u&#39;pm&#39;, 0.3718754053115845), (u&#39;went&#39;, 0.3549380302429199), (u&#39;tonight&#39;, 0.326946496963501), (u&#39;perform&#39;, 0.3159770965576172)]</code></pre><p>Sasha loves grades, which is unsurprising.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'sasha'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;email&#39;, 0.5593311786651611), (u&#39;ta&#39;, 0.4426960051059723), (u&#39;monday&#39;, 0.4238441586494446), (u&#39;grade&#39;, 0.42380213737487793), (u&#39;talk&#39;, 0.40258437395095825), (u&#39;grading&#39;, 0.3625785708427429), (u&#39;mentioned&#39;, 0.3540249466896057), (u&#39;approaches&#39;, 0.3509276807308197), (u&#39;cs&#39;, 0.3439938724040985), (u&#39;hope&#39;, 0.3431258201599121)]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.doesnt_match(<span class="string">"bauer blaer graph"</span>.split())</span><br></pre></td></tr></table></figure><pre><code>&#39;graph&#39;</code></pre><p>And of course it differentiates between a TA and a professor.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.doesnt_match(<span class="string">"bauer blaer linan"</span>.split())</span><br></pre></td></tr></table></figure><pre><code>&#39;linan&#39;</code></pre><p>ISN’T THIS FUCKING AWESOME.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Word embedding (very bad explanation follows) is translating each word in a corpus into a D dimension vector. These vectors are supposed 
      
    
    </summary>
    
    
      <category term="ta" scheme="http://linanqiu.github.io/tags/ta/"/>
    
      <category term="word2vec" scheme="http://linanqiu.github.io/tags/word2vec/"/>
    
      <category term="nlp" scheme="http://linanqiu.github.io/tags/nlp/"/>
    
      <category term="piazza" scheme="http://linanqiu.github.io/tags/piazza/"/>
    
  </entry>
  
  <entry>
    <title>Oil Futures Curve Visualization</title>
    <link href="http://linanqiu.github.io/2016/01/09/Oil-Futures-Curve-Visualization/"/>
    <id>http://linanqiu.github.io/2016/01/09/Oil-Futures-Curve-Visualization/</id>
    <published>2016-01-09T17:05:04.000Z</published>
    <updated>2016-01-09T15:09:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>This oil thing is getting pretty crazy, especially with Saudi and Iran going bonkers over each other. Futures curves are a great way to speculate, and it’d be great to visualize the movement of the futures curve over different trading days.</p><p>I thought this would be a pretty commonsensical thing for yahoo / google finance to provide, but turns out they provide nothing more than a single futures chain (settle prices for futures contracts right now). Historical prices aren’t available, and even if they are, they aren’t in the form of a futures curve. Instead, they are just prices for the specific contract (eg. the futures contract expiring on Feb 2016, not the front month contract and the contract expiring in one month etc). I want the relative numbers, not the absolute ones, hence this.</p><p>I want a plot of the current futures prices for the next 12 months. Here’s how to do that simply</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># %config InlineBackend.figure_format = 'retina'</span></span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas_datareader.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> pandas_datareader.wb <span class="keyword">as</span> wb</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> pyplot</span><br><span class="line">matplotlib.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> Quandl</span><br><span class="line"></span><br><span class="line">API_KEY = <span class="string">'SUBSTITUTE_YOUR_OWN_API_KEY'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pyplot.rcParams['figure.figsize'] = (10, 10)</span></span><br></pre></td></tr></table></figure><p>In Quandl (and in real life), futures contract are named as <code>AAMYYYY</code> where <code>AA</code> is the type of underlying asset (for WTI crude oil, it is <code>CL</code>), <code>M</code> is the month (the whole series of months starting from <code>F</code> to <code>Z</code> is in the array below) and <code>YYYY</code> is the year (eg. <code>2016</code>). Hence, a futures contract for crude oil expiring in March 2016 will be <code>CLH2016</code> or <code>CLH16</code> depending on the source of your data.</p><p>We make use of this fact and pull our data (in the form of <code>pandas</code> dataframes) into a dictionary.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">MONTHS = [<span class="string">'F'</span>, <span class="string">'G'</span>, <span class="string">'H'</span>, <span class="string">'J'</span>, <span class="string">'K'</span>, <span class="string">'M'</span>, <span class="string">'N'</span>, <span class="string">'Q'</span>, <span class="string">'U'</span>, <span class="string">'V'</span>, <span class="string">'X'</span>, <span class="string">'Z'</span>]</span><br><span class="line">YEARS = [<span class="number">2014</span>, <span class="number">2015</span>, <span class="number">2016</span>, <span class="number">2017</span>, <span class="number">2018</span>]</span><br><span class="line">PREFIX = <span class="string">'CME/CL'</span></span><br><span class="line"></span><br><span class="line">dataframes = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> month <span class="keyword">in</span> MONTHS:</span><br><span class="line">    <span class="keyword">for</span> year <span class="keyword">in</span> YEARS:</span><br><span class="line">        symbol = <span class="string">'%s%s%d'</span> % (PREFIX, month, year)</span><br><span class="line">        internal_symbol = <span class="string">'%d%s'</span> % (year, month)</span><br><span class="line">        dataframes[internal_symbol] = Quandl.get(symbol, authtoken=API_KEY)</span><br><span class="line">        dataframes[internal_symbol] = dataframes[internal_symbol][<span class="string">'Settle'</span>]</span><br></pre></td></tr></table></figure><p>Next, we make some functions that extract the futures price at a given date from each of the dataframes (each of the contracts), skipping them if the date doesn’t exist. For example, there won’t be a settlement price on 5th Jan 2015 for a contract expiring in December 2014.</p><p>Then <code>extract_year</code> takes the first 12 prices from the list of prices. The keys for the dataframes are in the form of <code>YYYYMAA</code> so that the year comes first, simplifying the sorting process. Yes I know this is non conventional.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_curve</span><span class="params">(dataframes, date)</span>:</span></span><br><span class="line">    curve = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> symbol, dataframe <span class="keyword">in</span> dataframes.iteritems():</span><br><span class="line">        <span class="keyword">if</span> date <span class="keyword">in</span> dataframe:</span><br><span class="line">            curve[symbol] = dataframe[date]</span><br><span class="line">    <span class="keyword">return</span> curve</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_year</span><span class="params">(curve)</span>:</span></span><br><span class="line">    pvs = [curve[symbol] <span class="keyword">for</span> symbol <span class="keyword">in</span> sorted(curve)]</span><br><span class="line">    <span class="keyword">return</span> pvs[:<span class="number">12</span>]</span><br></pre></td></tr></table></figure><p>Now we can plot our first graph. This plots the futures curve at a certain date.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_year_curve</span><span class="params">(date)</span>:</span></span><br><span class="line">    pyplot.plot(extract_year(get_curve(dataframes, date)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>))</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Oil-Futures-Curve-Visualization/output_8_0.svg" alt="svg"><p class="caption">svg</p></div><p>That’s useful, but what I really want to know is how the futures curve has shifted over the last few days. I can do this by plotting a whole bunch of these lines, and varying the gradient such that the ones far back in time are red, and the recent ones are green.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_year_curve_range</span><span class="params">(date, shift_back_days)</span>:</span></span><br><span class="line">    date_list = [date - datetime.timedelta(days=x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, shift_back_days)]</span><br><span class="line">    <span class="keyword">for</span> index, date <span class="keyword">in</span> enumerate(date_list):</span><br><span class="line">        color = (index / len(date_list))</span><br><span class="line">        pyplot.plot(extract_year(get_curve(dataframes, date)), color=(color, <span class="number">1</span>-color, <span class="number">0</span>), linewidth=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve_range(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>), <span class="number">30</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Oil-Futures-Curve-Visualization/output_11_0.svg" alt="svg"><p class="caption">svg</p></div><p>The plot above is the futures curve for the last 30 days (non-trading days are included, so there are less than 30 lines in the graph). What we see that initially, the curve flattened, then dropped in a parallel manner, and finally steepening again. In fact, we can visualize the recent steepening a little closer by looking at the last 10 days.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve_range(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>), <span class="number">10</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Oil-Futures-Curve-Visualization/output_13_0.svg" alt="svg"><p class="caption">svg</p></div><p>This shows that over the last 10 days, the curve has fallen somewhat more on the short end than on the long end (37 to 33 vs 44 to 41).</p><p>We can also abuse this for cool artistic effects.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve_range(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>), <span class="number">360</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/Oil-Futures-Curve-Visualization/output_15_0.svg" alt="svg"><p class="caption">svg</p></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This oil thing is getting pretty crazy, especially with Saudi and Iran going bonkers over each other. Futures curves are a great way to s
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Grades</title>
    <link href="http://linanqiu.github.io/2016/01/04/Grades/"/>
    <id>http://linanqiu.github.io/2016/01/04/Grades/</id>
    <published>2016-01-05T04:09:58.000Z</published>
    <updated>2016-01-04T15:10:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>This conversation happened on Piazza today, two weeks after class ended.</p><blockquote><p>A student posted: Hi all, I was wondering if it’s possible to get the cutoffs for the course grades?</p></blockquote><blockquote><p>Me: No, and it won’t be productive in any way since your grades are final and the cut off changes from year to year.</p></blockquote><blockquote><p>Said student: Hi Linan, with all due respect I disagree with that. I understand the trouble it would cause since everyone would start asking to review and change their grades, but I simply just want to understand the grade I received. Since we hardly have an opportunity to review our final exams until next semester, knowing the cutoff would help understand why we got what grade we got. I received 100 or above on every homework assignment with the exception of one (and the one I dropped) and above 100 on the first midterm, but I did poorly on my final and this brought my grade down a lot more than I can see why. If I knew the cutoffs, maybe I could see where I fell compared to the class and be able to understand my grade. In a class in which the homework assignments have taken me over 12 hours straight to complete, I’d like to know exactly where my grade is coming from.</p></blockquote><blockquote><p>Me: Sure. You got a grade of x% (grades redacted). The cutoff for A- was 90%, A was 93%, and A+ was 100%. This was due to the finals, and the fact that the curves for the homeworks had high means with high skews. This should probably answer most of your question.</p></blockquote><blockquote><p>Now my refusal to answer this question is not because it would cause people to start asking for reviews: grades are final. It is because I want students to stop dwelling on the grades of this class and move on. No interviewer has ever asked me about my grades for data structures or even my GPA, and certainly getting a B+, A-, or an A would not make the tiniest difference. Get over grades. Instead, think about what you learned in this class, how it will help you in the things you build, and what you know now that you didn’t know 4 months ago.</p></blockquote><blockquote><p>If anything, this class is a very bad indicator of how you’ll do in any class following this. I didn’t get a good grade in data structures myself because like you, sometimes I screw up exams. In fact I’d wager that I screw them up way more often than you. However, I will say that I understand (and apply) these concepts better than most people in the same class as me. Seeing how you did in your homeworks (and attempted numerous extra credits), you should be proud of that too. This takes you way further in classes, projects, and, with a little bit of exaggeration, life.</p></blockquote><blockquote><p>tl;dr: you missed A- by a scratch. Unfortunately, we can’t change that – there has to be a cutoff, and you, like many many others in this class, fell slightly below a cutoff. However, it. does. not. matter. Move on from this piazza. Build things. Make the world a better place.</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This conversation happened on Piazza today, two weeks after class ended.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A student posted: Hi all, I was wondering if
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Memoization Recursion Dynamic Programming</title>
    <link href="http://linanqiu.github.io/2015/12/10/Memoization-Recursion-Dynamic-Programming/"/>
    <id>http://linanqiu.github.io/2015/12/10/Memoization-Recursion-Dynamic-Programming/</id>
    <published>2015-12-11T04:37:45.000Z</published>
    <updated>2015-12-11T04:38:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>A student asked this in class today: What’s the difference between Recursion, Memoization and Dynamic Programming.</p><p>I was quite surprised that said student couldn’t find a good answer online, so I made one. Here’s the answer:</p><hr><p>Okay. Here’s the short version: Recursion + Memoization = Dynamic Programming.</p><p>Was going to go through this at recitation but wtheck. :D</p><h2 id="recursion">Recursion</h2><p>Recursion is recursion is recursion but it ends somewhere. Basically, a recursive expression is one that depends on previous values of the same expression, and we have a base condition. Think Fibonacci numbers. In this case, I’m going to use the example of the coin change problem (which you’ve probably done in class).</p><p>The question goes like: coins come in 35 cents, 25 cents, 15 cents, 10 cents, 5 cents, and 1 cents. So I write it like this <code>int[] combinations = new int[] {35, 25, 15, 10, 5, 1}</code>. Now given <code>x</code> cents, what’s the minimum number of coins I need?</p><p>I can derive a recursive equation for this:</p><p>Let’s say <code>C(x)</code> is a magical function. <code>C(x)</code> gives me the minimum number of coins required to represent <code>x</code> cents. I can define <code>C(x)</code> recursively:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C(x) = minimum of the following &#123;</span><br><span class="line">         C(x-35) + 1,</span><br><span class="line">         C(x-25) + 1,</span><br><span class="line">         C(x-15) + 1,</span><br><span class="line">         C(x-10) + 1,</span><br><span class="line">         C(x-5) + 1,</span><br><span class="line">         C(x-1) + 1</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p>Why? Say <code>x=105</code>. Then, the minimum number of coins required to piece together 105 cents is the minimum of</p><ul><li>the minimum number of coins required to piece 70 cents plus another 35 cent coin</li><li>the minimum number of coins required to piece 80 cents plus another 25 cent coin</li><li>the minimum number of coins required to piece 90 cents plus another 15 cent coin etc. etc.</li></ul><p>What about our base condition? Since the smallest denomination is 1 cent, I can define <code>C(0) = 0</code> and <code>C(1) = 1</code>. Then, the entire recursive function is basically:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">minimumCoin</span><span class="params">(<span class="keyword">int</span>[] combinations, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(x == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(x == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  List&lt;Integer&gt; costs = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> combination : combinations) &#123;</span><br><span class="line">    <span class="keyword">if</span>(x - combination &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      costs.add(minimumCoin(combinations, x - combination) + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Collections.min(costs).intValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="memoization">Memoization</h2><p>The problem with this is that you’re doing a lot of repeat work. Let’s do a trace:</p><ul><li>To calculate C(105), you need C(70, 80, 90, 95, 100, 104).</li><li>For each of those, you’d need more values.</li></ul><p>Convince yourself that those values repeat by drawing up a giant tree. You’re doing a lot of duplicate work. This is basically the same reason why Fibonacci recursion is so inefficient.</p><p>The reason is because naive recursion is forgetful. You only remember results for the current layer, and that’s it. Instead, what if there’s a way to remember all the past results that you’ve had so far? Memoization is exactly that.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">minimumCoin</span><span class="params">(<span class="keyword">int</span>[] combinations, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span>[] memory = <span class="keyword">new</span> <span class="keyword">int</span>[x + <span class="number">1</span>];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; memory.length; i++) &#123;</span><br><span class="line">    memory[i] = Integer.MIN_VALUE;</span><br><span class="line">  &#125;</span><br><span class="line">  minimumCoin(combinations, x, memory);</span><br><span class="line">  <span class="keyword">return</span> memory[x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">minimumCoin</span><span class="params">(<span class="keyword">int</span>[] combinations, <span class="keyword">int</span> x, <span class="keyword">int</span>[] memory)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (x == <span class="number">0</span>) &#123;</span><br><span class="line">    memory[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (x == <span class="number">1</span>) &#123;</span><br><span class="line">    memory[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  List&lt;Integer&gt; costs = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> combination : combinations) &#123;</span><br><span class="line">    <span class="keyword">if</span> (x - combination &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (memory[x - combination] == Integer.MIN_VALUE) &#123;</span><br><span class="line">        minimumCoin(combinations, x - combination, memory);</span><br><span class="line">      &#125;</span><br><span class="line">      costs.add(memory[x - combination] + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  memory[x] = Collections.min(costs).intValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The only major difference between this and the previous recursive solution is that instead of recursing down <code>costs.add(minimumCoin(combinations, x - combination) + 1)</code> every single time, we check if this value has been calculated before in <code>int[] memory</code>. If it has, we just take the value straightaway instead of calculating it. We only calculate if it hasn’t been calculated (ie. still equals to the initial value of <code>Integer.MAX_VALUE</code>).</p><p>This is memoization.</p><h2 id="dynamic-programming">Dynamic Programming</h2><p>So DP really comprises of two parts:</p><ul><li>Getting a recursive equation</li><li>Coming up with a memoized way to do this</li></ul><p>Usually, the memoized solution is way easier to write <strong>iteratively</strong> than recursively. I just stuck to recursion in this case to extend from the original recursion example. Plus, providing you with the iterative solution would be too much of a giveaway.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;A student asked this in class today: What’s the difference between Recursion, Memoization and Dynamic Programming.&lt;/p&gt;
&lt;p&gt;I was quite sur
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Principal Component Analysis on Interest Rate Swaps</title>
    <link href="http://linanqiu.github.io/2015/12/03/pca-irs/"/>
    <id>http://linanqiu.github.io/2015/12/03/pca-irs/</id>
    <published>2015-12-03T06:40:39.000Z</published>
    <updated>2015-12-03T06:47:12.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>In partial satisfaction of the project requirement for the class Statistical Methods in Finance <code>STAT W4290</code> Fall 2015.</p></blockquote><h1 id="abstract">Abstract</h1><p>This project applies Principal Component Analysis (PCA) to interest rate swaps and shows that the first 3 principal components correspond to yields, slope, and curvature respectively. I first start with vanilla interest rate swaps, and explain how an analysis based purely on single trades are unsatisfactory. I then shift our analysis to curve trades done using pairs of interest rate swaps and show how that is more useful in modeling different parts of the yield curve. I then demonstrate how the principal components from the analysis corresponding to yield, slope and curvature.</p><h1 id="introduction">Introduction</h1><h2 id="what-are-interest-rate-swaps">What are Interest Rate Swaps</h2><blockquote><p>A swap is an over-the-counter agreement between two companies to exchange cash flows in the future. The agreement defines the dates when the cash flows are to be paid and the way in which they are to be calculated. Usually, the calculation of the cash flows involve the future value of an interest rate, an exchange rate, or other market variable. … The most common type of swap is a “plain vanilla” interest rate swap. In this swap a company agrees to pay cash flows equal to interest at a predetermined fixed rate on a notional principal for a predetermined number of years. In return, it receives interest at a floating rate on the same notional principal for the same period of time. - Hull, Chapter 7</p></blockquote><h2 id="mechanics-of-interest-rate-swaps">Mechanics of Interest Rate Swaps</h2><p>In other words, an interest rate swap (IRS) is an <strong>exchange</strong> of</p><ul><li><strong>Floating Leg</strong>: a series of coupons paid out at predetermined intervals based on the prevailing interest rate at the beginning of those intervals</li><li><strong>Fixed Leg</strong>: a series of fixed amount coupons paid out at predetermined intervals</li></ul><p>Hence, it is a swap of a fixed payment and a floating payment flow. The floating leg and the fixed leg coupons are paid as a percent of a notional amount.</p><p>Consider a 5 year interest rate swap initiated on Jan 1 2012 between Google and Baidu. Let’s say that Google prefers a fixed payment. Then, Google will pay 5% on a notional of $1M every 6 months for 5 years. In return, Baidu pays Google the 6-month LIBOR rate on the same principal taken at the start of every 6 months for that 6 months. Hence, on Jan 1 2012, if the 6-month LIBOR rate is 2%, Baidu will pay Google $2000 / 2 = $1000 (since interest rate is annual. We assume away compounding complications for now) for that 6 months. This payment occurs at Jul 1 2012. On Jul 1 2012, if the 6-month LIBOR rate goes to 7%, Baidu will pay Google $7000 / 2 = $3500 on Jan 1 2013. For those 2 periods, Google always pays Baidu $2500 per period.</p><p>In real markets, companies rarely negotiate such contracts on their own. Instead, they negotiate with a financial intermediary who charges a spread between the parties. The average of the fixed rates charged to either party is known as the <em>swap rate</em>.</p><h2 id="libor-and-usd-interest-rate">LIBOR and USD Interest Rate</h2><p>The LIBOR is used as the reference rate for the floating legs in interest rate swaps. LIBOR is the rate that AA rated banks borrow from each other. Over different periods (ranging from say spot to 12 months) the USD LIBOR forward curve is usually above the Treasury Yield curve with mostly the same shape. Hence, the LIBOR forward curve is often used by speculators to speculate on the underlying treasury yield curve (or the ECB rate curve if EUR denominated IRS are used instead).</p><h2 id="interest-rate-swap-yield-rates-and-speculation">Interest Rate Swap Yield Rates and Speculation</h2><p>How IRS can be used for interest rate speculation is straightforward. Say that I am “paying fixed” (hence receiving the floating leg) for a 5 year IRS, colloquially termed a “5y”, that exchanges payments every 6 months. Then, I am essentially betting on the spot 6 month rate, forward 6 month rate in 6 months, forward 6 month rate in 1 year … and the forward 6 month rate in 4.5 years for each of the floating leg payments. If each of those rates go up, I am profitting since I am paying a lower amount (via the fixed rate I locked in). My counterparty would be losing since he’s paying a larger amount than he originally though.</p><p>Then, the IRS swap rate can be viewered as the “yield to maturity” of the fixed leg that makes the present value of the entire swap 0, given the forward rates estimated for the floating leg. Or, in other words, the swap rate is the discount rate that makes the present value of the fixed leg equal to the present value of the floating leg when the flaoting leg is discounted by each of the forward rates.</p><p>Hence, an IRS is an instrument to bet on the entire forward curve from spot rate to the year of maturity. A “5y” allows us to bet on the entire curve up to the 5 year point.</p><p>In terms of directions:</p><ul><li>If I pay fixed (receive float), when the yield curve goes up, I profit (since I’m paying less than I would have).</li><li>If I receive fixed (pay float), when the yield curve goes up, I lose (since I’m paying more).</li></ul><h3 id="curve-trades">Curve Trades</h3><p>Then, one can imagine a trade where:</p><ul><li>I pay fixed (receive float) on one 2 year IRS: I profit from the yield curve going up at the short end</li><li>I pay float (receive fixed) on one 10 year IRS: I profit from the yield curve going down at the long end</li></ul><p>What am I doing here? The fixed payments from now to year 2 cancel each other out, just as the floating payments. Hence, I am betting on the curve from year 2 to year 10. In other words, I am betting on a specific section of the curve, not just from today till the end of the curve. In particular, I am betting that the section of the curve <em>flattens</em> (going up at the short end and going down at the long end). There’s an important caveat to this: <strong>I do not hold this trade to maturity.</strong> Otherwise, this would cease to be a curve trade. The 2 year would expire and I would be left with one outstanding swap, making this a normal directional bet.</p><h3 id="butterfly-trades">Butterfly Trades</h3><p>Butterfly trades benefit from differing movements in 3 instruments. Imagine this trade:</p><ul><li>I pay fixed (receive float) on 2 year IRS: I profit from yield curve going up at the short end</li><li>I receive float (pay fixed) on 10 year IRS: I profit from the yield curve going down at the middle end</li><li>I pay fixed (receive float) on 30 year IRS: I profit from the yield curve going up at the long end</li></ul><p>I essentially betting on the curvature of the curve. An imaginative trader gave this trade the name, presumably because of the symmetric direction.</p><h1 id="pca-on-vanilla-irs">PCA on Vanilla IRS</h1><p>We begin by performing PCA on single IRS rates. Here, I try to find the relationships between different IRS maturities. By doing this, I am essentially finding out similar components in movements of the yield curve between</p><ul><li>Spot to 1 year</li><li>Spot to 2 year</li><li>Spot to 3 year</li><li>Spot to 4 year</li><li>Spot to 5 year</li><li>Spot to 7 year</li><li>Spot to 10 year</li><li>Spot to 30 year</li></ul><p>An astute reader would realize that we are including the short end of the curve in all the time series, which is a problem we can solve by using curve trade yields instead in a later section.</p><h2 id="data-collection">Data Collection</h2><p>We collect data for the various time series from the St. Louis FRED using the <code>quantmod</code> package.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(quantmod)</span><br><span class="line"><span class="keyword">library</span>(downloader)</span><br><span class="line"></span><br><span class="line">terms = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> (term <span class="keyword">in</span> terms) &#123;</span><br><span class="line">  getSymbols(paste(<span class="string">'DSWP'</span>, term, sep=<span class="string">''</span>), src=<span class="string">'FRED'</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then I select the data for year to date which leaves me with 250 yields over the past year.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">DSWP1 = DSWP1[!is.na(DSWP1)]</span><br><span class="line">DSWP2 = DSWP2[!is.na(DSWP2)]</span><br><span class="line">DSWP3 = DSWP3[!is.na(DSWP3)]</span><br><span class="line">DSWP4 = DSWP4[!is.na(DSWP4)]</span><br><span class="line">DSWP5 = DSWP5[!is.na(DSWP5)]</span><br><span class="line">DSWP7 = DSWP7[!is.na(DSWP7)]</span><br><span class="line">DSWP10 = DSWP10[!is.na(DSWP10)]</span><br><span class="line">DSWP30 = DSWP30[!is.na(DSWP30)]</span><br><span class="line"></span><br><span class="line">rates = cbind(DSWP1, DSWP2, DSWP3, DSWP4, DSWP5, DSWP7, DSWP10, DSWP30)</span><br><span class="line">rates = last(rates, <span class="number">250</span>)</span><br></pre></td></tr></table></figure><p>I can plot the yields for the different IRS maturities. Due to the upward sloping nature of the yield curve, yields of IRS with longer maturities are always higher</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="keyword">library</span>(reshape)</span><br></pre></td></tr></table></figure><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataframe = data.frame(index(rates), rates)</span><br><span class="line">colnames(dataframe) = c(<span class="string">'date'</span>, <span class="string">'y1'</span>, <span class="string">'y2'</span>, <span class="string">'y3'</span>, <span class="string">'y4'</span>, <span class="string">'y5'</span>, <span class="string">'y7'</span>, <span class="string">'y10'</span>, <span class="string">'y30'</span>)</span><br><span class="line">melted = melt(dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=melted, aes(x=date, y=value, color=variable)) + geom_line() + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'IRS Yield Rate'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_12_0.svg" alt="svg"><p class="caption">svg</p></div><h2 id="results">Results</h2><p>I perform PCA on the time series using the covariance matrix of the various time series.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pcadata = rates</span><br><span class="line">colnames(pcadata) = c(<span class="string">'y1'</span>, <span class="string">'y2'</span>, <span class="string">'y3'</span>, <span class="string">'y4'</span>, <span class="string">'y5'</span>, <span class="string">'y7'</span>, <span class="string">'y10'</span>, <span class="string">'y30'</span>)</span><br><span class="line">fit = princomp(pcadata, cor=<span class="literal">FALSE</span>, scores=<span class="literal">TRUE</span>)</span><br><span class="line">summary(fit)</span><br></pre></td></tr></table></figure><pre><code>Importance of components:                          Comp.1    Comp.2     Comp.3      Comp.4       Comp.5Standard deviation     0.3437851 0.1209262 0.07618897 0.019044680 0.0051760656Proportion of Variance 0.8500517 0.1051749 0.04174988 0.002608666 0.0001926951Cumulative Proportion  0.8500517 0.9552266 0.99697646 0.999585128 0.9997778228                             Comp.6       Comp.7       Comp.8Standard deviation     3.715011e-03 3.106083e-03 2.727945e-03Proportion of Variance 9.926388e-05 6.939006e-05 5.352322e-05Cumulative Proportion  9.998771e-01 9.999465e-01 1.000000e+00</code></pre><p>First observation would be that the data has a high degree of covariance among the time series. This should not be surprising at all, since the short end of the curve was included in all these measurements.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">covariance_matrix = cor(pcadata)</span><br><span class="line"><span class="keyword">require</span>(corrplot)</span><br><span class="line">corrplot(covariance_matrix, method=<span class="string">'shade'</span>, type=<span class="string">'full'</span>, shade.col=<span class="literal">NA</span>, tl.col=<span class="string">'black'</span>)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_16_0.svg" alt="svg"><p class="caption">svg</p></div><p>Correspondingly, I should expect the first few principal components to have a high proportion of explained variance.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggbiplot)</span><br><span class="line">ggbiplot(fit, obs.scale=<span class="number">1</span>, var.scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_18_0.svg" alt="svg"><p class="caption">svg</p></div><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ggscreeplot(fit)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_19_0.svg" alt="svg"><p class="caption">svg</p></div><p>Indeed, the first principal component accounts for 85.0% of variance, with the second principal component getting 10.5% and the third 4.1%. The first 3 principal components account for, cumulatively, 99.7% of all movements in the data. Hence, in terms of dimensionality reduction, the first 3 principal components are representative of the data.</p><p>We can plot the scores of the first 3 components across time.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scores = fit$scores</span><br><span class="line">scores_dataframe = data.frame(index(rates), scores)</span><br><span class="line">colnames(scores_dataframe) = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>, <span class="string">'pc4'</span>, <span class="string">'pc5'</span>, <span class="string">'pc6'</span>, <span class="string">'pc7'</span>, <span class="string">'pc8'</span>)</span><br><span class="line">keeps = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>)</span><br><span class="line">scores_dataframe = scores_dataframe[keeps]</span><br><span class="line">scores_melted = melt(scores_dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=scores_melted, aes(x=as.Date(date), y=value, color=variable)) + geom_line() + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'Principal Component Score'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_21_0.svg" alt="svg"><p class="caption">svg</p></div><h2 id="interpretation-of-results">Interpretation of Results</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loadings = with(fit, unclass(loadings))</span><br><span class="line">loadings</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th scope="col">Comp.1</th><th scope="col">Comp.2</th><th scope="col">Comp.3</th><th scope="col">Comp.4</th><th scope="col">Comp.5</th><th scope="col">Comp.6</th><th scope="col">Comp.7</th><th scope="col">Comp.8</th></tr></thead><tbody><pre><code>&lt;tr&gt;&lt;th scope=row&gt;y1&lt;/th&gt;&lt;td&gt;-0.05693512&lt;/td&gt;&lt;td&gt;-0.13640484&lt;/td&gt;&lt;td&gt; 0.81073244&lt;/td&gt;&lt;td&gt;-0.16509581&lt;/td&gt;&lt;td&gt;-0.52010662&lt;/td&gt;&lt;td&gt;-0.10535402&lt;/td&gt;&lt;td&gt;-0.10119507&lt;/td&gt;&lt;td&gt;-0.04192361&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y2&lt;/th&gt;&lt;td&gt;-0.16669185&lt;/td&gt;&lt;td&gt;-0.34625166&lt;/td&gt;&lt;td&gt; 0.43078043&lt;/td&gt;&lt;td&gt; 0.03625115&lt;/td&gt;&lt;td&gt; 0.62509086&lt;/td&gt;&lt;td&gt; 0.43345259&lt;/td&gt;&lt;td&gt; 0.19830580&lt;/td&gt;&lt;td&gt; 0.21792835&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y3&lt;/th&gt;&lt;td&gt;-0.25832243&lt;/td&gt;&lt;td&gt;-0.41911497&lt;/td&gt;&lt;td&gt; 0.02728088&lt;/td&gt;&lt;td&gt; 0.32238835&lt;/td&gt;&lt;td&gt; 0.26957189&lt;/td&gt;&lt;td&gt;-0.50912909&lt;/td&gt;&lt;td&gt;-0.23991017&lt;/td&gt;&lt;td&gt;-0.51331798&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y4&lt;/th&gt;&lt;td&gt;-0.3264334&lt;/td&gt;&lt;td&gt;-0.3807082&lt;/td&gt;&lt;td&gt;-0.1918120&lt;/td&gt;&lt;td&gt; 0.3024259&lt;/td&gt;&lt;td&gt;-0.3000946&lt;/td&gt;&lt;td&gt;-0.2516847&lt;/td&gt;&lt;td&gt; 0.2005263&lt;/td&gt;&lt;td&gt; 0.6531742&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y5&lt;/th&gt;&lt;td&gt;-0.37780952&lt;/td&gt;&lt;td&gt;-0.27733220&lt;/td&gt;&lt;td&gt;-0.24318642&lt;/td&gt;&lt;td&gt; 0.00362353&lt;/td&gt;&lt;td&gt;-0.38673513&lt;/td&gt;&lt;td&gt; 0.55717635&lt;/td&gt;&lt;td&gt; 0.22904952&lt;/td&gt;&lt;td&gt;-0.45685974&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y7&lt;/th&gt;&lt;td&gt;-0.43649941&lt;/td&gt;&lt;td&gt;-0.03879438&lt;/td&gt;&lt;td&gt;-0.15120515&lt;/td&gt;&lt;td&gt;-0.42341285&lt;/td&gt;&lt;td&gt; 0.05459486&lt;/td&gt;&lt;td&gt; 0.13634667&lt;/td&gt;&lt;td&gt;-0.73385353&lt;/td&gt;&lt;td&gt; 0.21379852&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y10&lt;/th&gt;&lt;td&gt;-0.4708117505&lt;/td&gt;&lt;td&gt; 0.2213930338&lt;/td&gt;&lt;td&gt; 0.0007092894&lt;/td&gt;&lt;td&gt;-0.5524750953&lt;/td&gt;&lt;td&gt; 0.1530175357&lt;/td&gt;&lt;td&gt;-0.3715511987&lt;/td&gt;&lt;td&gt; 0.5064115711&lt;/td&gt;&lt;td&gt;-0.0785801970&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;y30&lt;/th&gt;&lt;td&gt;-0.490660311&lt;/td&gt;&lt;td&gt; 0.643019711&lt;/td&gt;&lt;td&gt; 0.193912132&lt;/td&gt;&lt;td&gt; 0.539919671&lt;/td&gt;&lt;td&gt; 0.008108114&lt;/td&gt;&lt;td&gt; 0.106656257&lt;/td&gt;&lt;td&gt;-0.072175546&lt;/td&gt;&lt;td&gt; 0.003512140&lt;/td&gt;&lt;/tr&gt;</code></pre></tbody></table><p>However, I am also interested in the interpretation of the principal components. I hypothesized that the first 3 principal components should correspond to:</p><ul><li>Principal Component 1: Directional movements in the yield curve. These are movements that shift the entire yield curve up or down.</li><li>Principal Component 2: Slope movements in the yield curve. These are movements that steepen or flatten (change the first derivative wrt maturity) the entire yield curve.</li><li>Principal Component 3: Curvature movements in the yield curve. These are movements that change the curvature (or the second derivative wrt maturity) of the entire yield curve.</li></ul><p>I find that this interpretation stands. By evaluating the loadings of the principal components, I observe that</p><ul><li>Principal Component 1 (PC1): All IRS yields are weighted in the same direction (negative). Since the sign of the loadings are arbitrary, this means that PC1 reflects movements that causes IRS of all maturities to move in the same direction. This corresponds to directional movements in the yield curve – if the yield curve goes up, all yields go up be it the short end or the long end and vice versa.</li><li>Principal Component 2 (PC2): IRS yields on the short end of the curve (from y1 to y7) are weighted negatively and the ones reaching the long end (y10 and y30) are weighted positively. Since the signs are arbitrary, this means that PC2 reflects movements that cause the short end to go in one direction and the long end in the other. This is exactly what slope movements do – if the yield curve steepens, the short end goes down and the long end goes up and vice versa if the yield curve flattens.</li><li>Principal Component 3 (PC3): IRS yields on the short and long ends of the curve are weighted positively while the ones in the middle are weighted negatively. Since the signs are arbitrary, this means that PC3 reflects movements that cause the short and long end to go in one direction, and the middle to go in the other. This is exactly what curvature movements do – if the yield curve increases in curvature, the short and long end goes down while the middle goes up.</li></ul><p>Hence PC1 can be interpreted as directional movements, PC2 as slope movements, and PC3 as curvature movements.</p><h2 id="shortcoming">Shortcoming</h2><p>I find this analysis lacking in one striking way: we are unable to isolate portions of the curve. For example, the time series for y30 includes movements from the spot all the way to year 30. In other words, it includes movements of the y1, y2, y3 etc. In a similar way, the y3 includes movements of y1. Hence, we are unable to isolate movements in the “long end only” and are instead forced to make conclusions about yield rates “from the short end to the long end” or on the “short end” only.</p><p>This could be done instead by measuring yields for curve trades. This is what I will do in the next section.</p><h1 id="pca-on-curve-trade-rates">PCA on Curve Trade Rates</h1><h2 id="review-on-curve-trades-and-butterfly-trades">Review on Curve Trades and Butterfly Trades</h2><p>Refer to the introduction for a complete breakdown of curve trades and butterfly trades. As a reminder,</p><ul><li>Curve trades are bets on the slope of a specific section of the curve</li><li>Butterflies are bets on the curvature of two specific sections of the curve.</li></ul><h2 id="data-collection-1">Data Collection</h2><p>I employ most of the same data collection methods as in the previous section.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(quantmod)</span><br><span class="line"><span class="keyword">library</span>(downloader)</span><br><span class="line"></span><br><span class="line">terms = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> (term <span class="keyword">in</span> terms) &#123;</span><br><span class="line">  getSymbols(paste(<span class="string">'DSWP'</span>, term, sep=<span class="string">''</span>), src=<span class="string">'FRED'</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DSWP1 = DSWP1[!is.na(DSWP1)]</span><br><span class="line">DSWP2 = DSWP2[!is.na(DSWP2)]</span><br><span class="line">DSWP3 = DSWP3[!is.na(DSWP3)]</span><br><span class="line">DSWP4 = DSWP4[!is.na(DSWP4)]</span><br><span class="line">DSWP5 = DSWP5[!is.na(DSWP5)]</span><br><span class="line">DSWP7 = DSWP7[!is.na(DSWP7)]</span><br><span class="line">DSWP10 = DSWP10[!is.na(DSWP10)]</span><br><span class="line">DSWP30 = DSWP30[!is.na(DSWP30)]</span><br></pre></td></tr></table></figure><p>The yield of a curve trade is calculated as follow:</p><p><span class="math display">\[C = S\_{0, t\_2} - S\_{0, t\_1}\]</span></p><p>where <span class="math inline">\(C\)</span> is the curve trade rate, <span class="math inline">\(S\_{0,t\_2}\)</span> is the swap rate for an IRS of maturity <span class="math inline">\(t\_2\)</span> and <span class="math inline">\(S\_{0, t\_2}\)</span> is the swap rate for an IRS of maturity <span class="math inline">\(t\_1\)</span>. Intuitively, we can think of this the forward rate from <span class="math inline">\(t\_1\)</span> to <span class="math inline">\(t\_2\)</span> and indeed it is. We select the following “tenors” (sections of the yield curve) to represent the whole yield curve. They are quoted as “XsYs” where we pay fix for X years and receive fix for Y years of IRS.</p><ul><li>2s1s</li><li>3s1s</li><li>4s1s</li><li>5s1s</li><li>7s1s</li><li>10s2s</li><li>10s5s</li><li>30s10s</li></ul><p>And select only the rates for the year to date.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2-1, 3-1, 4-1, 5-1, 7-1, 10-2, 10-5, 30-10</span></span><br><span class="line">curve2_1 = DSWP2 - DSWP1</span><br><span class="line">curve3_1 = DSWP3 - DSWP1</span><br><span class="line">curve4_1 = DSWP4 - DSWP1</span><br><span class="line">curve5_1 = DSWP5 - DSWP1</span><br><span class="line">curve7_1 = DSWP7 - DSWP1</span><br><span class="line">curve10_2 = DSWP10 - DSWP2</span><br><span class="line">curve10_5 = DSWP10 - DSWP5</span><br><span class="line">curve30_10 = DSWP30 - DSWP10</span><br><span class="line"></span><br><span class="line">rates = cbind(curve2_1, curve3_1, curve4_1, curve5_1, curve7_1, curve10_2, curve10_5, curve30_10)</span><br><span class="line">rates = last(rates, <span class="number">250</span>)</span><br><span class="line">colnames(rates) = c(<span class="string">'curve2y1y'</span>, <span class="string">'curve3y1y'</span>, <span class="string">'curve4y1y'</span>, <span class="string">'curve5y1y'</span>, <span class="string">'curve7y1y'</span>, <span class="string">'curve10y2y'</span>, <span class="string">'curve10y5y'</span>, <span class="string">'curve30y10y'</span>)</span><br></pre></td></tr></table></figure><p>As for the vanilla yields, I can plot a time series of the different curve rates. However, this chart isn’t very telling, since I am measuring different ends of the curve.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="keyword">library</span>(reshape)</span><br><span class="line">dataframe = data.frame(index(rates), rates)</span><br><span class="line">colnames(dataframe) = c(<span class="string">'date'</span>, <span class="string">'curve2y1y'</span>, <span class="string">'curve3y1y'</span>, <span class="string">'curve4y1y'</span>, <span class="string">'curve5y1y'</span>, <span class="string">'curve7y1y'</span>, <span class="string">'curve10y2y'</span>, <span class="string">'curve10y5y'</span>, <span class="string">'curve30y10y'</span>)</span><br><span class="line">melted = melt(dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=melted, aes(x=as.Date(date), y=value, color=variable)) + geom_line()</span><br><span class="line">plot</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_31_0.svg" alt="svg"><p class="caption">svg</p></div><h2 id="results-1">Results</h2><p>I perform PCA on the series as well using the covariance matrix of the time series.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pcadata = rates</span><br><span class="line">colnames(pcadata) = c(<span class="string">'curve2y1y'</span>, <span class="string">'curve3y1y'</span>, <span class="string">'curve4y1y'</span>, <span class="string">'curve5y1y'</span>, <span class="string">'curve7y1y'</span>, <span class="string">'curve10y2y'</span>, <span class="string">'curve10y5y'</span>, <span class="string">'curve30y10y'</span>)</span><br><span class="line">fit = princomp(pcadata, cor=<span class="literal">FALSE</span>, scores=<span class="literal">TRUE</span>)</span><br><span class="line">summary(fit)</span><br></pre></td></tr></table></figure><pre><code>Importance of components:                          Comp.1    Comp.2      Comp.3      Comp.4       Comp.5Standard deviation     0.2775099 0.1294640 0.028713618 0.011572150 0.0048336969Proportion of Variance 0.8126072 0.1768567 0.008699608 0.001413032 0.0002465373Cumulative Proportion  0.8126072 0.9894639 0.998163497 0.999576529 0.9998230661                             Comp.6       Comp.7 Comp.8Standard deviation     2.971792e-03 2.817212e-03      0Proportion of Variance 9.318811e-05 8.374576e-05      0Cumulative Proportion  9.999163e-01 1.000000e+00      1</code></pre><p>Again, the series has a high degree of covariance among the time series. This again should not be surprising, since they are all yield rates after all (though of different tenors) hence should be driven by the same macroeconomic factors.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">covariance_matrix = cor(pcadata)</span><br><span class="line"><span class="keyword">require</span>(corrplot)</span><br><span class="line">corrplot(covariance_matrix, method=<span class="string">'shade'</span>, type=<span class="string">'full'</span>, shade.col=<span class="literal">NA</span>, tl.col=<span class="string">'black'</span>)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_35_0.svg" alt="svg"><p class="caption">svg</p></div><p>However, what should be interesting to note is that some time series now have somewhat negative covariance with others. These happen to be between the far short end of the curve and the far long end (eg. 2s1s vs 30s10s). This makes sense, since the far end usually doesn’t move as much as the short end, and sometimes in the opposite direction (slope).</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggbiplot)</span><br><span class="line">ggbiplot(fit, obs.scale=<span class="number">1</span>, var.scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_37_0.svg" alt="svg"><p class="caption">svg</p></div><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ggscreeplot(fit)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_38_0.svg" alt="svg"><p class="caption">svg</p></div><p>The first principal component accounts for 81.3% of variance, with the second principal component getting 17.7% and the third 0.87%. The first 3 principal components account for, cumulatively, 99.8% of all movements in the data. Hence, in terms of dimensionality reduction, the first 3 principal components are representative of the data.</p><p>We can plot the scores of the first 3 components across time.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scores = fit$scores</span><br><span class="line">scores_dataframe = data.frame(index(rates), scores)</span><br><span class="line">colnames(scores_dataframe) = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>, <span class="string">'pc4'</span>, <span class="string">'pc5'</span>, <span class="string">'pc6'</span>, <span class="string">'pc7'</span>, <span class="string">'pc8'</span>)</span><br><span class="line">keeps = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>)</span><br><span class="line">scores_dataframe = scores_dataframe[keeps]</span><br><span class="line">scores_melted = melt(scores_dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=scores_melted, aes(x=as.Date(date), y=value, color=variable)) + geom_line() + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'Principal Component Score'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_40_0.svg" alt="svg"><p class="caption">svg</p></div><h2 id="interpretation-of-results-1">Interpretation of Results</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loadings = with(fit, unclass(loadings))</span><br><span class="line">loadings</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th scope="col">Comp.1</th><th scope="col">Comp.2</th><th scope="col">Comp.3</th><th scope="col">Comp.4</th><th scope="col">Comp.5</th><th scope="col">Comp.6</th><th scope="col">Comp.7</th><th scope="col">Comp.8</th></tr></thead><tbody><pre><code>&lt;tr&gt;&lt;th scope=row&gt;curve2y1y&lt;/th&gt;&lt;td&gt;-0.171227734&lt;/td&gt;&lt;td&gt;-0.195448923&lt;/td&gt;&lt;td&gt; 0.004706401&lt;/td&gt;&lt;td&gt; 0.667761277&lt;/td&gt;&lt;td&gt; 0.255984666&lt;/td&gt;&lt;td&gt;-0.361642751&lt;/td&gt;&lt;td&gt;-0.200598804&lt;/td&gt;&lt;td&gt;-0.500000000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve3y1y&lt;/th&gt;&lt;td&gt;-3.263336e-01&lt;/td&gt;&lt;td&gt;-2.874607e-01&lt;/td&gt;&lt;td&gt; 1.814160e-01&lt;/td&gt;&lt;td&gt; 2.487582e-01&lt;/td&gt;&lt;td&gt;-5.310257e-01&lt;/td&gt;&lt;td&gt; 5.745447e-01&lt;/td&gt;&lt;td&gt;-3.224754e-01&lt;/td&gt;&lt;td&gt; 3.785444e-13&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve4y1y&lt;/th&gt;&lt;td&gt;-4.295687e-01&lt;/td&gt;&lt;td&gt;-2.585274e-01&lt;/td&gt;&lt;td&gt; 2.043599e-01&lt;/td&gt;&lt;td&gt;-1.301226e-01&lt;/td&gt;&lt;td&gt;-4.286356e-01&lt;/td&gt;&lt;td&gt;-4.860891e-01&lt;/td&gt;&lt;td&gt; 5.195463e-01&lt;/td&gt;&lt;td&gt;-6.752862e-13&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve5y1y&lt;/th&gt;&lt;td&gt;-0.49071115&lt;/td&gt;&lt;td&gt;-0.14814235&lt;/td&gt;&lt;td&gt; 0.05408491&lt;/td&gt;&lt;td&gt;-0.21436777&lt;/td&gt;&lt;td&gt; 0.33797228&lt;/td&gt;&lt;td&gt;-0.25143465&lt;/td&gt;&lt;td&gt;-0.51081605&lt;/td&gt;&lt;td&gt; 0.50000000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve7y1y&lt;/th&gt;&lt;td&gt;-5.385355e-01&lt;/td&gt;&lt;td&gt; 1.119178e-01&lt;/td&gt;&lt;td&gt;-1.587484e-01&lt;/td&gt;&lt;td&gt; 1.153416e-01&lt;/td&gt;&lt;td&gt; 4.549395e-01&lt;/td&gt;&lt;td&gt; 4.507466e-01&lt;/td&gt;&lt;td&gt; 4.988054e-01&lt;/td&gt;&lt;td&gt;-3.640491e-13&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve10y2y&lt;/th&gt;&lt;td&gt;-0.38081672&lt;/td&gt;&lt;td&gt; 0.58044994&lt;/td&gt;&lt;td&gt;-0.17867132&lt;/td&gt;&lt;td&gt;-0.33936332&lt;/td&gt;&lt;td&gt;-0.20605357&lt;/td&gt;&lt;td&gt;-0.06584042&lt;/td&gt;&lt;td&gt;-0.27234639&lt;/td&gt;&lt;td&gt;-0.50000000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve10y5y&lt;/th&gt;&lt;td&gt;-0.06133330&lt;/td&gt;&lt;td&gt; 0.53314337&lt;/td&gt;&lt;td&gt;-0.22804983&lt;/td&gt;&lt;td&gt; 0.54276573&lt;/td&gt;&lt;td&gt;-0.28804119&lt;/td&gt;&lt;td&gt;-0.17604852&lt;/td&gt;&lt;td&gt; 0.03787086&lt;/td&gt;&lt;td&gt; 0.50000000&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th scope=row&gt;curve30y10y&lt;/th&gt;&lt;td&gt;7.557077e-03&lt;/td&gt;&lt;td&gt;3.958458e-01&lt;/td&gt;&lt;td&gt;9.018019e-01&lt;/td&gt;&lt;td&gt;7.913918e-02&lt;/td&gt;&lt;td&gt;1.487753e-01&lt;/td&gt;&lt;td&gt;3.332223e-02&lt;/td&gt;&lt;td&gt;2.224416e-02&lt;/td&gt;&lt;td&gt;5.464379e-16&lt;/td&gt;&lt;/tr&gt;</code></pre></tbody></table><p>Earlier I confirmed my hypothesis of the interpretation of the principal components, namely that:</p><ul><li>Principal Component 1: Directional movements in the yield curve. These are movements that shift the entire yield curve up or down.</li><li>Principal Component 2: Slope movements in the yield curve. These are movements that steepen or flatten (change the first derivative wrt maturity) the entire yield curve.</li><li>Principal Component 3: Curvature movements in the yield curve. These are movements that change the curvature (or the second derivative wrt maturity) of the entire yield curve.</li></ul><p>Recall that the major shortcoming of that analysis was that we included the short end of the curve in all our time series and was unable to isolate the middle portion fo the curve individually. We are able to do that now. We see that the same interpretation of the principal components hold.</p><ul><li>Principal Component 1: Almost all the loadings are negative (with a very small positive for the 30s10s which we can ignore since it is two orders of magnitude smaller than the other loadings and would have been suppressed by <code>R</code>’s output if not for the fact that I forced the output to be present). Since the signs of loadings are arbitrary in PCA, we can conclude that in PC1 type movement, all sections of the yield curve move in the same direction. This corresponds to directional movements in the yield curve where the entire curve shifts up or down.</li><li>Principal Component 2: The short end of the curve (2s1s, 3s1s, 4s1s, 5s1s) are negative while the middle (7s1s, 10s2s, 10s5s) are positive as far the far end (30s10s). Again, signs are arbitrary in PCA loadings. This means that in PC2 type movements, the far and middle end moves in opposite direction as the short end. This corresponds well with the slope interpretation.</li><li>Principal Component 3: The short end and the long end moves in the same direction while the middle end moves in the opposite direction. This again corresponds well with the interpretation of curvature movements.</li></ul><p>This relationship is summarized in the plot below.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">loadings = with(fit, unclass(loadings))</span><br><span class="line">loadings_dataframe = data.frame(index(loadings), loadings)</span><br><span class="line">colnames(loadings_dataframe) = c(<span class="string">'tenor'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>, <span class="string">'pc4'</span>, <span class="string">'pc5'</span>, <span class="string">'pc6'</span>, <span class="string">'pc7'</span>, <span class="string">'pc8'</span>)</span><br><span class="line">keeps = c(<span class="string">'tenor'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>)</span><br><span class="line">loadings_dataframe = loadings_dataframe[keeps]</span><br><span class="line">loadings_melted = melt(loadings_dataframe, id.vars=<span class="string">'tenor'</span>)</span><br><span class="line">plot = ggplot() + geom_line(data=loadings_melted, aes(x=tenor, y=value, color=variable)) + scale_x_discrete(labels=c(<span class="string">'2y1y'</span>, <span class="string">'3y1y'</span>, <span class="string">'4y1y'</span>, <span class="string">'5y1y'</span>, <span class="string">'7y1y'</span>, <span class="string">'10y2y'</span>, <span class="string">'10y5y'</span>, <span class="string">'30y10y'</span>)) + xlab(<span class="string">'Tenor'</span>) + ylab(<span class="string">'Loading of First 3 PCs'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_44_0.svg" alt="svg"><p class="caption">svg</p></div><p>To confirm this further, I can plot each of the principal components with yield movements.</p><h3 id="first-principal-component">First Principal Component</h3><p>I plot both the scores of the first principal component and the swap rate for a 10 year IRS and find that the correlation indeed holds up, and this shows that my interpretation of the principal component holds.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">'graphing_utility.R'</span>)</span><br><span class="line">first_factor_10y = data.frame(rownames(scores), scores_dataframe$pc1, last(DSWP10, <span class="number">250</span>))</span><br><span class="line">colnames(first_factor_10y) = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'y10'</span>)</span><br><span class="line">first_factor_10y$pc1 = -first_factor_10y$pc1</span><br><span class="line"></span><br><span class="line">p1 = ggplot() + geom_line(data=first_factor_10y, aes(x=as.Date(date), y=pc1), colour=gg_color_hue(<span class="number">1</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'left/red: PC1\nright/blue: 10y Yield'</span>)</span><br><span class="line">p2 = ggplot() + geom_line(data=first_factor_10y, aes(x=as.Date(date), y=y10), colour=gg_color_hue(<span class="number">2</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(panel.background = element_rect(fill = <span class="literal">NA</span>))</span><br><span class="line">g = stack_plot(p1, p2)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_46_0.svg" alt="svg"><p class="caption">svg</p></div><h3 id="second-principal-component">Second Principal Component</h3><p>To see that the second principal component holds, I use a common curve trade: 10s2s. To see why this represents slope, one can consider the bets I made:</p><ul><li>Receive fixed for 10 year IRS: if rates go up on the long end, I lose</li><li>Pay fixed for 2 year IRS: if rates go up in the short end, I gain</li></ul><p>Hence, I’m making a bet on the slope of the curve. In fact, this bet is a steepener (I profit when the curve steepens). The yield rate for this trade is constructed as:</p><p><span class="math display">\[C\_{2, 10} = Y\_{0, 10} - Y\_{0, 2}\]</span></p><p>where <span class="math inline">\(C\)</span> is the rate for curve trade, <span class="math inline">\(Y\)</span> is the IRS yield.</p><p>I again find a high level of correlation in the movements.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">second_factor_10y2y = data.frame(rownames(scores), scores_dataframe$pc2, last(curve10_2, <span class="number">250</span>))</span><br><span class="line">colnames(second_factor_10y2y) = c(<span class="string">'date'</span>, <span class="string">'pc2'</span>, <span class="string">'curve10y2y'</span>)</span><br><span class="line"></span><br><span class="line">p1 = ggplot() + geom_line(data=second_factor_10y2y, aes(x=as.Date(date), y=pc2), colour=gg_color_hue(<span class="number">1</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'left/red: PC2\nright/blue: 10s2s Yield'</span>)</span><br><span class="line">p2 = ggplot() + geom_line(data=second_factor_10y2y, aes(x=as.Date(date), y=curve10y2y), colour=gg_color_hue(<span class="number">2</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(panel.background = element_rect(fill = <span class="literal">NA</span>))</span><br><span class="line">g = stack_plot(p1, p2)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_48_0.svg" alt="svg"><p class="caption">svg</p></div><h3 id="third-principal-component">Third Principal Component</h3><p>To see that the third principal component holds, I use another common trade: a butterfly of 2s10s30s. This is essentially:</p><ul><li>Receive fixed on 2 year IRS: I lose if rates go up on the short end</li><li>Pay fixed on two 10 year IRS: I gain if rates go up in the middle end</li><li>Receive fixed on 30 year IRS: I lose if rates go up in the far end</li></ul><p>The yield can be constructed as</p><p><span class="math display">\[C\_{2,10,30} = \left(Y\_{0,10} - Y\_{0,2}\right) - \left(Y\_{0,30} - Y\_{0,10}\right)\]</span></p><p>Essentially, I am long two 10 year IRS, and short one 2 year IRS and one 30 year IRS. This can be seen as a bet on curvature. If the rates go up in the middle and go down in the two ends, I profit. Thus this is a curvature bet.</p><p>Again there is a high degree of correlation between this and the yields of a butterfly, confirming my interpretation of the third principal component.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">butterfly2_10_30 = (DSWP10 - DSWP5) - (DSWP30 - DSWP10)</span><br><span class="line">third_factor_butterfly = data.frame(rownames(scores), scores_dataframe$pc3, last(butterfly2_10_30, <span class="number">250</span>))</span><br><span class="line">colnames(third_factor_butterfly) = c(<span class="string">'date'</span>, <span class="string">'pc3'</span>, <span class="string">'butterfly2y10y30y'</span>)</span><br><span class="line">third_factor_butterfly$pc3 = -third_factor_butterfly$pc3</span><br><span class="line"></span><br><span class="line">p1 = ggplot() + geom_line(data=third_factor_butterfly, aes(x=as.Date(date), y=pc3), colour=gg_color_hue(<span class="number">1</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'left/red: PC3, right/blue: 2s10s30s Yield'</span>)</span><br><span class="line">p2 = ggplot() + geom_line(data=third_factor_butterfly, aes(x=as.Date(date), y=butterfly2y10y30y), colour=gg_color_hue(<span class="number">2</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(panel.background = element_rect(fill = <span class="literal">NA</span>))</span><br><span class="line">g = stack_plot(p1, p2)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure><div class="figure"><img src="/images/pca-irs/output_50_0.svg" alt="svg"><p class="caption">svg</p></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;In partial satisfaction of the project requirement for the class Statistical Methods in Finance &lt;code&gt;STAT W4290&lt;/code&gt; Fall
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Binomial European Option Pricing in R</title>
    <link href="http://linanqiu.github.io/2015/10/26/Binomial-European-Option-Pricing-in-R/"/>
    <id>http://linanqiu.github.io/2015/10/26/Binomial-European-Option-Pricing-in-R/</id>
    <published>2015-10-26T04:48:14.000Z</published>
    <updated>2015-10-30T05:12:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>The code for this is available at <a href="https://github.com/linanqiu/binomial-european-option-r" target="_blank" rel="noopener">linanqiu/binomial-european-option-r</a>.</p><p>This post by Intel <a href="https://software.intel.com/en-us/articles/binomial-options-pricing-model-code-for-intel-xeon-phi-coprocessor" class="uri" target="_blank" rel="noopener">https://software.intel.com/en-us/articles/binomial-options-pricing-model-code-for-intel-xeon-phi-coprocessor</a> is a surprisingly good explanation of the theoretical background of this subject and an insanely fast CPU level implementation of this.</p><p>My Financial Engineering class was working on Binomial European Option Pricing, and the prof insisted that we show the entire tree matrix for the intermediate steps (and not just the final price). Turns out the packages available on <a href="https://cran.r-project.org/" class="uri" target="_blank" rel="noopener">https://cran.r-project.org/</a> don’t seem to do that. Either way, good exercise to implement this from scratch and revise for the midterms.</p><p>First, let’s talk about our model.</p><p>Let’s say time is <span class="math inline">\(T\)</span> where <span class="math inline">\(T=1\)</span> represents a year, and <span class="math inline">\(T=0.25\)</span> represents 3 months. The number of periods we simulate is <span class="math inline">\(N\)</span>. Then, the amount of time represented by each period is <span class="math inline">\(\Delta t = \frac{T}{N}\)</span>.</p><p>We assume that in each period, the stock can go up by</p><p><span class="math display">\[U = e^{\sigma * \sqrt{\Delta t}}\]</span></p><p>where <span class="math inline">\(\sigma\)</span> is the volatility, and <span class="math inline">\(\Delta t\)</span> is <span class="math inline">\(\frac{T}{N}\)</span>.</p><p>Then, if the stock value is <span class="math inline">\(S\)</span> at period 1, it would go up to</p><p><span class="math display">\[S_U = US = e^{\sigma * \sqrt{\Delta t}}S\]</span> in period 2.</p><p>It can also go down by</p><p><span class="math display">\[D = e^{-\sigma * \sqrt{\Delta t}}\]</span>.</p><p>Astute readers will recognize this as a <strong>Geometric Brownian Motion</strong> (I will probably make another post about this next time).</p><p>That means, say <span class="math inline">\(S=10\)</span> and <span class="math inline">\(\sigma = 0.2\)</span>, <span class="math inline">\(T=1\)</span> (1 year) and <span class="math inline">\(N=2\)</span>, then <span class="math inline">\(U = e^{\sigma * sqrt{\Delta t}} = 1.15191\)</span> and <span class="math inline">\(D = 0.8681234\)</span>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">period 0: 10.0</span><br><span class="line">period 1: 8.68  11.5</span><br><span class="line">period 2: 7.54  10.0  13.3</span><br></pre></td></tr></table></figure><p>The number directly below represents <span class="math inline">\(S_D = DS\)</span> and the number directly above represents <span class="math inline">\(S_U = US\)</span>, and the second period is calculated recursively.</p><p>Then, we can build a stock tree!</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">build_stock_tree = <span class="keyword">function</span>(S, sigma, delta_t, N) &#123;</span><br><span class="line">  tree = matrix(<span class="number">0</span>, nrow=N+<span class="number">1</span>, ncol=N+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  u = exp(sigma*sqrt(delta_t))</span><br><span class="line">  d = exp(-sigma*sqrt(delta_t))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:(N+<span class="number">1</span>)) &#123;</span><br><span class="line">    <span class="keyword">for</span> (j <span class="keyword">in</span> <span class="number">1</span>:i) &#123;</span><br><span class="line">      tree[i,j] = S * u^(j-<span class="number">1</span>) * d^((i-<span class="number">1</span>)-(j-<span class="number">1</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>(tree)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>To see what this gives us, let’s try it with the parameters above:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; build_stock_tree(S=10, sigma=0.2, delta_t=1/2, N=2)</span><br><span class="line">          [,1]    [,2]     [,3]</span><br><span class="line">[1,] 10.000000  0.0000  0.00000</span><br><span class="line">[2,]  8.681234 11.5191  0.00000</span><br><span class="line">[3,]  7.536383 10.0000 13.26896</span><br></pre></td></tr></table></figure><p>Cool! We just did what we wanted to do but way faster. In fact, we can expand the number of levels really easily. Note that when <code>N</code> changes, <code>delta_t</code> should change too. This is not too much of a problem – we’ll be calculating <code>delta_t</code> programmatically soon.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; build_stock_tree(S=<span class="number">10</span>, sigma=<span class="number">0.2</span>, delta_t=<span class="number">1</span>/<span class="number">5</span>, N=<span class="number">5</span>)</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]     [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">10.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">2</span>,]  <span class="number">9.144406</span> <span class="number">10.935647</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">3</span>,]  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.958837</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">4</span>,]  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.935647</span> <span class="number">13.07776</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">5</span>,]  <span class="number">6.992333</span>  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.95884</span> <span class="number">14.30138</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">6</span>,]  <span class="number">6.394073</span>  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.93565</span> <span class="number">13.07776</span> <span class="number">15.63948</span></span><br></pre></td></tr></table></figure><p>Now how do we get an option’s price from the underlier’s (stock’s) price? Let’s say that we have a <strong>call</strong> option. Then, we know that at termination, the value of the call option is <span class="math inline">\(\max(S-X, 0)\)</span> where <span class="math inline">\(S\)</span> here is the price of the stock at termination, and <span class="math inline">\(X\)</span> is the strike price. So say <span class="math inline">\(X=10\)</span>, then in our example above, the various values of the call option would be</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.0000000 0.0000000 0.0000000 0.9356469 3.0777623 5.6394832</span><br></pre></td></tr></table></figure><p>But how do we advance up the option back to the price at the beginning? We call upon the powers of the <strong>q-measure</strong> where <span class="math inline">\(q\)</span> is the risk-neutral no-arbitrage probability which is independent of the actual probability of the stock going up or down. Finance textbooks tell us that</p><p><span class="math display">\[q \equiv \frac{R-D}{U-D}\]</span></p><p>where <span class="math inline">\(R\)</span> is <span class="math inline">\(e^{r*\Delta t}\)</span> where <span class="math inline">\(r\)</span> is the interest rate per annum continuously compounded. <span class="math inline">\(R\)</span> is then the discount factor. The derivation of <span class="math display">\[q\]</span> will be left to another time.</p><p>Then, we can write a function to calculate <span class="math display">\[q\]</span>.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">q_prob = <span class="keyword">function</span>(r, delta_t, sigma) &#123;</span><br><span class="line">  u = exp(sigma*sqrt(delta_t))</span><br><span class="line">  d = exp(-sigma*sqrt(delta_t))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span>((exp(r*delta_t) - d)/(u-d))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then, we know that</p><p><span class="math display">\[C = \frac{qC_U + (1-q)C_D}{R}\]</span></p><p>where <span class="math inline">\(C\)</span> is the price of the option in a previous time period, and <span class="math inline">\(C_U\)</span> is the value of the option when the underlier went up, and <span class="math inline">\(C_D\)</span> is the value of the option when the underlier went down.</p><p>That means we can derive the step above the last row of the call option. Let’s say that <span class="math inline">\(r = 0.1\)</span> for <strong>10 percent interest continuously compounded a year.</strong> First we find that</p><p><span class="math display">\[R = e^{r * \Delta t} = e^{\frac{0.1}{5}} = 1.020201\]</span></p><p>Then, <span class="math inline">\(q = \frac{R-D}{U-D} = 0.5904327\)</span> using our <code>q_prob</code> function above with <code>q_prob(0.1, 1/5, 0.2)</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.0000000 0.0000000 0.5414976 2.1568506 4.499392 0.000000</span><br><span class="line">0.0000000 0.0000000 0.0000000 0.9356469 3.077762 5.639483</span><br></pre></td></tr></table></figure><p>You should verify the first row using the q-measure method.</p><p>We can code this into a method (account for both “put” and “call”).</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">value_binomial_option = <span class="keyword">function</span>(tree, sigma, delta_t, r, X, type) &#123;</span><br><span class="line">  q = q_prob(r, delta_t, sigma)</span><br><span class="line"></span><br><span class="line">  option_tree = matrix(<span class="number">0</span>, nrow=nrow(tree), ncol=ncol(tree))</span><br><span class="line">  <span class="keyword">if</span>(type == <span class="string">'put'</span>) &#123;</span><br><span class="line">    option_tree[nrow(option_tree),] = pmax(X - tree[nrow(tree),], <span class="number">0</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    option_tree[nrow(option_tree),] = pmax(tree[nrow(tree),] - X, <span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> (nrow(tree)-<span class="number">1</span>):<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span>(j <span class="keyword">in</span> <span class="number">1</span>:i) &#123;</span><br><span class="line">      option_tree[i, j] = ((<span class="number">1</span>-q)*option_tree[i+<span class="number">1</span>,j] + q*option_tree[i+<span class="number">1</span>,j+<span class="number">1</span>])/exp(r*delta_t)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>(option_tree)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This function takes in a stock tree generated in the <code>build_stock_tree</code> function, and returns an option tree. For the previous option, it would generate</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; tree = build_stock_tree(S=<span class="number">10</span>, sigma=<span class="number">0.2</span>, delta_t=<span class="number">1</span>/<span class="number">5</span>, N=<span class="number">5</span>)</span><br><span class="line">&gt; value_binomial_option(tree, sigma=<span class="number">0.2</span>, delta_t=<span class="number">1</span>/<span class="number">5</span>, r=<span class="number">0.1</span>, X=<span class="number">10</span>, type=<span class="string">'call'</span>)</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]      [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">1.3515415</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">2</span>,] <span class="number">0.6365307</span> <span class="number">1.8937675</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">3</span>,] <span class="number">0.1813700</span> <span class="number">0.9740419</span> <span class="number">2.5965507</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">4</span>,] <span class="number">0.0000000</span> <span class="number">0.3133870</span> <span class="number">1.4656468</span> <span class="number">3.4698679</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">5</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.5414976</span> <span class="number">2.1568506</span> <span class="number">4.499392</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">6</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.9356469</span> <span class="number">3.077762</span> <span class="number">5.639483</span></span><br></pre></td></tr></table></figure><p>Now let’s put everything together and make the output a nice little list.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">binomial_option = <span class="keyword">function</span>(type, sigma, <span class="literal">T</span>, r, X, S, N) &#123;</span><br><span class="line">  q = q_prob(r=r, delta_t=<span class="literal">T</span>/N, sigma=sigma)</span><br><span class="line">  tree = build_stock_tree(S=S, sigma=sigma, delta_t=<span class="literal">T</span>/N, N=N)</span><br><span class="line">  option = value_binomial_option(tree, sigma=sigma, delta_t=<span class="literal">T</span>/N, r=r, X=X, type=type)</span><br><span class="line">  <span class="keyword">return</span>(list(q=q, stock=tree, option=option, price=option[<span class="number">1</span>,<span class="number">1</span>], delta=delta))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Usually, there’s also something that we want to compute: the <span class="math display">\[\Delta\]</span> of stocks – the amount of stocks that are required to replicate the portfolio.</p><p><span class="math display">\[\Delta = \frac{C_U - C_D}{S_U - S_D}\]</span></p><p>We code this as</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delta = <span class="keyword">function</span>(binomial_option, row, col) &#123;</span><br><span class="line">  stock_tree = binomial_option$stock</span><br><span class="line">  option_tree = binomial_option$option</span><br><span class="line">  <span class="keyword">return</span>((option_tree[row+<span class="number">1</span>, col+<span class="number">1</span>] - option_tree[row+<span class="number">1</span>, col])/(stock_tree[row+<span class="number">1</span>, col+<span class="number">1</span>] - stock_tree[row+<span class="number">1</span>, col]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Then, the overall function becomes</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">binomial_option = <span class="keyword">function</span>(type, sigma, <span class="literal">T</span>, r, X, S, N) &#123;</span><br><span class="line">  q = q_prob(r=r, delta_t=<span class="literal">T</span>/N, sigma=sigma)</span><br><span class="line">  tree = build_stock_tree(S=S, sigma=sigma, delta_t=<span class="literal">T</span>/N, N=N)</span><br><span class="line">  option = value_binomial_option(tree, sigma=sigma, delta_t=<span class="literal">T</span>/N, r=r, X=X, type=type)</span><br><span class="line">  delta = (option[<span class="number">2</span>,<span class="number">2</span>]-option[<span class="number">2</span>,<span class="number">1</span>])/(tree[<span class="number">2</span>,<span class="number">2</span>]-tree[<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">  <span class="keyword">return</span>(list(q=q, stock=tree, option=option, price=option[<span class="number">1</span>,<span class="number">1</span>], delta=delta))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Look how pretty the output is for our example!</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; binomial_option(type=<span class="string">'call'</span>, sigma=<span class="number">0.2</span>, <span class="literal">T</span>=<span class="number">1</span>, r=<span class="number">0.1</span>, X=<span class="number">10</span>, S=<span class="number">10</span>, N=<span class="number">5</span>)</span><br><span class="line">$q</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.5904327</span></span><br><span class="line"></span><br><span class="line">$stock</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]     [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">10.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">2</span>,]  <span class="number">9.144406</span> <span class="number">10.935647</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">3</span>,]  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.958837</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">4</span>,]  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.935647</span> <span class="number">13.07776</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">5</span>,]  <span class="number">6.992333</span>  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.95884</span> <span class="number">14.30138</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">6</span>,]  <span class="number">6.394073</span>  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.93565</span> <span class="number">13.07776</span> <span class="number">15.63948</span></span><br><span class="line"></span><br><span class="line">$option</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]      [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">1.3515415</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">2</span>,] <span class="number">0.6365307</span> <span class="number">1.8937675</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">3</span>,] <span class="number">0.1813700</span> <span class="number">0.9740419</span> <span class="number">2.5965507</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">4</span>,] <span class="number">0.0000000</span> <span class="number">0.3133870</span> <span class="number">1.4656468</span> <span class="number">3.4698679</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">5</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.5414976</span> <span class="number">2.1568506</span> <span class="number">4.499392</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">6</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.9356469</span> <span class="number">3.077762</span> <span class="number">5.639483</span></span><br><span class="line"></span><br><span class="line">$price</span><br><span class="line">[<span class="number">1</span>] <span class="number">1.351541</span></span><br><span class="line"></span><br><span class="line">$delta</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.7018805</span></span><br></pre></td></tr></table></figure><p>Let’s try the model for a put with the same parameters.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; binomial_option(type=<span class="string">'put'</span>, sigma=<span class="number">0.2</span>, <span class="literal">T</span>=<span class="number">1</span>, r=<span class="number">0.1</span>, X=<span class="number">10</span>, S=<span class="number">10</span>, N=<span class="number">5</span>)</span><br><span class="line">$q</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.5904327</span></span><br><span class="line"></span><br><span class="line">$stock</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]     [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">10.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">2</span>,]  <span class="number">9.144406</span> <span class="number">10.935647</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">3</span>,]  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.958837</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">4</span>,]  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.935647</span> <span class="number">13.07776</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">5</span>,]  <span class="number">6.992333</span>  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.95884</span> <span class="number">14.30138</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">6</span>,]  <span class="number">6.394073</span>  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.93565</span> <span class="number">13.07776</span> <span class="number">15.63948</span></span><br><span class="line"></span><br><span class="line">$option</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]       [,<span class="number">3</span>] [,<span class="number">4</span>] [,<span class="number">5</span>] [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">0.3999157</span> <span class="number">0.0000000</span> <span class="number">0.00000000</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">2</span>,] <span class="number">0.7232877</span> <span class="number">0.1892841</span> <span class="number">0.00000000</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">3</span>,] <span class="number">1.2369985</span> <span class="number">0.3916873</span> <span class="number">0.05535867</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">4</span>,] <span class="number">1.9613263</span> <span class="number">0.7768750</span> <span class="number">0.13789428</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">5</span>,] <span class="number">2.8096541</span> <span class="number">1.4399698</span> <span class="number">0.34348430</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">6</span>,] <span class="number">3.6059268</span> <span class="number">2.3534319</span> <span class="number">0.85559356</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line"></span><br><span class="line">$price</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.3999157</span></span><br><span class="line"></span><br><span class="line">$delta</span><br><span class="line">[<span class="number">1</span>] -<span class="number">0.2981195</span></span><br></pre></td></tr></table></figure><p>As a sanity check, we ensure that</p><ol style="list-style-type: decimal"><li>Price of call minus price of put (long a call, short a put) equals a forward. In other words <span class="math inline">\(C - P = S + \frac{X}{e^{r}}\)</span>. In our case, <span class="math inline">\(1.351541 - 0.3999157 = 10 - \frac{10}{e^{0.1}} = 0.9516258\)</span> so that’s good!</li><li><span class="math inline">\(\Delta_C - \Delta_P = 1\)</span>, which again is true!</li></ol><p>Woohoo!</p><p>What if we want to find out how option price evolves as we increase the number of periods? Well we can do that!</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">periods = seq(<span class="number">100</span>, <span class="number">120</span>)</span><br><span class="line">option_price_vary_period = <span class="keyword">function</span>(period) &#123;</span><br><span class="line">  print(period)</span><br><span class="line">  option = binomial_option(type=<span class="string">'call'</span>, sigma=<span class="number">0.2</span>, <span class="literal">T</span>=<span class="number">1</span>, r=<span class="number">0</span>, X=<span class="number">100</span>, S=<span class="number">100</span>, N=period)</span><br><span class="line">  <span class="keyword">return</span>(option$price)</span><br><span class="line">&#125;</span><br><span class="line">values = sapply(periods, option_price_vary_period)</span><br><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">data = as.data.frame(list(periods=periods, values=values))</span><br><span class="line">plot = ggplot(data=data) + geom_line(aes(x=periods, y=values)) + labs(title=<span class="string">"Call Value"</span>, x=<span class="string">"Periods"</span>, y=<span class="string">"Value"</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure><p>However, this gets really slow as we increase the number of periods. This is rather unfortunate, since we are going at <span class="math inline">\(O(N^2)\)</span>. However, we can use a slightly faster parallel implementation using the library <code>parallel</code>.</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(parallel)</span><br><span class="line">cl = makeCluster(<span class="number">8</span>)</span><br><span class="line">clusterEvalQ(cl, <span class="keyword">source</span>(<span class="string">'binomial.R'</span>))</span><br><span class="line">periods = seq(<span class="number">100</span>, <span class="number">1000</span>)</span><br><span class="line">periods = sample(periods)</span><br><span class="line">valuesPar = parSapply(cl=cl, periods, option_price_vary_period)</span><br><span class="line">data = as.data.frame(list(periods=periods, values=valuesPar))</span><br><span class="line">plot = ggplot(data=data) + geom_line(aes(x=periods, y=values, alpha=<span class="number">0.1</span>)) + geom_point((aes(x=periods, y=values))) + labs(title=<span class="string">"Call Value"</span>, x=<span class="string">"Periods"</span>, y=<span class="string">"Value"</span>)</span><br><span class="line">plot</span><br><span class="line">stopCluster(cl)</span><br></pre></td></tr></table></figure><p>This assumes that <code>binomial.R</code> is in the same folder. This should speed things up A LOT. Reason why I randomized periods in the 5th line is because the larger periods take WAY longer, so you’ll want to distribute that among the cores rather evenly (since <code>parSapply</code> segments the input into equal segments increasingly). This doesn’t affect the graphing at all, and if you want you can always sort the result.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The code for this is available at &lt;a href=&quot;https://github.com/linanqiu/binomial-european-option-r&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;linanqi
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Finding Quantile Given Weird Density Function</title>
    <link href="http://linanqiu.github.io/2015/10/15/Finding-Quantile-Given-Weird-Density-Function/"/>
    <id>http://linanqiu.github.io/2015/10/15/Finding-Quantile-Given-Weird-Density-Function/</id>
    <published>2015-10-15T20:27:46.000Z</published>
    <updated>2016-05-06T03:04:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>For one of my Statistical Finance homeworks, I had to solve this question.</p><p>Given a density function <span class="math inline">\(f(x)\)</span>, where</p><p><span class="math display">\[f(x) = \int_{-\infty}^{\infty} \frac{1}{Z} \frac{|x+1|}{(x^2+1)^2} = 1\]</span></p><p>Find the quantile <span class="math inline">\(y\)</span> that satisfies the <span class="math inline">\(F^{-1}(y) = 0.95\)</span> where <span class="math inline">\(F(x)\)</span> is the cumulative ditribution function of <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(F^{-1}\)</span> is the quantile function (the inverse of <span class="math inline">\(F\)</span>).</p><p>Obviously that’d mean that <span class="math inline">\(F(x) = \int f(x) \: dx\)</span> and I should start by integrating <span class="math inline">\(f(x)\)</span> and then finding its inverse. However, upon visual inspection, one should see that <span class="math inline">\(f(x)\)</span> is a bitch to integrate.</p><p>Yes it is possible to integrate it by splitting the ranges for the absolute function, then splitting <span class="math inline">\((x+1) = x + 1\)</span>, then <span class="math inline">\(\frac{x}{(x^2+1)^2}\)</span> can be integrated by substitution of <span class="math inline">\(u = x^2+1\)</span> and the other portion can be done trigonometrically. Now because my integration-fu is too bad, let me solve for this numerically. So here’s the trick to (ab)use <code>R</code>.</p><p>First let’s solve for <span class="math inline">\(Z\)</span>. Since <span class="math inline">\(f(x)\)</span> is a density function, then by definition of density functions, <span class="math inline">\(\int_{-\infty}^\infty f(x) \: dx = 1\)</span>. Then,</p><p><span class="math display">\[Z = \int_{-\infty}^{\infty} \frac{|x+1|}{(x^2+1)^2} = 1.785398\]</span></p><p>Great! Now let’s move to <code>R</code>. Unfortunately, <code>R</code> does not have a function for numerical computation of quantiles for arbitrary distribution functions. However, we can build one.</p><p>Finding <span class="math inline">\(y\)</span> above is equivalent to the following optimization problem:</p><p><span class="math display">\[y^* = \arg\min_{y} (F(y) - 0.95)^2\]</span></p><p>Then all we need is an optimization routine to find <span class="math inline">\(y\)</span> that minimizes the squared error <span class="math inline">\(F(y) - 0.95)^2\)</span>. In <code>R</code> there exists the library <code>nlminb</code> for numerical optimization. The functions are below:</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">CDF = <span class="keyword">function</span> (x, dist) &#123;</span><br><span class="line">  integrate(f = dist, lower = -<span class="literal">Inf</span>, upper = x)$value</span><br><span class="line">&#125;</span><br><span class="line">objective = <span class="keyword">function</span> (x, quantile, dist) &#123;</span><br><span class="line">  (CDF(x, dist) - quantile)^<span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line">find_quantile = <span class="keyword">function</span> (dist, quantile) &#123;</span><br><span class="line">  result = nlminb(start = <span class="number">0</span>, objective = objective, quantile = quantile, dist = dist)$par</span><br><span class="line">  <span class="keyword">return</span> (result)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">crazy_eqn = <span class="keyword">function</span> (x) &#123;</span><br><span class="line">  abs(x+<span class="number">1</span>)/((x^<span class="number">2</span>+<span class="number">1</span>)^<span class="number">2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">z = integrate(crazy_eqn, lower=-<span class="literal">Inf</span>, upper=<span class="literal">Inf</span>)</span><br><span class="line"></span><br><span class="line">crazy_eqn_to_integrate = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  z$value * (abs(x+<span class="number">1</span>)/((x^<span class="number">2</span>+<span class="number">1</span>)^<span class="number">2</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">y = find_quantile(dist = crazy_eqn_to_integrate, quantile = <span class="number">0.95</span>)</span><br></pre></td></tr></table></figure><p>Using this, we find that <span class="math inline">\(y = 0.03161596\)</span>. Let’s check this!</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">integrate(crazy_eqn_to_integrate, lower=-<span class="literal">Inf</span>, upper=alpha)</span><br><span class="line"><span class="number">0.95</span> with absolute error &lt; <span class="number">1.8e-11</span></span><br></pre></td></tr></table></figure><p>Booyah. This is why I’m not a statistics major.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;For one of my Statistical Finance homeworks, I had to solve this question.&lt;/p&gt;
&lt;p&gt;Given a density function &lt;span class=&quot;math inline&quot;&gt;\(f(
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Python on EC2</title>
    <link href="http://linanqiu.github.io/2015/10/13/Python-on-EC2/"/>
    <id>http://linanqiu.github.io/2015/10/13/Python-on-EC2/</id>
    <published>2015-10-13T17:12:39.000Z</published>
    <updated>2016-02-17T20:23:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>Running Python on EC2 is a pain, and installing packages can be more of a pain (version clashes, permissions etc). Turns out the easiest way was just to use <code>virtualenv</code>. Here’s a helper script I created:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install gcc-c++ python27-devel atlas-sse3-devel lapack-devel</span><br><span class="line">curl -O from https://bootstrap.pypa.io/get-pip.py</span><br><span class="line">sudo python get-pip.py</span><br><span class="line">pip install virtualenv</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~/</span><br><span class="line">mkdir ./.virtualenv</span><br><span class="line"><span class="built_in">cd</span> ./.virtualenv</span><br><span class="line">virtualenv default</span><br><span class="line"><span class="built_in">source</span> ~/.virtualenv/default/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"source ~/.virtualenv/default/bin/activate"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"></span><br><span class="line">pip install --upgrade pip</span><br><span class="line">pip install numpy</span><br><span class="line">pip install scipy</span><br><span class="line"><span class="comment"># pip install gensim</span></span><br></pre></td></tr></table></figure><p>This would get your <code>virtualenv</code> setup, and the default environment would be used every time you log in. It also upgrades <code>pip</code>, installs <code>numpy</code> and <code>scipy</code> as a demonstration.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Running Python on EC2 is a pain, and installing packages can be more of a pain (version clashes, permissions etc). Turns out the easiest 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Sentiment Analysis Using Doc2Vec</title>
    <link href="http://linanqiu.github.io/2015/10/07/word2vec-sentiment/"/>
    <id>http://linanqiu.github.io/2015/10/07/word2vec-sentiment/</id>
    <published>2015-10-07T18:51:24.000Z</published>
    <updated>2015-11-29T21:15:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sentiment-analysis-using-doc2vec">Sentiment Analysis using Doc2Vec</h1><p>Word2Vec is dope. In short, it takes in a corpus, and churns out vectors for each of those words. What’s so special about these vectors you ask? Well, similar words are near each other. Furthermore, these vectors represent how we use the words. For example, <code>v_man - v_woman</code> is approximately equal to <code>v_king - v_queen</code>, illustrating the relationship that “man is to woman as king is to queen”. This process, in NLP voodoo, is called <strong>word embedding</strong>. These representations have been applied widely. This is made even more awesome with the introduction of Doc2Vec that represents not only words, but entire sentences and documents. Imagine being able to represent an entire sentence using a fixed-length vector and proceeding to run all your standard classification algorithms. Isn’t that amazing?</p><p>However, Word2Vec documentation is shit. The C-code is nigh unreadable (700 lines of highly optimized, and sometimes weirdly optimized code). I personally spent a lot of time untangling Doc2Vec and crashing into ~50% accuracies due to implementation mistakes. This tutorial aims to help other users get off the ground using Word2Vec for their own research. We use Word2Vec for <strong>sentiment analysis</strong> by attempting to classify the Cornell IMDB movie review corpus (http://www.cs.cornell.edu/people/pabo/movie-review-data/).</p><p>The source code used in this demo can be found at https://github.com/linanqiu/word2vec-sentiments</p><h2 id="setup">Setup</h2><h3 id="modules">Modules</h3><p>We use <code>gensim</code>, since <code>gensim</code> has a much more readable implementation of Word2Vec (and Doc2Vec). Bless those guys. We also use <code>numpy</code> for general array manipulation, and <code>sklearn</code> for Logistic Regression classifier.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gensim modules</span></span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> utils</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> LabeledSentence</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Doc2Vec</span><br><span class="line"></span><br><span class="line"><span class="comment"># numpy</span></span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"><span class="comment"># random</span></span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle</span><br><span class="line"></span><br><span class="line"><span class="comment"># classifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br></pre></td></tr></table></figure><h3 id="input-format">Input Format</h3><p>We can’t input the raw reviews from the Cornell movie review data repository. Instead, we clean them up by converting everything to lower case and removing punctuation. I did this via bash, and you can do this easily via Python, JS, or your favorite poison. This step is trivial.</p><p>The result is to have five documents:</p><ul><li><code>test-neg.txt</code>: 12500 negative movie reviews from the test data</li><li><code>test-pos.txt</code>: 12500 positive movie reviews from the test data</li><li><code>train-neg.txt</code>: 12500 negative movie reviews from the training data</li><li><code>train-pos.txt</code>: 12500 positive movie reviews from the training data</li><li><code>train-unsup.txt</code>: 50000 Unlabelled movie reviews</li></ul><p>Each of the reviews should be formatted as such:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">once again mr costner has dragged out a movie for far longer than necessary aside from the terrific sea rescue sequences of which there are very few i just did not care about any of the characters most of us have ghosts in the closet and costner s character are realized early on and then forgotten until much later by which time i did not care the character we should really care about is a very cocky overconfident ashton kutcher the problem is he comes off as kid who thinks he s better than anyone else around him and shows no signs of a cluttered closet his only obstacle appears to be winning over costner finally when we are well past the half way point of this stinker costner tells us all about kutcher s ghosts we are told why kutcher is driven to be the best with no prior inkling or foreshadowing no magic here it was all i could do to keep from turning it off an hour in</span><br><span class="line">this is an example of why the majority of action films are the same generic and boring there s really nothing worth watching here a complete waste of the then barely tapped talents of ice t and ice cube who ve each proven many times over that they are capable of acting and acting well don t bother with this one go see new jack city ricochet or watch new york undercover for ice t or boyz n the hood higher learning or friday for ice cube and see the real deal ice t s horribly cliched dialogue alone makes this film grate at the teeth and i m still wondering what the heck bill paxton was doing in this film and why the heck does he always play the exact same character from aliens onward every film i ve seen with bill paxton has him playing the exact same irritating character and at least in aliens his character died which made it somewhat gratifying overall this is second rate action trash there are countless better films to see and if you really want to see this one watch judgement night which is practically a carbon copy but has better acting and a better script the only thing that made this at all worth watching was a decent hand on the camera the cinematography was almost refreshing which comes close to making up for the horrible film itself but not quite</span><br></pre></td></tr></table></figure><p>The sample up there contains two movie reviews, each one taking up one entire line. Yes, <strong>each document should be on one line, separated by new lines</strong>. This is extremely important, because our parser depends on this to identify sentences.</p><h3 id="feeding-data-to-doc2vec">Feeding Data to Doc2Vec</h3><p>Doc2Vec (the portion of <code>gensim</code> that implements the Doc2Vec algorithm) does a great job at word embedding, but a terrible job at reading in files. It only takes in <code>LabeledLineSentence</code> classes which basically yields <code>LabeledSentence</code>, a class from <code>gensim.models.doc2vec</code> representing a single sentence. Why the “Labeled” word? Well, here’s how Doc2Vec differs from Word2Vec.</p><p>Word2Vec simply converts a word into a vector.</p><p>Doc2Vec not only does that, but also aggregates all the words in a sentence into a vector. To do that, it simply treats a sentence label as a special word, and does some voodoo on that special word. Hence, that special word is a label for a sentence.</p><p>So we have to format sentences into</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="string">'word1'</span>, <span class="string">'word2'</span>, <span class="string">'word3'</span>, <span class="string">'lastword'</span>], [<span class="string">'label1'</span>]]</span><br></pre></td></tr></table></figure><p><code>LabeledSentence</code> is simply a tidier way to do that. It contains a list of words, and a label for the sentence. We don’t really need to care about how <code>LabeledSentence</code> works exactly, we just have to know that it stores those two things – a list of words and a label.</p><p>However, we need a way to convert our new line separated corpus into a collection of <code>LabeledSentence</code>s. The default constructor for the default <code>LabeledLineSentence</code> class in Doc2Vec can do that for a single text file, but can’t do that for multiple files. In classification tasks however, we usually deal with multiple documents (test, training, positive, negative etc). Ain’t that annoying?</p><p>So we write our own <code>LabeledLineSentence</code> class. The constructor takes in a dictionary that defines the files to read and the label prefixes sentences from that document should take on. Then, Doc2Vec can either read the collection directly via the iterator, or we can access the array directly. We also need a function to return a permutated version of the array of <code>LabeledSentence</code>s. We’ll see why later on.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabeledLineSentence</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, sources)</span>:</span></span><br><span class="line">        self.sources = sources</span><br><span class="line">        </span><br><span class="line">        flipped = &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># make sure that keys are unique</span></span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> sources.items():</span><br><span class="line">            <span class="keyword">if</span> value <span class="keyword">not</span> <span class="keyword">in</span> flipped:</span><br><span class="line">                flipped[value] = [key]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> Exception(<span class="string">'Non-unique prefix encountered'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> source, prefix <span class="keyword">in</span> self.sources.items():</span><br><span class="line">            <span class="keyword">with</span> utils.smart_open(source) <span class="keyword">as</span> fin:</span><br><span class="line">                <span class="keyword">for</span> item_no, line <span class="keyword">in</span> enumerate(fin):</span><br><span class="line">                    <span class="keyword">yield</span> LabeledSentence(utils.to_unicode(line).split(), [prefix + <span class="string">'_%s'</span> % item_no])</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_array</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.sentences = []</span><br><span class="line">        <span class="keyword">for</span> source, prefix <span class="keyword">in</span> self.sources.items():</span><br><span class="line">            <span class="keyword">with</span> utils.smart_open(source) <span class="keyword">as</span> fin:</span><br><span class="line">                <span class="keyword">for</span> item_no, line <span class="keyword">in</span> enumerate(fin):</span><br><span class="line">                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + <span class="string">'_%s'</span> % item_no]))</span><br><span class="line">        <span class="keyword">return</span> self.sentences</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sentences_perm</span><span class="params">(self)</span>:</span></span><br><span class="line">        shuffle(self.sentences)</span><br><span class="line">        <span class="keyword">return</span> self.sentences</span><br></pre></td></tr></table></figure><p>Now we can feed the data files to <code>LabeledLineSentence</code>. As we mentioned earlier, <code>LabeledLineSentence</code> simply takes a dictionary with keys as the file names and values the special prefixes for sentences from that document. The prefixes need to be unique, so that there is no ambiguitiy for sentences from different documents.</p><p>The prefixes will have a counter appended to them to label individual sentences in the documetns.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sources = &#123;<span class="string">'test-neg.txt'</span>:<span class="string">'TEST_NEG'</span>, <span class="string">'test-pos.txt'</span>:<span class="string">'TEST_POS'</span>, <span class="string">'train-neg.txt'</span>:<span class="string">'TRAIN_NEG'</span>, <span class="string">'train-pos.txt'</span>:<span class="string">'TRAIN_POS'</span>, <span class="string">'train-unsup.txt'</span>:<span class="string">'TRAIN_UNS'</span>&#125;</span><br><span class="line"></span><br><span class="line">sentences = LabeledLineSentence(sources)</span><br></pre></td></tr></table></figure><h2 id="model">Model</h2><h3 id="building-the-vocabulary-table">Building the Vocabulary Table</h3><p>Doc2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them). So we feed it the array of sentences. <code>model.build_vocab</code> takes an array of <code>LabeledLineSentence</code>, hence our <code>to_array</code> function in the <code>LabeledLineSentences</code> class.</p><p>If you’re curious about the parameters, do read the Word2Vec documentation. Otherwise, here’s a quick rundown:</p><ul><li><code>min_count</code>: ignore all words with total frequency lower than this. You have to set this to 1, since the sentence labels only appear once. Setting it any higher than 1 will miss out on the sentences.</li><li><code>window</code>: the maximum distance between the current and predicted word within a sentence. Word2Vec uses a skip-gram model, and this is simply the window size of the skip-gram model.</li><li><code>size</code>: dimensionality of the feature vectors in output. 100 is a good number. If you’re extreme, you can go up to around 400.</li><li><code>sample</code>: threshold for configuring which higher-frequency words are randomly downsampled</li><li><code>workers</code>: use this many worker threads to train the model</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Doc2Vec(min_count=<span class="number">1</span>, window=<span class="number">10</span>, size=<span class="number">100</span>, sample=<span class="number">1e-4</span>, negative=<span class="number">5</span>, workers=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">model.build_vocab(sentences.to_array())</span><br></pre></td></tr></table></figure><h3 id="training-doc2vec">Training Doc2Vec</h3><p>Now we train the model. The model is better trained if <strong>in each training epoch, the sequence of sentences fed to the model is randomized</strong>. This is important: missing out on this steps gives you really shitty results. This is the reason for the <code>sentences_perm</code> method in our <code>LabeledLineSentences</code> class.</p><p>We train it for 10 epochs. If I had more time, I’d have done 20.</p><p>This process takes around 10 mins, so go grab some coffee.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    model.train(sentences.sentences_perm())</span><br></pre></td></tr></table></figure><h3 id="saving-and-loading-models">Saving and Loading Models</h3><p>To avoid training the model again, we can save it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'./imdb.d2v'</span>)</span><br></pre></td></tr></table></figure><p>And load it.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = Doc2Vec.load(<span class="string">'./imdb.d2v'</span>)</span><br></pre></td></tr></table></figure><h3 id="inspecting-the-model">Inspecting the Model</h3><p>Let’s see what our model gives. It seems that it has kind of understood the word <code>good</code>, since the most similar words to good are <code>glamorous</code>, <code>spectacular</code>, <code>astounding</code> etc. This is really awesome (and important), since we are doing sentiment analysis.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'good'</span>)</span><br></pre></td></tr></table></figure><pre><code>[(u&#39;excellent&#39;, 0.49283793568611145), (u&#39;rudolfs&#39;, 0.43693652749061584), (u&#39;chattanooga&#39;, 0.4162406325340271), (u&#39;dodgy&#39;, 0.4156044125556946), (u&#39;hurts&#39;, 0.4120287299156189), (u&#39;maytime&#39;, 0.4106871485710144), (u&#39;problematic&#39;, 0.4097048342227936), (u&#39;lousy&#39;, 0.40627604722976685), (u&#39;humanization&#39;, 0.40399202704429626), (u&#39;detaches&#39;, 0.40335381031036377)]</code></pre><p>We can also prop the hood open and see what the model actually contains. This is each of the vectors of the words and sentences in the model. We can access all of them using <code>model.syn0</code> (for the geekier ones among you, <code>syn0</code> is simply the output layer of the shallow neural network). However, we don’t want to use the entire <code>syn0</code> since that contains the vectors for the words as well, but we are only interested in the ones for sentences.</p><p>Here’s a sample vector for the first sentence in the training set for negative reviews:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model[<span class="string">'TRAIN_NEG_0'</span>]</span><br></pre></td></tr></table></figure><pre><code>array([-0.29009071, -0.12225933,  0.31921104,  0.12690307, -0.78038144,        0.22722125,  0.20833154,  0.43868524,  0.23561548, -0.36413202,       -0.15643257,  0.00461203,  0.08018852, -0.08258788, -0.2760058 ,        0.10478264, -0.08799575, -0.37180164, -0.33013585,  0.18241297,        0.88061708,  0.31900761,  0.23834513, -0.10049706,  0.28829831,       -0.10783304,  0.0262799 ,  0.14395693, -0.10469725, -0.52104455,       -0.65519089,  0.55344343,  0.01129826,  0.04632513, -0.15539262,       -0.28914869,  0.33816752, -0.62154663, -0.02470196,  0.62869382,        0.11478873, -0.25910828, -0.08567604, -0.02737088, -0.07904764,       -1.01183033, -0.17131189,  0.04178049, -0.25471294, -0.42550623,       -0.58592063, -0.31924966,  0.17547569,  0.20776786, -0.34506091,        0.00154094,  0.30706513,  0.09242618,  0.02120452, -0.09602273,       -0.40714192,  0.47554722,  0.36416441,  0.01952979,  0.6814065 ,       -0.15965664, -0.22644502, -0.24989423,  0.40612498,  0.27820811,       -0.35662967,  0.27260619,  0.07444458, -0.40855888,  0.09954116,        0.11635212, -0.13925125,  0.18950833,  0.10479139, -0.17033359,        0.06540342, -0.01675605,  0.00690889, -0.06219884,  0.13443422,        0.05676769, -0.19048406, -0.08656956,  0.16460682, -0.18292029,        0.42254189,  0.23022693, -0.10003133, -0.52825296,  0.18979053,       -0.10800292,  0.01646511, -0.00504603,  0.173182  ,  0.19618541], dtype=float32)</code></pre><h2 id="classifying-sentiments">Classifying Sentiments</h2><h3 id="training-vectors">Training Vectors</h3><p>Now let’s use these vectors to train a classifier. First, we must extract the training vectors. Remember that we have a total of 25000 training reviews, with equal numbers of positive and negative ones (12500 positive, 12500 negative).</p><p>Hence, we create a <code>numpy</code> array (since the classifier we use only takes numpy arrays. There are two parallel arrays, one containing the vectors (<code>train_arrays</code>) and the other containing the labels (<code>train_labels</code>).</p><p>We simply put the positive ones at the first half of the array, and the negative ones at the second half.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_arrays = numpy.zeros((<span class="number">25000</span>, <span class="number">100</span>))</span><br><span class="line">train_labels = numpy.zeros(<span class="number">25000</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12500</span>):</span><br><span class="line">    prefix_train_pos = <span class="string">'TRAIN_POS_'</span> + str(i)</span><br><span class="line">    prefix_train_neg = <span class="string">'TRAIN_NEG_'</span> + str(i)</span><br><span class="line">    train_arrays[i] = model[prefix_train_pos]</span><br><span class="line">    train_arrays[<span class="number">12500</span> + i] = model[prefix_train_neg]</span><br><span class="line">    train_labels[i] = <span class="number">1</span></span><br><span class="line">    train_labels[<span class="number">12500</span> + i] = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>The training array looks like this: rows and rows of vectors representing each sentence.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> train_arrays</span><br></pre></td></tr></table></figure><pre><code>[[ 0.18376358  0.14441976  0.09568384 ..., -0.28158343  0.29901281   0.30613518] [-0.24681839  0.71076155 -0.40998992 ...,  0.39490703 -0.0812839   0.21507834] [-0.05608005  0.48018554  0.35442445 ...,  0.28135905 -0.3482835   0.23772541] ...,  [-0.23058473  0.03048714  0.8894285  ..., -0.5808149   0.18430299  -0.08481987] [ 0.33824882  0.32103017 -0.24168059 ..., -0.55988938  0.61781228  -0.4085339 ] [ 0.3712599  -0.18826039  0.30162022 ..., -0.21118143  0.00217488  -0.4914557 ]]</code></pre><p>The labels are simply category labels for the sentence vectors – 1 representing positive and 0 for negative.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> train_labels</span><br></pre></td></tr></table></figure><pre><code>[ 1.  1.  1. ...,  0.  0.  0.]</code></pre><h3 id="testing-vectors">Testing Vectors</h3><p>We do the same for testing data – data that we are going to feed to the classifier after we’ve trained it using the training data. This allows us to evaluate our results. The process is pretty much the same as extracting the results for the training data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">test_arrays = numpy.zeros((<span class="number">25000</span>, <span class="number">100</span>))</span><br><span class="line">test_labels = numpy.zeros(<span class="number">25000</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">12500</span>):</span><br><span class="line">    prefix_test_pos = <span class="string">'TEST_POS_'</span> + str(i)</span><br><span class="line">    prefix_test_neg = <span class="string">'TEST_NEG_'</span> + str(i)</span><br><span class="line">    test_arrays[i] = model[prefix_test_pos]</span><br><span class="line">    test_arrays[<span class="number">12500</span> + i] = model[prefix_test_neg]</span><br><span class="line">    test_labels[i] = <span class="number">1</span></span><br><span class="line">    test_labels[<span class="number">12500</span> + i] = <span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="classification">Classification</h3><p>Now we train a logistic regression classifier using the training data.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">classifier = LogisticRegression()</span><br><span class="line">classifier.fit(train_arrays, train_labels)</span><br></pre></td></tr></table></figure><pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,          intercept_scaling=1, penalty=&#39;l2&#39;, random_state=None, tol=0.0001)</code></pre><p>And find that we have achieved near 87% accuracy for sentiment analysis. This is rather incredible, given that we are only using a linear SVM and a very shallow neural network.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classifier.score(test_arrays, test_labels)</span><br></pre></td></tr></table></figure><pre><code>0.87312000000000001</code></pre><p>Isn’t this fantastic? Hope I saved you some time!</p><h2 id="references">References</h2><ul><li>Doc2vec: https://radimrehurek.com/gensim/models/doc2vec.html</li><li>Paper that inspired this: http://arxiv.org/abs/1405.4053</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;sentiment-analysis-using-doc2vec&quot;&gt;Sentiment Analysis using Doc2Vec&lt;/h1&gt;
&lt;p&gt;Word2Vec is dope. In short, it takes in a corpus, and chu
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Using CircleCI to Grade Java Assignments</title>
    <link href="http://linanqiu.github.io/2015/08/21/Using-CircleCI-to-Grade-Java-Assignments/"/>
    <id>http://linanqiu.github.io/2015/08/21/Using-CircleCI-to-Grade-Java-Assignments/</id>
    <published>2015-08-21T18:51:24.000Z</published>
    <updated>2015-10-13T17:15:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>It’s ridiculous we don’t have a proper solution that uses Continuous Integration (CI) to grade homeworks hosted on GitHub.</p><p>CI, in short, is just a server that runs unit tests on your code every time you commit it. That means instead of you having to run unit tests before your commit your code (or manually run them after you commit them), a little robot checks your code against your unit tests every time you commit the code. That little robot never gets tired, doesn’t need to be fed. In short, these little robots are way better than human Teaching Assistants (TAs) (who in contrast, need to be fed pizza).</p><p>Given that I’ll be Head TAing a class with nearly 300 students this fall, I can’t afford enough pizzas to keep my team running. Or maybe I can, but I prefer not to. So why not get CI servers to grade homeworks? That requires two things:</p><ol style="list-style-type: decimal"><li>Getting students on GitHub (and submitting homeworks via GitHub)</li><li>Grading those homeworks on GitHub</li></ol><p>I’ll talk about (1) in a later post when I have the system fully set up, but basically it involves playing nice to GitHub and getting a team with lots and lots of private repositories. Then you give each student one private repository (so that they can’t copy. But then again, since they’re all on GitHub, it should be easy to implement a cheat check. That’s for next time).</p><h2 id="homework-assignment">Homework Assignment</h2><p>Let’s say that the student is supposed to write an assignment like this:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FibonacciRecursive</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(fibonacci(<span class="number">5</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">fibonacci</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// this is the method that student codes up</span></span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (n == <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> fibonacci(n - <span class="number">1</span>) + fibonacci(n - <span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This happens in a file called <code>FibonacciRecursive.java</code>. (Wow surprise).</p><p>This is usually one of the first assignments in a data structures class or a last assignment in an intro programming class. Whatever it is, we can be sure of the following:</p><ol style="list-style-type: decimal"><li>You do not want to introduce unnecessary files into the homework package that the student works with. This confuses a student easily, and no good packaging software exists for Java which is as simple and intuitive as Grunt or NPM in JavaScript. You probably don’t want to use Maven or Ant.</li><li>You probably want to avoid unit tests, since they make it difficult for you to score the entire assignment, run asynchronously, and produce rather ugly output.</li></ol><p>Given those two limitations, you are set back by quite a bit, since most CI servers only run well on those systems. Give it Java with Maven and CircleCI (one of the larger CI services out there that provide free CI) will work like magic. However, give it non standard stuff and it coughs blood. Unfortunately, that bloody puddle is what we have to work with.</p><h2 id="setting-up-circleci">Setting up CircleCI</h2><p>(Side note: I chose CircleCI not TravisCI because Circle allows for private repositories while Travis insists on public).</p><p>Without a single unit test command, we have to be a little hacky with CircleCI. Now here’s how CircleCI runs in a nutshell:</p><ol style="list-style-type: decimal"><li>CircleCI reads off <code>circle.yml</code> in your repository. If it finds that file, it follows the instructions in that file. Otherwise, it tries to infer your environment (be it some Ruby thingum, Maven for Java, or Grunt for JS).</li><li>It runs the commands in <code>circle.yml</code> or the inferred commands.</li><li>Specifically, in the unit test portion, it runs every command in the unit test portion. If all of them produces an exit code of 0 (that means everything’s good), the unit tests pass. If any of them produce a non-0 exit code, unit tests fail, you get an error.</li><li>The results of these get emailed to you.</li></ol><p>That sounds cool right? So let’s start appropriating that system for homework grading.</p><h2 id="game-plan">Game Plan</h2><p>Your directory will end up containing</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- FibonacciRecursive.java</span><br><span class="line">- Grader.java</span><br><span class="line">- build.sh</span><br><span class="line">- circle.yml</span><br></pre></td></tr></table></figure><p>Here’s how everything works:</p><ol style="list-style-type: decimal"><li>CircleCI reads <code>circle.yml</code> which tells the server to run <code>build.sh</code> instead of running standard unit tests</li><li><code>build.sh</code> does the following<ol style="list-style-type: decimal"><li>It tries to compile <code>FibonacciRecursive.java</code> and <code>Grader.java</code></li><li>It runs Grader (now compiled as a class). Grader runs a series of tests on FibonacciRecursive, printing out the score that the student receives along each step. Depending on the score, Grader returns with an exit code of either 0 or 1.</li></ol></li><li><code>build.sh</code> returns whatever exit code Grader returns.</li><li>CircleCI consumes that exit code.</li></ol><p>And this is how we’ll abuse CircleCI to grade homeworks.</p><h2 id="overriding-circle.yml">Overriding <code>circle.yml</code></h2><p>We know that we have to override <code>circle.yml</code> to not try and run Maven / Ant / freeze up and die when we run our custom Java stuff. What’s simpler than making it run a <code>.sh</code> script?</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Customize the test machine</span></span><br><span class="line"><span class="attr">machine:</span></span><br><span class="line">  <span class="comment"># Version of java to use</span></span><br><span class="line"><span class="attr">  java:</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">oraclejdk8</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Customize test commands</span></span><br><span class="line"><span class="attr">test:</span></span><br><span class="line"><span class="attr">  override:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">sh</span> <span class="string">build.sh</span></span><br></pre></td></tr></table></figure><p>That’s all that should go into your <code>circle.yml</code>.</p><h2 id="creating-build.sh">Creating <code>build.sh</code></h2><p>Now your <code>build.sh</code> should just compile every <code>.java</code> file in your directory and run Grader. So that’s exactly what it does:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">javac *.java</span><br><span class="line">java Grader</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><h2 id="creating-a-grader-tool-in-java">Creating a Grader Tool in Java</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Grader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> score = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> scoreMax = <span class="number">50</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Fibonacci</span></span><br><span class="line">        <span class="comment">// Test 0</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 1 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 1</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 2 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 5</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">5</span>) == <span class="number">5</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 3 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 10</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">10</span>) == <span class="number">55</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 4 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test -1</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(-<span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 5 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (score != scoreMax) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This should be rather self explanatory – you’re basically making a series of “assertions”, but tabulating scores at the same time.</p><h2 id="pushing-to-github">Pushing to GitHub</h2><p>We push all this code to a GitHub repository:</p><p><a href="https://github.com/linanqiu/circle-ci-java-assignment-grading" class="uri" target="_blank" rel="noopener">https://github.com/linanqiu/circle-ci-java-assignment-grading</a></p><h2 id="setting-up-circleci-1">Setting up CircleCI</h2><p>Add your repository on CircleCI after you’ve set up an account.</p><div class="figure"><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci1.png"></div><div class="figure"><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci2.png"></div><p>You’ll see that the build has started.</p><div class="figure"><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci3.png"></div><p>And you should get the results of <code>Grader.java</code> being run on <code>FibonacciRecursive.java</code> as a result of <code>build.sh</code> being run as told by <code>circle.yml</code> (Phew)</p><div class="figure"><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci4.png"></div><h2 id="grade-on-commit">Grade On Commit</h2><p>It shows that we’ve failed the assignment and didn’t get full marks. Well obviously, since we made <code>Test 5</code> in the Grader an errorneous test. It should be producing 0 instead of 1. Let’s change that line:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Grader</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> score = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> scoreMax = <span class="number">50</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Fibonacci</span></span><br><span class="line">        <span class="comment">// Test 0</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 1 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 1</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 2 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 5</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">5</span>) == <span class="number">5</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 3 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test 10</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(<span class="number">10</span>) == <span class="number">55</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 4 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Test -1</span></span><br><span class="line">        <span class="comment">// Modified</span></span><br><span class="line">        <span class="keyword">if</span> (FibonacciRecursive.fibonacci(-<span class="number">1</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Test 5 Passed +10"</span>);</span><br><span class="line">            score += <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (score != scoreMax) &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"Score: "</span> + score + <span class="string">"/"</span> + scoreMax);</span><br><span class="line">            System.exit(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We make this modification, and submit. We see that CircleCI has already seen the new commit and started building it:</p><div class="figure"><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci5.png"></div><p>Seems like the problem has been fixed! And this happened without us intervening (and no pizzas involved).</p><div class="figure"><img src="/images/Using-CircleCI-to-Grade-Java-Assignments/circleci6.png"></div><p>Isn’t this awesome? Even awesome-er, CircleCI has a great API. That means you can use this to create a live scoreboard for your students / email notifications every time they submit code.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It’s ridiculous we don’t have a proper solution that uses Continuous Integration (CI) to grade homeworks hosted on GitHub.&lt;/p&gt;
&lt;p&gt;CI, in 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>If Greece Ran on Digital Currency</title>
    <link href="http://linanqiu.github.io/2015/07/09/greece-cash/"/>
    <id>http://linanqiu.github.io/2015/07/09/greece-cash/</id>
    <published>2015-07-09T04:10:41.000Z</published>
    <updated>2015-07-09T04:12:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>If the Greeks had no physical cash and only digital cash (in banks), they won’t be able to stash paper cash to wait out the conversion and drachma devaluation. Capital control would be easy and effective. Then, everyone would receive a haircut, and since the rumored haircut right now stands at anything above €8000, this would probably affect rich people disproportionately. So we end up getting a currency conversion that is hugely progressive tax from a crisis.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;If the Greeks had no physical cash and only digital cash (in banks), they won’t be able to stash paper cash to wait out the conversion an
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Getting Numpy on EC2</title>
    <link href="http://linanqiu.github.io/2015/06/17/ec2-numpy/"/>
    <id>http://linanqiu.github.io/2015/06/17/ec2-numpy/</id>
    <published>2015-06-17T04:48:14.000Z</published>
    <updated>2016-05-06T03:04:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>After spending around half an hour trying to install <code>numpy</code> on Amazon Linux EC2, this <a href="http://stackoverflow.com/a/25456990" target="_blank" rel="noopener">StackOverflow answer</a> saved me</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install gcc-c++ python27-devel atlas-sse3-devel lapack-devel</span><br><span class="line">wget https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.2.tar.gz</span><br><span class="line">tar xzf virtualenv-1.11.2.tar.gz </span><br><span class="line">python27 virtualenv-1.11.2/virtualenv.py sk-learn</span><br><span class="line">. sk-learn/bin/activate</span><br><span class="line">pip install numpy</span><br></pre></td></tr></table></figure><p>Simply run and grab coffee.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After spending around half an hour trying to install &lt;code&gt;numpy&lt;/code&gt; on Amazon Linux EC2, this &lt;a href=&quot;http://stackoverflow.com/a/254
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Class Score Analysis for CS 3134 Data Structures</title>
    <link href="http://linanqiu.github.io/2015/05/20/class-score-analysis/"/>
    <id>http://linanqiu.github.io/2015/05/20/class-score-analysis/</id>
    <published>2015-05-20T04:48:14.000Z</published>
    <updated>2016-05-06T03:04:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>After TA-ing COMS W3134 Data Structures for a semester, I was left with a sizable amount of data from the homeworks, exams, and piazza usage. So I decided to make some pretty graphs out of them. This stemmed from my frustration at previous classes – why only give students a mean and standard deviation if there are so many more dimensions to the data? And perhaps this may even inspire a student or two to like statistics (which unfortunately, given the way it is taught in Columbia, is hardly inspiring).</p><p>So here’s some data porn.</p><p>To make sense of it all, I’m going to invoke an imaginary student called George. George is that annoying student at the front of the class that questions the professor non-stop regarding the nitty gritty details of the course. Yes there’s always George.</p><h2 id="overall-distributions">Overall Distributions</h2><p>*George: What’s the mean and standard deviation for each homework, the midterm, and the final? Are they normal? You know I have this hypothesis that homeworks are bimodal…“*</p><p>Now now George. Here’s all the info you need:</p><div class="figure"><img src="/images/class-score-analysis/homework-exam-summary.png"></div><p>The mode of some homeworks tend to be around full marks, which is rather unsurprising given the nature of homeworks. Some fulfil all requirements, while others simply throw their hands in the air and well…not do them. This also reflects the content of the homeworks. Homework 3 and 4 tend to have many small (unrelated) parts hence it is entirely possible to score well in one and not others. The rest of them tend to have a larger single programming component.</p><h2 id="homework-covariance">Homework Covariance</h2><p><em>George: Do students do consistenly well / bad in all the homeworks or do they tend to vary quite a bit?</em></p><p>Great question George! Let’s see. Here we are interested if homework grades, when taken as a whole, move together. That means if Student A scores well in Homework 1, 2, and 3, does he score well in Homework 4 and 5 as well? What about Student B? What about other homeworks?</p><p>Turns out the easiest way to answer this is: what is the <strong>correlation</strong> of the homework scores.</p><div class="figure"><img src="/images/class-score-analysis/corrplot.png"></div><p>Turns out most of them are moderately correlated. We can quantify this further by using <strong>Principal Component Analysis</strong> (PCA). Intuitively, PCA is a method that distills a common “factor” for all the data. After running PCA on the data, we have the following results:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Loadings:</span><br><span class="line">         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5</span><br><span class="line">data.hw1 -0.324 -0.103  0.139         0.927</span><br><span class="line">data.hw2 -0.410 -0.433  0.686  0.317 -0.270</span><br><span class="line">data.hw3 -0.612        -0.653  0.428       </span><br><span class="line">data.hw4 -0.510               -0.825 -0.240</span><br><span class="line">data.hw5 -0.304  0.892  0.286  0.172</span><br></pre></td></tr></table></figure><p>This means that the PCA reduced our data from 5 dimensions (since we had 5 datasets), the first of which is the homeworks moving in the same direction. But how much of the actual change is represented by that dimension? Turns out, quite a lot!</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Importance of components:</span><br><span class="line">                           Comp.1     Comp.2     Comp.3     Comp.4     Comp.5</span><br><span class="line">Standard deviation     40.9058984 25.1014708 23.9316752 20.2610806 19.4151851</span><br><span class="line">Proportion of Variance  0.4567392  0.1719867  0.1563301  0.1120525  0.1028915</span><br><span class="line">Cumulative Proportion   0.4567392  0.6287259  0.7850560  0.8971085  1.0000000</span><br></pre></td></tr></table></figure><p>The first dimension when all 5 homeworks are moving in the same direction accounts for around 41% of the total amount of variation. That means a common “force” that moves all the homeworks in the same direction accounts for around half the changes in homeworks from student to student.</p><p>This means that students’ homeworks are covaried to a pretty large extent. So George, students who do well in some homeworks tend to do well in others as well.</p><h2 id="homework-and-exams">Homework and Exams</h2><p><em>George: What about the age old idiom that students who do well in homeworks tend to do better in exams? I was told by my elementary school teacher that…</em></p><p>Calm your tits George.</p><p>Let’s run a linear regression of homework against midterm and finals. Intuitively, this answers the question: if a question scores one point better on homeworks, how much better does he score on midterms / finals?</p><p>Let’s look at midterms first:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept) 39.82253    4.52721   8.796 7.88e-16 ***</span><br><span class="line">data$hw      0.07482    0.01105   6.768 1.52e-10 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><br><span class="line"></span><br><span class="line">Residual standard error: 13.79 on 193 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.1918,    Adjusted R-squared:  0.1876 </span><br><span class="line">F-statistic: 45.81 on 1 and 193 DF,  p-value: 1.523e-10</span><br></pre></td></tr></table></figure><p>Turns out homeworks correlate <em>pretty</em> well with midterm. A 1 point increase in homework (remember homeworks are graded out of 500, since I excluded homework 6 which we are still grading at the time of writing) translates into a 0.075 point increase in midterms. This is a pretty significant effect, but the R-squared is rather low, meaning that this does not hold for all students very strictly.</p><p>Let’s look at finals now:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Coefficients:</span><br><span class="line">            Estimate Std. Error t value Pr(&gt;|t|)    </span><br><span class="line">(Intercept)  25.3966     4.7103   5.392 2.02e-07 ***</span><br><span class="line">data$hw       0.1108     0.0115   9.637  &lt; 2e-16 ***</span><br><span class="line">---</span><br><span class="line">Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><br><span class="line"></span><br><span class="line">Residual standard error: 14.35 on 193 degrees of freedom</span><br><span class="line">Multiple R-squared:  0.3249,    Adjusted R-squared:  0.3214 </span><br><span class="line">F-statistic: 92.87 on 1 and 193 DF,  p-value: &lt; 2.2e-16</span><br></pre></td></tr></table></figure><p>Homeworks correlate a lot better with finals than midterms. Again, a 1 point increase in homework translates into a 0.11 point increase in finals, and we have a higher R-squared here.</p><div class="figure"><img src="/images/class-score-analysis/homework-midterm-final.png"></div><p>These two correlations are visualized in the scatter plot above.</p><h2 id="piazza">Piazza</h2><p><em>George: So I’ve been contributing a lot on piazza. My grades are awesome. Does that relationship hold?</em></p><p>Finally, I always tell students that the more they use piazza, the better they are able to learn. Asking question gets you answers, which makes you better. Answering answers makes you even better, since you learn way more by teaching than just being spoon-fed.</p><p>Well, you can answer these for yourself here.</p><div class="figure"><img src="/images/class-score-analysis/piazza-homework.png"></div><div class="figure"><img src="/images/class-score-analysis/piazza-midterm.png"></div><div class="figure"><img src="/images/class-score-analysis/piazza-final.png"></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After TA-ing COMS W3134 Data Structures for a semester, I was left with a sizable amount of data from the homeworks, exams, and piazza us
      
    
    </summary>
    
    
  </entry>
  
</feed>
