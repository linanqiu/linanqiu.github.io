<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Pandamonium | Musings of a Panda</title>
  <meta name="author" content="Linan Qiu">
  
  <meta name="description" content="Linan&#39;s Blog">
  
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:site_name" content="Pandamonium"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Pandamonium" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
</head>


<body>
<div id="page" class="site">
  <div id="primary" class="content-area">

    <header id="header" class="inner"><div class="site-branding">
  <h1 class="site-title">
    <a href="/">Pandamonium</a>
  </h1>
  <p class="site-description">Musings of a Panda</p>
</div>
<nav id="site-navigation" class="main-navigation" role="navigation">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
</nav></header>

    <article id="content" class="site-content">
      <main id="main" class="site-main posts-loop" role="main">
        
  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2016/06/09/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/"><span>Crude Oil Inventory and Intraday Oil Price Movements</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/06/09/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/" rel="bookmark">
        <time class="entry-date published" datetime="2016-06-10T02:21:50.000Z">
          2016-06-09
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br></pre></td></tr></table></figure>
<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p><a href="http://www.wsj.com/articles/oil-at-seven-month-high-as-u-s-stockpiles-drop-1464168624" target="_blank" rel="external">News</a> <a href="http://www.marketwatch.com/story/oil-prices-march-past-50-amid-signs-of-us-inventory-falls-2016-06-08" target="_blank" rel="external">articles</a> love citing the crude inventory as reasons for movements in oil prices. Quoting from the WSJ:</p>
<blockquote>
<p>U.S. inventories are closely watched by traders as the first indicator of the global supply-and-demand balance. Stockpiles have fallen in recent weeks from their highest level in more than 80 years, boosting expectations that the global glut of crude that has weighed on prices for nearly two years is now receding.</p>
<p>The U.S. Energy Information Administration said U.S. crude stockpiles fell 4.2 million barrels last week, while analysts polled by The Wall Street Journal had expected a decrease of 2.5 million barrels.</p>
</blockquote>
<p>So this got me really curious. How good is the Energy Information Administration (EIA) figure as a predictor of crude oil prices? To test this, I decided to use the following data:</p>
<ol>
<li>EIA US Crude Inventory ex-SPR (Strategic Petroleum Reserve). This data (basically the one that WSJ quoted on top) is <strong>usually released every Wednesday afternoon</strong>. This data is going to be a single number for every week.</li>
<li>US Oil Fund (USO), an ETF that tracks the front month West Texas Intermediate (WTI) futures. This is going to be a set of numbers daily describing the <strong>open, high, low, close</strong> (OHLC) prices. We are most interested in the extent of movement from the beginning of the day (before EIA data is released) to the end of the day (after EIA data is released). Hence, we define <strong>intraday return</strong> as <strong>(close - open) / close</strong> for a specific day. Furthermore, we are probably interested in this figure for <strong>Wednesdays</strong> given that EIA data is released every Wednesday.</li>
</ol>
<h1 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h1><p>I pull the data from Thomson Datastream using this <a href="https://github.com/vfilimonov/pydatastream" target="_blank" rel="external">wonderful Python interface</a>. If you want to replicate this, you’d need to get yourself some Datastream credentials. Ask your school librarian very nicely. :)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pydatastream</span><br><span class="line"><span class="keyword">from</span> pydatastream <span class="keyword">import</span> Datastream</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">import</span> statsmodels.graphics.tsaplots <span class="keyword">as</span> tsaplots</span><br><span class="line"><span class="keyword">import</span> statsmodels.formula.api <span class="keyword">as</span> sm</span><br><span class="line"></span><br><span class="line">credentials = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'credentials.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> credentials_file:</span><br><span class="line">    line = credentials_file.readline().split(<span class="string">','</span>)</span><br><span class="line">    credentials[<span class="string">'username'</span>] = line[<span class="number">0</span>]</span><br><span class="line">    credentials[<span class="string">'password'</span>] = line[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">DWE = Datastream(username=credentials[<span class="string">'username'</span>], password=credentials[<span class="string">'password'</span>])</span><br><span class="line">DWE.raise_on_error = <span class="keyword">False</span></span><br></pre></td></tr></table></figure>
<p>The crude oil inventory data has the datastream mnemonic <code>EIA2007</code> (trust me it took me like 2 hours to find it.) Then I plot it to inject some pictures into this post (otherwise you’d find it boring right?) Besides everyone likes pictures.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crude_oil_stock = DWE.fetch([<span class="string">'EIA2007'</span>], date_from=<span class="string">'2000-01-01'</span>, freq=<span class="string">'D'</span>)</span><br><span class="line">uso = DWE.get_OHLC(<span class="string">'U:USO'</span>, date_from=<span class="string">'2000-01-01'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crude_oil_stock.plot()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_6_1.svg" alt="svg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uso.plot()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_7_1.svg" alt="svg"></p>
<p>Uh oh looks like we don’t have complete data before late 2009. Oh well. We just truncate our analysis then.</p>
<p>Now let’s subdivide our data into each of the days of the week: Monday till Friday.</p>
<p>Also, Thomson Datastream’s crude oil stock data seems to be lagged by 2 days. That is, Wednesday’s data seems to only be in the system by Friday. Hence, I shift the inventory data by <code>-2</code> days.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">data = crude_oil_stock.merge(uso, left_index=<span class="keyword">True</span>, right_index=<span class="keyword">True</span>)</span><br><span class="line">data.columns=[<span class="string">'crude_oil_stock'</span>, <span class="string">'uso_close'</span>, <span class="string">'uso_high'</span>, <span class="string">'uso_low'</span>, <span class="string">'uso_open'</span>]</span><br><span class="line">data[<span class="string">'dayofweek'</span>] = data.index.dayofweek</span><br><span class="line">data[<span class="string">'crude_oil_stock'</span>] = data[<span class="string">'crude_oil_stock'</span>].shift(<span class="number">-2</span>)</span><br><span class="line">data = data.dropna()</span><br><span class="line"></span><br><span class="line">data_daily = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    data_daily[dayofweek] = data[data.index.dayofweek == dayofweek]</span><br><span class="line">    data_daily[dayofweek][<span class="string">'uso_intraday_return'</span>] = (data_daily[dayofweek][<span class="string">'uso_close'</span>] - data_daily[dayofweek][<span class="string">'uso_open'</span>]) / data_daily[dayofweek][<span class="string">'uso_open'</span>]</span><br><span class="line">    data_daily[dayofweek][<span class="string">'crude_oil_stock_pct'</span>] = data_daily[dayofweek][<span class="string">'crude_oil_stock'</span>].pct_change()</span><br><span class="line">    data_daily[dayofweek][<span class="string">'crude_oil_stock_diff'</span>] = data_daily[dayofweek][<span class="string">'crude_oil_stock'</span>].diff()</span><br><span class="line">    data_daily[dayofweek] = data_daily[dayofweek].dropna()</span><br></pre></td></tr></table></figure>
<p>We have all the fields that we need for our analysis. They should be pretty self explanatory.</p>
<h1 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h1><p>First we do scatter plots of <code>crude_oil_stock_pct</code>, the percent change of this week’s crude inventory stock on last week’s inventory stock, on <code>uso_intraday_return</code>, the intraday return. Turns out not much of a relationship exists:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    data_daily[dayofweek].plot(kind=<span class="string">'scatter'</span>, x=<span class="string">'crude_oil_stock_pct'</span>, y=<span class="string">'uso_intraday_return'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_0.svg" alt="svg"></p>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_1.svg" alt="svg"></p>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_2.svg" alt="svg"></p>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_3.svg" alt="svg"></p>
<p><img src="/images/Crude-Oil-Inventory-and-Intraday-Oil-Price-Movements/output_13_4.svg" alt="svg"></p>
<p>When I ran OLS regressions on each of them, not only are the R-squared pathetic, the slopes are in entirely wrong direction as well. For example, the slope for Wednesdays is 0.734359432686, which means that oil prices tend to increase intraday when the inventory increases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    model = sm.ols(formula=<span class="string">'uso_intraday_return ~ crude_oil_stock_pct'</span>, data=data_daily[dayofweek])</span><br><span class="line">    results = model.fit()</span><br><span class="line">    print(<span class="string">'Day Of Week '</span> + str(dayofweek))</span><br><span class="line">    print(<span class="string">'Slope '</span> + str(results.params.crude_oil_stock_pct))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Day Of Week 0</span><br><span class="line">Slope 0.0959621772799</span><br><span class="line">Day Of Week 1</span><br><span class="line">Slope -0.202762367053</span><br><span class="line">Day Of Week 2</span><br><span class="line">Slope 0.734359432686</span><br><span class="line">Day Of Week 3</span><br><span class="line">Slope 0.482402080895</span><br><span class="line">Day Of Week 4</span><br><span class="line">Slope 0.179556901751</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> dayofweek <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">    model = sm.ols(formula=<span class="string">'uso_intraday_return ~ crude_oil_stock_pct'</span>, data=data_daily[dayofweek])</span><br><span class="line">    results = model.fit()</span><br><span class="line">    print(<span class="string">'Day Of Week '</span> + str(dayofweek))</span><br><span class="line">    print(<span class="string">''</span>)</span><br><span class="line">    print(results.summary())</span><br></pre></td></tr></table></figure>
<pre><code>Day Of Week 0

                             OLS Regression Results                            
===============================================================================
Dep. Variable:     uso_intraday_return   R-squared:                       0.001
Model:                             OLS   Adj. R-squared:                 -0.002
Method:                  Least Squares   F-statistic:                    0.2613
Date:                 Thu, 09 Jun 2016   Prob (F-statistic):              0.610
Time:                         22:34:39   Log-Likelihood:                 932.68
No. Observations:                  329   AIC:                            -1861.
Df Residuals:                      327   BIC:                            -1854.
Df Model:                            1                                         
Covariance Type:             nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------------
Intercept              -0.0001      0.001     -0.177      0.859        -0.002     0.001
crude_oil_stock_pct     0.0960      0.188      0.511      0.610        -0.273     0.465
==============================================================================
Omnibus:                       46.601   Durbin-Watson:                   1.846
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              268.062
Skew:                           0.364   Prob(JB):                     6.18e-59
Kurtosis:                       7.362   Cond. No.                         239.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Day Of Week 1

                             OLS Regression Results                            
===============================================================================
Dep. Variable:     uso_intraday_return   R-squared:                       0.003
Model:                             OLS   Adj. R-squared:                  0.000
Method:                  Least Squares   F-statistic:                     1.144
Date:                 Thu, 09 Jun 2016   Prob (F-statistic):              0.285
Time:                         22:34:39   Log-Likelihood:                 1035.4
No. Observations:                  359   AIC:                            -2067.
Df Residuals:                      357   BIC:                            -2059.
Df Model:                            1                                         
Covariance Type:             nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------------
Intercept               0.0002      0.001      0.302      0.763        -0.001     0.002
crude_oil_stock_pct    -0.2028      0.190     -1.070      0.285        -0.576     0.170
==============================================================================
Omnibus:                        8.913   Durbin-Watson:                   1.929
Prob(Omnibus):                  0.012   Jarque-Bera (JB):               14.310
Skew:                          -0.117   Prob(JB):                     0.000781
Kurtosis:                       3.950   Cond. No.                         265.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Day Of Week 2

                             OLS Regression Results                            
===============================================================================
Dep. Variable:     uso_intraday_return   R-squared:                       0.028
Model:                             OLS   Adj. R-squared:                  0.026
Method:                  Least Squares   F-statistic:                     10.44
Date:                 Thu, 09 Jun 2016   Prob (F-statistic):            0.00134
Time:                         22:34:39   Log-Likelihood:                 963.67
No. Observations:                  359   AIC:                            -1923.
Df Residuals:                      357   BIC:                            -1916.
Df Model:                            1                                         
Covariance Type:             nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------------
Intercept            4.491e-05      0.001      0.051      0.959        -0.002     0.002
crude_oil_stock_pct     0.7344      0.227      3.232      0.001         0.287     1.181
==============================================================================
Omnibus:                       18.131   Durbin-Watson:                   2.048
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.969
Skew:                           0.335   Prob(JB):                     3.11e-07
Kurtosis:                       4.247   Cond. No.                         260.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Day Of Week 3

                             OLS Regression Results                            
===============================================================================
Dep. Variable:     uso_intraday_return   R-squared:                       0.014
Model:                             OLS   Adj. R-squared:                  0.012
Method:                  Least Squares   F-statistic:                     5.126
Date:                 Thu, 09 Jun 2016   Prob (F-statistic):             0.0242
Time:                         22:34:39   Log-Likelihood:                 968.11
No. Observations:                  352   AIC:                            -1932.
Df Residuals:                      350   BIC:                            -1924.
Df Model:                            1                                         
Covariance Type:             nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------------
Intercept              -0.0004      0.001     -0.500      0.618        -0.002     0.001
crude_oil_stock_pct     0.4824      0.213      2.264      0.024         0.063     0.901
==============================================================================
Omnibus:                       32.562   Durbin-Watson:                   2.031
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              120.200
Skew:                          -0.274   Prob(JB):                     7.92e-27
Kurtosis:                       5.810   Cond. No.                         258.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Day Of Week 4

                             OLS Regression Results                            
===============================================================================
Dep. Variable:     uso_intraday_return   R-squared:                       0.003
Model:                             OLS   Adj. R-squared:                 -0.000
Method:                  Least Squares   F-statistic:                    0.8663
Date:                 Thu, 09 Jun 2016   Prob (F-statistic):              0.353
Time:                         22:34:39   Log-Likelihood:                 991.29
No. Observations:                  347   AIC:                            -1979.
Df Residuals:                      345   BIC:                            -1971.
Df Model:                            1                                         
Covariance Type:             nonrobust                                         
=======================================================================================
                          coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------------
Intercept               0.0009      0.001      1.153      0.250        -0.001     0.002
crude_oil_stock_pct     0.1796      0.193      0.931      0.353        -0.200     0.559
==============================================================================
Omnibus:                       56.151   Durbin-Watson:                   2.035
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              254.440
Skew:                           0.577   Prob(JB):                     5.61e-56
Kurtosis:                       7.033   Cond. No.                         258.
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</code></pre><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>EIA inventory data is probably a weak predictor in and of itself. We can add more factors (momentum, etc) but the correlation’s definitely not as clear cut as most news agencies would like to claim.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2016/05/24/OPT-I-765-Processing-Time/"><span>OPT I-765 Processing Time</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/05/24/OPT-I-765-Processing-Time/" rel="bookmark">
        <time class="entry-date published" datetime="2016-05-24T18:51:45.000Z">
          2016-05-24
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br></pre></td></tr></table></figure>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>Students under the F-1 visa usually apply for Optional Practical Training (OPT) to get work authorization from US Citizenship and Immigration Services (USCIS) for internships / jobs. It is also the ultimate test of one’s patience. Even after one has braved the inane paperworks and countless trips to advisors / international student offices, one would still have to wait up to 90 days for the authorization approval. <strong>What makes this wait worse is the lack of updates during the wait.</strong> When one applies for OPT (and the application is received by USCIS), one gets a receipt number. Using this receipt number to check one’s progress (at <a href="https://egov.uscis.gov/casestatus/mycasestatus.do" target="_blank" rel="external">https://egov.uscis.gov/casestatus/mycasestatus.do</a>) is highly unsatisfying. Until the work authorization is approved (or God forbid rejected / put on hold for additional evidence), one is faced with rather useless description that reads something like this:</p>
<blockquote>
<p>‘On February 22, 2016, we received your Form I-765, Application for Employment Authorization , Receipt Number EAC1690120079, and sent you the receipt notice that describes how we will process your case. Please follow the instructions in the notice. If you do not receive your receipt notice by March 23, 2016, please call Customer Service at 1-800-375-5283. If you move, go to www.uscis.gov/addresschange to give us your new mailing address.’</p>
</blockquote>
<p>USCIS does a really bad job of keeping one updated on the progress of a case and in general how far along they are going with the entire year’s batch of students.</p>
<p><strong>Fortunately, we can do better.</strong></p>
<h1 id="Receipt-Numbers"><a href="#Receipt-Numbers" class="headerlink" title="Receipt Numbers"></a>Receipt Numbers</h1><p>USCIS issues receipt numbers in chronological order. That means if I submitted my application on March 1, 2016 and I got the number YSC1690079958, the next person to submit his application gets the number YSC169007995<strong>9</strong>. The person before me gets the number YSC169007995<strong>7</strong>. Using this fact, I can see how people before and after me are doing. USCIS also states that the cases are processed in a first-come-first-serve order.</p>
<ul>
<li>If a huge proportion of people before (and possibly after) me have their OPTs approved, I should have mine processed soon.</li>
<li>However, if the people who submitted around my date are stil waiting for their approval, I can expect to wait a long time.</li>
</ul>
<p>However, doing so manually at [<a href="https://egov.uscis.gov/casestatus/mycasestatus.do(https://egov.uscis.gov/casestatus/mycasestatus.do" target="_blank" rel="external">https://egov.uscis.gov/casestatus/mycasestatus.do(https://egov.uscis.gov/casestatus/mycasestatus.do</a>) is a slow and tiring process. Instead, I can write a script to “scrape” the website for the 50,000 or so cases before and after my own number.</p>
<blockquote>
<p>Additional note: This year, there are two USCIS centers processing OPT applications – the Vermont office and the Potomac office. The Potomac office opened later in the cycle (around March) to help with the application volume. <a href="https://www.uscis.gov/news/potomac-service-center-now-processing-certain-form-i-765-cases" target="_blank" rel="external">https://www.uscis.gov/news/potomac-service-center-now-processing-certain-form-i-765-cases</a>. Applications that are sent to the Vermont office first have the prefix <code>EAC</code>. Those may be then routed to the Potomac office. Applications that are sent in late March and later are sent directly to the Potomac office, giving them the prefix <code>YSC</code>. This means that when I scrape the pages for data, I have to account for both prefixes.</p>
</blockquote>
<p>I planned to scrape receipt numbers <code>EAC1690120000</code> to <code>EAC1690180000</code> and <code>YSC1690040000</code> to <code>YSC1690080000</code>. This should give me a good sense of applications submitted in the February to April period.</p>
<h1 id="Scraping"><a href="#Scraping" class="headerlink" title="Scraping"></a>Scraping</h1><h2 id="IP-Blocking"><a href="#IP-Blocking" class="headerlink" title="IP Blocking"></a>IP Blocking</h2><p>I first wrote a simple <code>Node.JS</code> script to do this. I didn’t use <code>python</code> because <code>async</code> in <code>python</code> is a pain in the ass.</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">'cheerio'</span>);</span><br><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">'request'</span>);</span><br><span class="line"><span class="keyword">var</span> <span class="keyword">async</span> = <span class="built_in">require</span>(<span class="string">'async'</span>);</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"><span class="keyword">var</span> stringify = <span class="built_in">require</span>(<span class="string">'csv-stringify'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> URL = <span class="string">'https://egov.uscis.gov/casestatus/mycasestatus.do?appReceiptNum=RECEIPT_NUM'</span>;</span><br><span class="line"><span class="keyword">var</span> PREFIX = <span class="string">'EAC'</span>;</span><br><span class="line"><span class="keyword">var</span> START_NUMBER = <span class="number">1690120000</span>;</span><br><span class="line"><span class="keyword">var</span> END_NUMBER = <span class="number">1690180000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> receiptNumbers = [];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = START_NUMBER; i &lt; END_NUMBER; i++) &#123;</span><br><span class="line">  receiptNumbers.push(PREFIX + i);</span><br><span class="line">&#125;</span><br><span class="line">fs.writeFileSync(<span class="string">'raw_data.csv'</span>, <span class="string">'receipt,title,text\n'</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">retrieveReceiptNumber</span>(<span class="params">receiptNumber, callback</span>) </span>&#123;</span><br><span class="line">  request(&#123;</span><br><span class="line">      url: URL.replace(<span class="string">'RECEIPT_NUM'</span>, receiptNumber),</span><br><span class="line">      rejectUnauthorized: <span class="literal">false</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="keyword">function</span> (<span class="params">err, resp, body</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="built_in">console</span>.error(err);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(body);</span><br><span class="line">      <span class="keyword">var</span> title = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'h1'</span>).text();</span><br><span class="line">      <span class="keyword">var</span> description = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'p'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> violation = $(<span class="string">'label[for=accessviolation]'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (title.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (violation.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="built_in">console</span>.log(<span class="string">'access violation'</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        callback();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> row = [</span><br><span class="line">          [receiptNumber, title, description]</span><br><span class="line">        ];</span><br><span class="line"></span><br><span class="line">        stringify(row, <span class="function"><span class="keyword">function</span> (<span class="params">err, output</span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (err) &#123;</span><br><span class="line">            <span class="built_in">console</span>.error(err);</span><br><span class="line">          &#125;</span><br><span class="line">          fs.appendFile(<span class="string">'raw_data.csv'</span>, output, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (err) &#123;</span><br><span class="line">              <span class="built_in">console</span>.error(err);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">console</span>.log(receiptNumber + <span class="string">' written'</span>);</span><br><span class="line">            callback();</span><br><span class="line">          &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span>.eachLimit(receiptNumbers, <span class="number">100</span>, retrieveReceiptNumber, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'DONE'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<h2 id="Scrapoxy"><a href="#Scrapoxy" class="headerlink" title="Scrapoxy"></a>Scrapoxy</h2><p>USCIS (unsurprisingly) blocked my IP after around 2,000 queries. So I needed a way to get around the IP blocking. Fortunately, an easy solution was available: <a href="http://scrapoxy.io/" target="_blank" rel="external">http://scrapoxy.io/</a>. Scrapoxy manages a pool of EC2 / DigitalOcean instances for you (afte some setting up) and provides a single local port for you as a proxy. This allows you to route your requests through the multiple cloud instances. This lowers the likelihood of a single IP getting blocked. (Even if one gets blocked, you can simply kill the instance and restart it. I didn’t have to do this, sine none of the cloud instances got blocked). After setting up Scrapoxy and running the proxy at <code>http://localhost:8888</code>, I can pass this easily to the <code>request</code> module in my script:</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">'cheerio'</span>);</span><br><span class="line"><span class="keyword">var</span> request = <span class="built_in">require</span>(<span class="string">'request'</span>);</span><br><span class="line"><span class="keyword">var</span> <span class="keyword">async</span> = <span class="built_in">require</span>(<span class="string">'async'</span>);</span><br><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>);</span><br><span class="line"><span class="keyword">var</span> stringify = <span class="built_in">require</span>(<span class="string">'csv-stringify'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> URL = <span class="string">'https://egov.uscis.gov/casestatus/mycasestatus.do?appReceiptNum=RECEIPT_NUM'</span>;</span><br><span class="line"><span class="keyword">var</span> PREFIX = <span class="string">'EAC'</span>;</span><br><span class="line"><span class="keyword">var</span> START_NUMBER = <span class="number">1690149000</span>;</span><br><span class="line"><span class="keyword">var</span> END_NUMBER = <span class="number">1690180000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> receiptNumbers = [];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> i = START_NUMBER; i &lt; END_NUMBER; i++) &#123;</span><br><span class="line">  receiptNumbers.push(PREFIX + i);</span><br><span class="line">&#125;</span><br><span class="line">fs.writeFileSync(<span class="string">'raw_data.csv'</span>, <span class="string">'receipt,title,text\n'</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">retrieveReceiptNumber</span>(<span class="params">receiptNumber, callback</span>) </span>&#123;</span><br><span class="line">  request(&#123;</span><br><span class="line">      url: URL.replace(<span class="string">'RECEIPT_NUM'</span>, receiptNumber),</span><br><span class="line">      rejectUnauthorized: <span class="literal">false</span>,</span><br><span class="line">      proxy: <span class="string">'http://localhost:8888'</span>,</span><br><span class="line">      tunnel: <span class="literal">false</span> <span class="comment">// remember to set tunnel to false</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="function"><span class="keyword">function</span> (<span class="params">err, resp, body</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        <span class="built_in">console</span>.error(err);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(body);</span><br><span class="line">      <span class="keyword">var</span> title = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'h1'</span>).text();</span><br><span class="line">      <span class="keyword">var</span> description = $(<span class="string">'.appointment-sec'</span>).find(<span class="string">'.text-center'</span>).find(<span class="string">'p'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">var</span> violation = $(<span class="string">'label[for=accessviolation]'</span>).text();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (title.length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (violation.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="built_in">console</span>.log(<span class="string">'access violation'</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        callback();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> row = [</span><br><span class="line">          [receiptNumber, title, description]</span><br><span class="line">        ];</span><br><span class="line"></span><br><span class="line">        stringify(row, <span class="function"><span class="keyword">function</span> (<span class="params">err, output</span>) </span>&#123;</span><br><span class="line">          <span class="keyword">if</span> (err) &#123;</span><br><span class="line">            <span class="built_in">console</span>.error(err);</span><br><span class="line">          &#125;</span><br><span class="line">          fs.appendFile(<span class="string">'raw_data.csv'</span>, output, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (err) &#123;</span><br><span class="line">              <span class="built_in">console</span>.error(err);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">console</span>.log(receiptNumber + <span class="string">' written'</span>);</span><br><span class="line">            callback();</span><br><span class="line">          &#125;);</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span>.eachLimit(receiptNumbers, <span class="number">100</span>, retrieveReceiptNumber, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(err);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'DONE'</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>The changes are in the options object passed to <code>request</code>:</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  url: URL.replace(<span class="string">'RECEIPT_NUM'</span>, receiptNumber),</span><br><span class="line">  rejectUnauthorized: <span class="literal">false</span>,</span><br><span class="line">  proxy: <span class="string">'http://localhost:8888'</span>,</span><br><span class="line">  tunnel: <span class="literal">false</span> <span class="comment">// remember to set tunnel to false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>This allows me to scrape the receipt numbers very quickly within the hour. (see the <code>eachLimit</code> for <code>async</code>? I’m making 100 requests at any time through the proxy). I collected the scraped results into <code>raw_data_eac.csv</code> and <code>raw_data_ysc.csv</code> for the two prefixes.</p>
<p>Now let’s analyze them.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> pandas</span><br></pre></td></tr></table></figure>
<h1 id="Parsing-Data"><a href="#Parsing-Data" class="headerlink" title="Parsing Data"></a>Parsing Data</h1><p>Earlier, I only scraped the raw data from the pages. Hence, I only have the <code>receipt</code> (receipt number), <code>title</code> (the short line of text displayed at the top of each case status) and <code>text</code> (the full text of the case status). This is hardly useful.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_eac = pandas.read_csv(<span class="string">'raw_data_eac.csv'</span>)</span><br><span class="line">data_ysc = pandas.read_csv(<span class="string">'raw_data_ysc.csv'</span>)</span><br><span class="line">data = data_eac.append(data_ysc)</span><br></pre></td></tr></table></figure>
<p>I can use this information to create a <code>status</code> for each receipt number. I’m using a lot of simplifying assupmtions here and disregarding a lot of corner cases (USCIS sometimes requests additional evidence, does weird thing with cases etc.) In fact, let’s take a look at the vaious case <code>title</code>s:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(data.groupby(<span class="string">'title'</span>).count()[<span class="string">'receipt'</span>])</span><br></pre></td></tr></table></figure>
<pre><code>title
Amended Notice Was Mailed                                                             8
Appeal Was Dismissed                                                                  9
Card Is Being Returned to USCIS by Post Office                                       10
Card Returned Undeliverable                                                           4
Card Was Delivered To Me By The Post Office                                       11434
Card Was Determined As Undeliverable By The Post Office                              26
Card Was Mailed To Me                                                              2045
Card Was Picked Up By The United States Postal Service                              162
Card Was Received By USCIS Along With My Letter                                       4
Card Was Returned And USCIS Is Holding It For One Year                               20
Card Was Returned To USCIS By Post Office                                             7
Case Is Pending at a Local Office                                                   449
Case Rejected Because I Sent An Incorrect Fee                                      1942
Case Rejected Because The Version Of The Form I Sent Is No Longer Accepted           64
Case Rejected For Form Not Signed And Incorrect Form Version                         38
Case Rejected For Incorrect Fee And Form Not Signed                                  94
Case Rejected For Incorrect Fee, Payment Not Signed And Incorrect Form Version       10
Case Terminated Benefit Received By Other Means                                      35
Case Transferred And New Office Has Jurisdiction                                      1
Case Transferred To Another Office                                                 1068
Case Was Approved                                                                  4558
Case Was Received                                                                 63510
Case Was Received At My Local Office                                               6210
Case Was Rejected                                                                    81
Case Was Rejected Because I Did Not Sign My Form                                    836
Case Was Rejected Because It Was Improperly Filed                                  1291
Case Was Reopened                                                                    11
Case Was Reopened For Reconsideration                                                 1
Case Was Sent To The Department of State                                          10569
Case Was Transferred And A New Office Has Jurisdiction                            14926
Case Was Transferred To An Asylum Office                                              1
Case Was Transferred To Schedule An Interview                                         1
Correspondence Was Received And USCIS Is Reviewing It                               133
Date of Birth Was Updated                                                           236
Decision Notice Mailed                                                              169
Document Was Mailed To Me                                                             2
Duplicate Notice Was Mailed                                                          15
Fee Refund Was Mailed                                                                 2
Fee Was Not Corrected                                                                 1
Fee Will Be Refunded                                                                  2
Fees Were Waived                                                                    249
Fingerprint Fee Has Issues That Need To Be Fixed                                      8
Fingerprint Fee Was Received                                                        577
Name Was Updated                                                                   1245
New Card Is Being Produced                                                         1862
Notice Explaining USCIS&apos; Actions Was Mailed                                         179
Notice Was Returned To USCIS Because The Post Office Could Not Deliver It           365
Payment Fee Was Returned For Insufficient Funds                                      41
Receipt Notice Was Changed                                                           58
Request for Additional Evidence Was Mailed                                          861
Request for Initial Evidence Was Mailed                                            3262
Response To USCIS&apos; Request For Evidence Was Received                                940
Withdrawal Acknowledgement Notice Was Sent                                           24
Name: receipt, dtype: int64
</code></pre><p>I ignore most of the corner cases and only look at a few larger categories:</p>
<ul>
<li>If the word <code>I-765</code> appears in the <code>text</code> of a case (since we are only looking at OPT cases), and <code>Case Was Received</code> is in the <code>title</code>, then the case is still processing. This happens when USCIS receives the case. Most people enduring the long 60 to 90 day wait will see this.</li>
<li>If the word <code>I-765</code> appears in the <code>text</code> of a case, and <code>Case Was Transferred</code> is in the <code>title</code>, then the case was probably submitted to the Vermont office first then routed to the Potomac office. This is still <code>processing</code> as well.</li>
<li>If the word <code>I-765</code> appears in the <code>text</code> of a case, and <code>Case Was Rejected</code>, well sucks for you. The case is rejected.</li>
<li>If the word <code>I-765</code> appears in the <code>text</code> of a case and <code>Case Was Approved</code>, congratulations! Your case is approved.</li>
<li>Even better, if a card is made and being delieverd, you’d have the <code>Card Was Delivered To Me By The Post Office</code> in the <code>title</code> of the case.</li>
</ul>
<p>I make a silly function for this and iterate over each row of the dataframe.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_status</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Received'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'processing'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Transferred'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'processing'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Rejected'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'rejected'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'I-765'</span> <span class="keyword">in</span> row[<span class="string">'text'</span>] <span class="keyword">and</span> <span class="string">'Case Was Approved'</span> <span class="keyword">in</span> row[<span class="string">'title'</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'approved'</span></span><br><span class="line">    <span class="keyword">if</span> row[<span class="string">'title'</span>] == <span class="string">'Card Was Delivered To Me By The Post Office'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'approved'</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line">data[<span class="string">'status'</span>] = data.apply(gen_status, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>Now here’s a slightly harder part. Only in the <code>Case Was Received</code> cases do we have a <strong>submission date</strong> for the OPT application. For the others (approved or rejected) the case status <code>text</code> only contains the date that the case was approved (which I am really not interested in for now). I want to know when those cases are <strong>submitted</strong>. Fortunately, I can again exploit the fact that the numbers are in increasing order. When the date of a case cannot be determined, I simply look backwards (to earlier receipt numbers) to the last known date of a still processing case. This gives me a good approximation of the submission dates of approved / rejected cases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line">pattern = re.compile(<span class="string">'On ([A-z]+ [0-9]+, [0-9]+),'</span>)</span><br><span class="line"></span><br><span class="line">last_date = <span class="keyword">None</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_date</span><span class="params">(row)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> row[<span class="string">'status'</span>] == <span class="string">'processing'</span>:</span><br><span class="line">        m = pattern.search(row[<span class="string">'text'</span>])</span><br><span class="line">        <span class="keyword">global</span> last_date</span><br><span class="line">        last_date = numpy.datetime64(pandas.Timestamp(m.group(<span class="number">1</span>)))</span><br><span class="line">        <span class="keyword">return</span> last_date</span><br><span class="line">    <span class="keyword">return</span> last_date</span><br><span class="line"></span><br><span class="line">data[<span class="string">'date'</span>] = data.apply(extract_date, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>Now I can look at the results. First, I group the data by the <code>date</code> column. Cases (rows) with the same date will be grouped together. Then, for each date, I count the number of <code>processing</code>, <code>approved</code>, and <code>rejected</code> cases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result = pandas.DataFrame(data[data[<span class="string">'status'</span>] == <span class="string">'processing'</span>].groupby(<span class="string">'date'</span>)[<span class="string">'receipt'</span>].count())</span><br><span class="line">result[<span class="string">'approved'</span>] = data[data[<span class="string">'status'</span>] == <span class="string">'approved'</span>].groupby(<span class="string">'date'</span>)[<span class="string">'receipt'</span>].count()</span><br><span class="line">result[<span class="string">'rejected'</span>] = data[data[<span class="string">'status'</span>] == <span class="string">'rejected'</span>].groupby(<span class="string">'date'</span>)[<span class="string">'receipt'</span>].count()</span><br><span class="line">result.columns = [<span class="string">'Processing'</span>, <span class="string">'Approved'</span>, <span class="string">'Rejected'</span>]</span><br></pre></td></tr></table></figure>
<p>And I make a silly plot.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.plot()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x111202358&gt;
</code></pre><p><img src="/images/OPT-I-765-Processing-Time/output_17_1.svg" alt="svg"></p>
<p>Here’s how to interpret this data. I can see that most of the cases submitted in February and early March are already processed. The ones submitted in later March are around 50% processed. The ones submitted in late March (like mine) are beginning to get approved.</p>
<p>For each date, I can see the number of cases approved, rejected, processing etc.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.loc[<span class="string">'2016-03-30'</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Processing    2069.0
Approved       328.0
Rejected         5.0
Name: 2016-03-30 00:00:00, dtype: float64
</code></pre><p>I can make this more readable by dividing the number of approved cases by the total number of processing, approved, and rejected cases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">result[<span class="string">'Total'</span>] = result[<span class="string">'Processing'</span>] + result[<span class="string">'Approved'</span>] + result[<span class="string">'Rejected'</span>]</span><br><span class="line">result[<span class="string">'Approved Proportion'</span>] = result[<span class="string">'Approved'</span>] / result[<span class="string">'Total'</span>]</span><br><span class="line">result[<span class="string">'Approved Proportion'</span>].plot()</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11131ee10&gt;
</code></pre><p><img src="/images/OPT-I-765-Processing-Time/output_21_1.svg" alt="svg"></p>
<p>I really don’t understand why USCIS would not release this data (since it will help calm the nerves of so many international students). I do hope that this will help calm your nerves though as it did calm mine.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
  

  <span class="post-tags">
    <i class="icon-tags"></i>
    <a href="/tags/data/">data</a>, <a href="/tags/opt/">opt</a>, <a href="/tags/uscis/">uscis</a>, <a href="/tags/scraping/">scraping</a>
  </span>


        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2016/04/22/Running-Word-Embedding-on-Piazza-Posts/"><span>Running Word Embedding on Piazza Posts</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/04/22/Running-Word-Embedding-on-Piazza-Posts/" rel="bookmark">
        <time class="entry-date published" datetime="2016-04-22T07:08:07.000Z">
          2016-04-22
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>Word embedding (very bad explanation follows) is translating each word in a corpus into a D dimension vector. These vectors are supposed to preserve semantic properties and are commonly used in NLP. For example, in a large corpus of words (say the google news corpus), the vector point for man $v_{king}$ should be near the vector point for $v_{queen}$. Furthermore, meaning such as “king is to man as queen is to woman” is preserved via $v_{king} - v_{queen} \approx v_{man} - v_{queen}$. These embeddings are generated via neural networks and a common tool for doing this is Word2Vec produced by <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="external">Mikolov et al</a>. A fast implementation of Word2Vec is available in gensim.</p>
<p>For more reading, read <a href="https://www.wikiwand.com/en/Word2vec" target="_blank" rel="external">the wiki</a> or the paper itself. For interesting experiments, read these:</p>
<ul>
<li><a href="http://instagram-engineering.tumblr.com/post/117889701472/emojineering-part-1-machine-learning-for-emoji" target="_blank" rel="external">Running Word2Vec on Instagram Emojis</a></li>
<li><a href="http://textminingonline.com/training-word2vec-model-on-english-wikipedia-by-gensim" target="_blank" rel="external">Word2Vec on English Wiki</a></li>
<li>And, shamelessly, my favorite because I wrote it <a href="https://github.com/linanqiu/word2vec-sentiments" target="_blank" rel="external">Sentiment Analysis using Word2Vec</a></li>
</ul>
<p>Won’t it be fun to run this on Piazza posts? I’m a TA for data structures this semester (for Prof Blaer and Prof Bauer) and we have a Piazza containing 800 posts (ripe with answers, followups, etc). Speaking of that, we have an average response time of 5min. Find me another team of TAs that can beat this hurhhurh.</p>
<h1 id="Creating-Corpus"><a href="#Creating-Corpus" class="headerlink" title="Creating Corpus"></a>Creating Corpus</h1><p>Turns out Piazza does not have an official API. However, there is an unofficial API. <a href="https://github.com/hfaran/piazza-api" target="_blank" rel="external">https://github.com/hfaran/piazza-api</a> That’s good enough for us.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> piazza_api <span class="keyword">import</span> Piazza</span><br><span class="line">piazza = Piazza()</span><br><span class="line">piazza.user_login()</span><br></pre></td></tr></table></figure>
<pre><code>Email: lq2137@columbia.edu
········
</code></pre><p>Now let’s grab all the posts as <code>.json</code>s.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">course = piazza.network(<span class="string">'ijfyurrye2g1oc'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">posts = course.iter_all_posts()</span><br><span class="line"></span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> post <span class="keyword">in</span> posts:</span><br><span class="line">    <span class="keyword">if</span> count % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'Downloading post %d'</span> % count</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'%d.json'</span> % count, <span class="string">'w'</span>) <span class="keyword">as</span> csv_file:</span><br><span class="line">        csv_file.write(json.dumps(post))</span><br><span class="line">    count += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<pre><code>Downloading post 0
Downloading post 100
Downloading post 200
Downloading post 300
Downloading post 400
Downloading post 500
Downloading post 600
Downloading post 700
Downloading post 800
</code></pre><p>Then we parse the <code>.json</code>s into a giant <code>.txt</code> by unscrambling the messy <code>.json</code> that the API provides. We also tokenize and perform some basic cleaning (mash everything to lower case). This is a very blunt tool, but should suffice for now.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> word_tokenize</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grab_children</span><span class="params">(post)</span>:</span></span><br><span class="line">    content_children = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">traverse</span><span class="params">(children)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> child <span class="keyword">in</span> children:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'history'</span> <span class="keyword">in</span> child:</span><br><span class="line">                history = child[<span class="string">'history'</span>]</span><br><span class="line">                content_children.extend([history_item[<span class="string">'content'</span>] <span class="keyword">for</span> history_item <span class="keyword">in</span> history])</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'children'</span> <span class="keyword">in</span> child:</span><br><span class="line">                traverse(child[<span class="string">'children'</span>])</span><br><span class="line">    traverse(post[<span class="string">'children'</span>])</span><br><span class="line">    <span class="keyword">return</span> content_children</span><br><span class="line"></span><br><span class="line">corpus = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> glob_file <span class="keyword">in</span> glob.glob(<span class="string">'*.json'</span>):</span><br><span class="line">    <span class="keyword">with</span> open(glob_file, <span class="string">'r'</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">        post = json.load(json_file)</span><br><span class="line">        content = [history[<span class="string">'content'</span>] <span class="keyword">for</span> history <span class="keyword">in</span> post[<span class="string">'history'</span>]]</span><br><span class="line">        content.extend(grab_children(post))</span><br><span class="line">        content = [BeautifulSoup(text, <span class="string">'html.parser'</span>).get_text() <span class="keyword">for</span> text <span class="keyword">in</span> content]</span><br><span class="line">        content = [word_tokenize(text.lower()) <span class="keyword">for</span> text <span class="keyword">in</span> content]</span><br><span class="line">        corpus.extend(content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'corpus.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> corpus_file:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> corpus:</span><br><span class="line">        corpus_file.write(<span class="string">'%s\n'</span> % <span class="string">' '</span>.join(line).strip().encode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure>
<h1 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h1><p>Now let’s train the model using <code>gensim</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gensim.models.word2vec <span class="keyword">as</span> word2vec</span><br></pre></td></tr></table></figure>
<p>Turns out <code>gensim</code> has a nice reader that iterates over a text file with one sentence a line. That’s exactly what we produced in the corpus section.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentences = word2vec.LineSentence(<span class="string">'corpus.txt'</span>)</span><br></pre></td></tr></table></figure>
<p>Now let’s train the model on this corpus. These are some hyperparameters that I found to be good. I shan’t explain them too much, but if you want a little more detail we are essentially using the Skip-Gram with Negative Sampling portion of Word2Vec over 100 iterations and a Skip-Gram window of 15. We also discard all words that occur few than 5 times.</p>
<p>This should take no more than a minute since the corpus is tiny (which theoretically should give us crappy results but let’s see.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = word2vec.Word2Vec(sentences, min_count=<span class="number">5</span>, workers=<span class="number">8</span>, iter=<span class="number">100</span>, window=<span class="number">15</span>, size=<span class="number">300</span>, negative=<span class="number">25</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>Now let’s look at some results. </p>
<p>The <code>most_similar</code> method takes in a word, converts it to its vector representation, and finds the other words that are closest to it by cosine distance. These similar words should have been used in a similar context with the original word. Let’s find some interesting results.</p>
<p>First, let’s do a sanity check using the word <code>homework</code>. Turns out <code>homework</code> is indeed associated with words we’d expect to be associated with <code>homework</code>: <code>solutions</code>, <code>grade</code>, <code>email</code>, and even <code>latex</code>. That’s good.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'homework'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;solutions&apos;, 0.3142701983451843),
 (u&apos;grade&apos;, 0.3114492893218994),
 (u&apos;email&apos;, 0.3077431321144104),
 (u&apos;inserted&apos;, 0.3056461215019226),
 (u&apos;description&apos;, 0.2953464388847351),
 (u&apos;programming&apos;, 0.2912822961807251),
 (u&apos;latex&apos;, 0.2862958312034607),
 (u&apos;theorem&apos;, 0.28351300954818726),
 (u&apos;signature&apos;, 0.2821905314922333),
 (u&apos;posts&apos;, 0.28168296813964844)]
</code></pre><p>Now for something more advanced. Let’s try the word <code>heap</code>. Turns out we have words that are pretty related to the <code>heap</code> concept:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'heap'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;build&apos;, 0.30242919921875),
 (u&apos;percolatedown&apos;, 0.2909688353538513),
 (u&apos;one-by-one&apos;, 0.28867167234420776),
 (u&apos;deletion&apos;, 0.2867096960544586),
 (u&apos;k&apos;, 0.28530699014663696),
 (u&apos;discussed&apos;, 0.2748313546180725),
 (u&apos;linear&apos;, 0.26605361700057983),
 (u&apos;increasing&apos;, 0.2620879113674164),
 (u&apos;quicksort&apos;, 0.25420695543289185),
 (u&apos;instructions&apos;, 0.2464582324028015)]
</code></pre><p>Now for the most awesome result ever. What concepts are associated with <code>good</code>? Turns out I’m one of them.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'good'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;great&apos;, 0.35192880034446716),
 (u&apos;very&apos;, 0.3159177303314209),
 (u&apos;almost&apos;, 0.30515187978744507),
 (u&apos;concepts&apos;, 0.3004434108734131),
 (u&apos;linan&apos;, 0.2995752990245819),
 (u&apos;too&apos;, 0.2964840829372406),
 (u&apos;basic&apos;, 0.2916448712348938),
 (u&apos;fit&apos;, 0.28502458333969116),
 (u&apos;useful&apos;, 0.2824944257736206),
 (u&apos;answered&apos;, 0.28173112869262695)]
</code></pre><p><img src="https://cdn.thinglink.me/api/image/727110550026190849/1240/10/scaletowidth" alt="doge"></p>
<p>Let’s see what’s similar to the profs. Turns out Prof Blaer’s love for <code>ocaml</code> is well noted.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'blaer'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;professor&apos;, 0.7219115495681763),
 (u&apos;prof.&apos;, 0.6643839478492737),
 (u&apos;bauer&apos;, 0.4823228120803833),
 (u&apos;today&apos;, 0.44543683528900146),
 (u&apos;went&apos;, 0.4129117727279663),
 (u&apos;pm&apos;, 0.4097597897052765),
 (u&apos;session&apos;, 0.40625864267349243),
 (u&apos;mentioned&apos;, 0.4010222554206848),
 (u&apos;ocaml&apos;, 0.3884058892726898),
 (u&apos;tonight&apos;, 0.38226139545440674)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'bauer'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;professor&apos;, 0.6429691314697266),
 (u&apos;slides&apos;, 0.5277301669120789),
 (u&apos;prof.&apos;, 0.5086715221405029),
 (u&apos;lecture&apos;, 0.4928019642829895),
 (u&apos;blaer&apos;, 0.4823228120803833),
 (u&apos;sign&apos;, 0.4362599849700928),
 (u&apos;pm&apos;, 0.3718754053115845),
 (u&apos;went&apos;, 0.3549380302429199),
 (u&apos;tonight&apos;, 0.326946496963501),
 (u&apos;perform&apos;, 0.3159770965576172)]
</code></pre><p>Sasha loves grades, which is unsurprising.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.most_similar(<span class="string">'sasha'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>[(u&apos;email&apos;, 0.5593311786651611),
 (u&apos;ta&apos;, 0.4426960051059723),
 (u&apos;monday&apos;, 0.4238441586494446),
 (u&apos;grade&apos;, 0.42380213737487793),
 (u&apos;talk&apos;, 0.40258437395095825),
 (u&apos;grading&apos;, 0.3625785708427429),
 (u&apos;mentioned&apos;, 0.3540249466896057),
 (u&apos;approaches&apos;, 0.3509276807308197),
 (u&apos;cs&apos;, 0.3439938724040985),
 (u&apos;hope&apos;, 0.3431258201599121)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.doesnt_match(<span class="string">"bauer blaer graph"</span>.split())</span><br></pre></td></tr></table></figure>
<pre><code>&apos;graph&apos;
</code></pre><p>And of course it differentiates between a TA and a professor.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.doesnt_match(<span class="string">"bauer blaer linan"</span>.split())</span><br></pre></td></tr></table></figure>
<pre><code>&apos;linan&apos;
</code></pre><p>ISN’T THIS FUCKING AWESOME.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
  

  <span class="post-tags">
    <i class="icon-tags"></i>
    <a href="/tags/ta/">ta</a>, <a href="/tags/word2vec/">word2vec</a>, <a href="/tags/nlp/">nlp</a>, <a href="/tags/piazza/">piazza</a>
  </span>


        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2016/01/09/Oil-Futures-Curve-Visualization/"><span>Oil Futures Curve Visualization</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/01/09/Oil-Futures-Curve-Visualization/" rel="bookmark">
        <time class="entry-date published" datetime="2016-01-09T17:05:04.000Z">
          2016-01-09
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>This oil thing is getting pretty crazy, especially with Saudi and Iran going bonkers over each other. Futures curves are a great way to speculate, and it’d be great to visualize the movement of the futures curve over different trading days.</p>
<p>I thought this would be a pretty commonsensical thing for yahoo / google finance to provide, but turns out they provide nothing more than a single futures chain (settle prices for futures contracts right now). Historical prices aren’t available, and even if they are, they aren’t in the form of a futures curve. Instead, they are just prices for the specific contract (eg. the futures contract expiring on Feb 2016, not the front month contract and the contract expiring in one month etc). I want the relative numbers, not the absolute ones, hence this.</p>
<p>I want a plot of the current futures prices for the next 12 months. Here’s how to do that simply</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># %config InlineBackend.figure_format = 'retina'</span></span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'svg'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas_datareader.data <span class="keyword">as</span> data</span><br><span class="line"><span class="keyword">import</span> pandas_datareader.wb <span class="keyword">as</span> wb</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> pyplot</span><br><span class="line">matplotlib.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> Quandl</span><br><span class="line"></span><br><span class="line">API_KEY = <span class="string">'SUBSTITUTE_YOUR_OWN_API_KEY'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pyplot.rcParams['figure.figsize'] = (10, 10)</span></span><br></pre></td></tr></table></figure>
<p>In Quandl (and in real life), futures contract are named as <code>AAMYYYY</code> where <code>AA</code> is the type of underlying asset (for WTI crude oil, it is <code>CL</code>), <code>M</code> is the month (the whole series of months starting from <code>F</code> to <code>Z</code> is in the array below) and <code>YYYY</code> is the year (eg. <code>2016</code>). Hence, a futures contract for crude oil expiring in March 2016 will be <code>CLH2016</code> or <code>CLH16</code> depending on the source of your data.</p>
<p>We make use of this fact and pull our data (in the form of <code>pandas</code> dataframes) into a dictionary.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">MONTHS = [<span class="string">'F'</span>, <span class="string">'G'</span>, <span class="string">'H'</span>, <span class="string">'J'</span>, <span class="string">'K'</span>, <span class="string">'M'</span>, <span class="string">'N'</span>, <span class="string">'Q'</span>, <span class="string">'U'</span>, <span class="string">'V'</span>, <span class="string">'X'</span>, <span class="string">'Z'</span>]</span><br><span class="line">YEARS = [<span class="number">2014</span>, <span class="number">2015</span>, <span class="number">2016</span>, <span class="number">2017</span>, <span class="number">2018</span>]</span><br><span class="line">PREFIX = <span class="string">'CME/CL'</span></span><br><span class="line"></span><br><span class="line">dataframes = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> month <span class="keyword">in</span> MONTHS:</span><br><span class="line">    <span class="keyword">for</span> year <span class="keyword">in</span> YEARS:</span><br><span class="line">        symbol = <span class="string">'%s%s%d'</span> % (PREFIX, month, year)</span><br><span class="line">        internal_symbol = <span class="string">'%d%s'</span> % (year, month)</span><br><span class="line">        dataframes[internal_symbol] = Quandl.get(symbol, authtoken=API_KEY)</span><br><span class="line">        dataframes[internal_symbol] = dataframes[internal_symbol][<span class="string">'Settle'</span>]</span><br></pre></td></tr></table></figure>
<p>Next, we make some functions that extract the futures price at a given date from each of the dataframes (each of the contracts), skipping them if the date doesn’t exist. For example, there won’t be a settlement price on 5th Jan 2015 for a contract expiring in December 2014.</p>
<p>Then <code>extract_year</code> takes the first 12 prices from the list of prices. The keys for the dataframes are in the form of <code>YYYYMAA</code> so that the year comes first, simplifying the sorting process. Yes I know this is non conventional.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_curve</span><span class="params">(dataframes, date)</span>:</span></span><br><span class="line">    curve = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> symbol, dataframe <span class="keyword">in</span> dataframes.iteritems():</span><br><span class="line">        <span class="keyword">if</span> date <span class="keyword">in</span> dataframe:</span><br><span class="line">            curve[symbol] = dataframe[date]</span><br><span class="line">    <span class="keyword">return</span> curve</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_year</span><span class="params">(curve)</span>:</span></span><br><span class="line">    pvs = [curve[symbol] <span class="keyword">for</span> symbol <span class="keyword">in</span> sorted(curve)]</span><br><span class="line">    <span class="keyword">return</span> pvs[:<span class="number">12</span>]</span><br></pre></td></tr></table></figure>
<p>Now we can plot our first graph. This plots the futures curve at a certain date.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_year_curve</span><span class="params">(date)</span>:</span></span><br><span class="line">    pyplot.plot(extract_year(get_curve(dataframes, date)))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>))</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Oil-Futures-Curve-Visualization/output_8_0.svg" alt="svg"></p>
<p>That’s useful, but what I really want to know is how the futures curve has shifted over the last few days. I can do this by plotting a whole bunch of these lines, and varying the gradient such that the ones far back in time are red, and the recent ones are green.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_year_curve_range</span><span class="params">(date, shift_back_days)</span>:</span></span><br><span class="line">    date_list = [date - datetime.timedelta(days=x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">0</span>, shift_back_days)]</span><br><span class="line">    <span class="keyword">for</span> index, date <span class="keyword">in</span> enumerate(date_list):</span><br><span class="line">        color = (index / len(date_list))</span><br><span class="line">        pyplot.plot(extract_year(get_curve(dataframes, date)), color=(color, <span class="number">1</span>-color, <span class="number">0</span>), linewidth=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve_range(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>), <span class="number">30</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Oil-Futures-Curve-Visualization/output_11_0.svg" alt="svg"></p>
<p>The plot above is the futures curve for the last 30 days (non-trading days are included, so there are less than 30 lines in the graph). What we see that initially, the curve flattened, then dropped in a parallel manner, and finally steepening again. In fact, we can visualize the recent steepening a little closer by looking at the last 10 days.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve_range(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>), <span class="number">10</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Oil-Futures-Curve-Visualization/output_13_0.svg" alt="svg"></p>
<p>This shows that over the last 10 days, the curve has fallen somewhat more on the short end than on the long end (37 to 33 vs 44 to 41).</p>
<p>We can also abuse this for cool artistic effects.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot_year_curve_range(datetime.datetime(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">8</span>), <span class="number">360</span>)</span><br><span class="line">pyplot.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/Oil-Futures-Curve-Visualization/output_15_0.svg" alt="svg"></p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2016/01/04/Grades/"><span>Grades</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2016/01/04/Grades/" rel="bookmark">
        <time class="entry-date published" datetime="2016-01-05T04:09:58.000Z">
          2016-01-04
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>This conversation happened on Piazza today, two weeks after class ended.</p>
<blockquote>
<p>A student posted: Hi all, I was wondering if it’s possible to get the cutoffs for the course grades?</p>
<p>Me: No, and it won’t be productive in any way since your grades are final and the cut off changes from year to year.</p>
<p>Said student: Hi Linan, with all due respect I disagree with that. I understand the trouble it would cause since everyone would start asking to review and change their grades, but I simply just want to understand the grade I received. Since we hardly have an opportunity to review our final exams until next semester, knowing the cutoff would help understand why we got what grade we got. I received 100 or above on every homework assignment with the exception of one (and the one I dropped) and above 100 on the first midterm, but I did poorly on my final and this brought my grade down a lot more than I can see why. If I knew the cutoffs, maybe I could see where I fell compared to the class and be able to understand my grade. In a class in which the homework assignments have taken me over 12 hours straight to complete, I’d like to know exactly where my grade is coming from.</p>
<p>Me: Sure. You got a grade of x% (grades redacted). The cutoff for A- was 90%, A was 93%, and A+ was 100%. This was due to the finals, and the fact that the curves for the homeworks had high means with high skews. This should probably answer most of your question.</p>
<p>Now my refusal to answer this question is not because it would cause people to start asking for reviews: grades are final. It is because I want students to stop dwelling on the grades of this class and move on. No interviewer has ever asked me about my grades for data structures or even my GPA, and certainly getting a B+, A-, or an A would not make the tiniest difference. Get over grades. Instead, think about what you learned in this class, how it will help you in the things you build, and what you know now that you didn’t know 4 months ago.</p>
<p>If anything, this class is a very bad indicator of how you’ll do in any class following this. I didn’t get a good grade in data structures myself because like you, sometimes I screw up exams. In fact I’d wager that I screw them up way more often than you. However, I will say that I understand (and apply) these concepts better than most people in the same class as me. Seeing how you did in your homeworks (and attempted numerous extra credits), you should be proud of that too. This takes you way further in classes, projects, and, with a little bit of exaggeration, life.</p>
<p>tl;dr: you missed A- by a scratch. Unfortunately, we can’t change that – there has to be a cutoff, and you, like many many others in this class, fell slightly below a cutoff. However, it. does. not. matter. Move on from this piazza. Build things. Make the world a better place.</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/12/10/Memoization-Recursion-Dynamic-Programming/"><span>Memoization Recursion Dynamic Programming</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/12/10/Memoization-Recursion-Dynamic-Programming/" rel="bookmark">
        <time class="entry-date published" datetime="2015-12-11T04:37:45.000Z">
          2015-12-10
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>A student asked this in class today: What’s the difference between Recursion, Memoization and Dynamic Programming.</p>
<p>I was quite surprised that said student couldn’t find a good answer online, so I made one. Here’s the answer:</p>
<hr>
<p>Okay. Here’s the short version: Recursion + Memoization = Dynamic Programming.</p>
<p>Was going to go through this at recitation but wtheck. :D</p>
<h2 id="Recursion"><a href="#Recursion" class="headerlink" title="Recursion"></a>Recursion</h2><p>Recursion is recursion is recursion but it ends somewhere. Basically, a recursive expression is one that depends on previous values of the same expression, and we have a base condition. Think Fibonacci numbers. In this case, I’m going to use the example of the coin change problem (which you’ve probably done in class).</p>
<p>The question goes like: coins come in 35 cents, 25 cents, 15 cents, 10 cents, 5 cents, and 1 cents. So I write it like this <code>int[] combinations = new int[] {35, 25, 15, 10, 5, 1}</code>. Now given <code>x</code> cents, what’s the minimum number of coins I need?</p>
<p>I can derive a recursive equation for this:</p>
<p>Let’s say <code>C(x)</code> is a magical function. <code>C(x)</code> gives me the minimum number of coins required to represent <code>x</code> cents. I can define <code>C(x)</code> recursively:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C(x) = minimum of the following &#123;</span><br><span class="line">         C(x-35) + 1,</span><br><span class="line">         C(x-25) + 1,</span><br><span class="line">         C(x-15) + 1,</span><br><span class="line">         C(x-10) + 1,</span><br><span class="line">         C(x-5) + 1,</span><br><span class="line">         C(x-1) + 1</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure>
<p>Why? Say <code>x=105</code>. Then, the minimum number of coins required to piece together 105 cents is the minimum of</p>
<ul>
<li>the minimum number of coins required to piece 70 cents plus another 35 cent coin</li>
<li>the minimum number of coins required to piece 80 cents plus another 25 cent coin</li>
<li>the minimum number of coins required to piece 90 cents plus another 15 cent coin etc. etc.</li>
</ul>
<p>What about our base condition? Since the smallest denomination is 1 cent, I can define <code>C(0) = 0</code> and <code>C(1) = 1</code>. Then, the entire recursive function is basically:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">minimumCoin</span><span class="params">(<span class="keyword">int</span>[] combinations, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(x == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(x == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  List&lt;Integer&gt; costs = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> combination : combinations) &#123;</span><br><span class="line">    <span class="keyword">if</span>(x - combination &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      costs.add(minimumCoin(combinations, x - combination) + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Collections.min(costs).intValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Memoization"><a href="#Memoization" class="headerlink" title="Memoization"></a>Memoization</h2><p>The problem with this is that you’re doing a lot of repeat work. Let’s do a trace:</p>
<ul>
<li>To calculate C(105), you need C(70, 80, 90, 95, 100, 104).</li>
<li>For each of those, you’d need more values.</li>
</ul>
<p>Convince yourself that those values repeat by drawing up a giant tree. You’re doing a lot of duplicate work. This is basically the same reason why Fibonacci recursion is so inefficient.</p>
<p>The reason is because naive recursion is forgetful. You only remember results for the current layer, and that’s it. Instead, what if there’s a way to remember all the past results that you’ve had so far? Memoization is exactly that.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">minimumCoin</span><span class="params">(<span class="keyword">int</span>[] combinations, <span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span>[] memory = <span class="keyword">new</span> <span class="keyword">int</span>[x + <span class="number">1</span>];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; memory.length; i++) &#123;</span><br><span class="line">    memory[i] = Integer.MIN_VALUE;</span><br><span class="line">  &#125;</span><br><span class="line">  minimumCoin(combinations, x, memory);</span><br><span class="line">  <span class="keyword">return</span> memory[x];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">minimumCoin</span><span class="params">(<span class="keyword">int</span>[] combinations, <span class="keyword">int</span> x, <span class="keyword">int</span>[] memory)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (x == <span class="number">0</span>) &#123;</span><br><span class="line">    memory[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (x == <span class="number">1</span>) &#123;</span><br><span class="line">    memory[<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  List&lt;Integer&gt; costs = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> combination : combinations) &#123;</span><br><span class="line">    <span class="keyword">if</span> (x - combination &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (memory[x - combination] == Integer.MIN_VALUE) &#123;</span><br><span class="line">        minimumCoin(combinations, x - combination, memory);</span><br><span class="line">      &#125;</span><br><span class="line">      costs.add(memory[x - combination] + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  memory[x] = Collections.min(costs).intValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>The only major difference between this and the previous recursive solution is that instead of recursing down <code>costs.add(minimumCoin(combinations, x - combination) + 1)</code> every single time, we check if this value has been calculated before in <code>int[] memory</code>. If it has, we just take the value straightaway instead of calculating it. We only calculate if it hasn’t been calculated (ie. still equals to the initial value of <code>Integer.MAX_VALUE</code>).</p>
<p>This is memoization.</p>
<h2 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h2><p>So DP really comprises of two parts:</p>
<ul>
<li>Getting a recursive equation</li>
<li>Coming up with a memoized way to do this</li>
</ul>
<p>Usually, the memoized solution is way easier to write <strong>iteratively</strong> than recursively. I just stuck to recursion in this case to extend from the original recursion example. Plus, providing you with the iterative solution would be too much of a giveaway.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/12/03/pca-irs/"><span>Principal Component Analysis on Interest Rate Swaps</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/12/03/pca-irs/" rel="bookmark">
        <time class="entry-date published" datetime="2015-12-03T06:40:39.000Z">
          2015-12-03
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <blockquote>
<p>In partial satisfaction of the project requirement for the class Statistical Methods in Finance <code>STAT W4290</code> Fall 2015.</p>
</blockquote>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>This project applies Principal Component Analysis (PCA) to interest rate swaps and shows that the first 3 principal components correspond to yields, slope, and curvature respectively. I first start with vanilla interest rate swaps, and explain how an analysis based purely on single trades are unsatisfactory. I then shift our analysis to curve trades done using pairs of interest rate swaps and show how that is more useful in modeling different parts of the yield curve. I then demonstrate how the principal components from the analysis corresponding to yield, slope and curvature.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="What-are-Interest-Rate-Swaps"><a href="#What-are-Interest-Rate-Swaps" class="headerlink" title="What are Interest Rate Swaps"></a>What are Interest Rate Swaps</h2><blockquote>
<p>A swap is an over-the-counter agreement between two companies to exchange cash flows in the future. The agreement defines the dates when the cash flows are to be paid and the way in which they are to be calculated. Usually, the calculation of the cash flows involve the future value of an interest rate, an exchange rate, or other market variable. … The most common type of swap is a “plain vanilla” interest rate swap. In this swap a company agrees to pay cash flows equal to interest at a predetermined fixed rate on a notional principal for a predetermined number of years. In return, it receives interest at a floating rate on the same notional principal for the same period of time. - Hull, Chapter 7</p>
</blockquote>
<h2 id="Mechanics-of-Interest-Rate-Swaps"><a href="#Mechanics-of-Interest-Rate-Swaps" class="headerlink" title="Mechanics of Interest Rate Swaps"></a>Mechanics of Interest Rate Swaps</h2><p>In other words, an interest rate swap (IRS) is an <strong>exchange</strong> of</p>
<ul>
<li><strong>Floating Leg</strong>: a series of coupons paid out at predetermined intervals based on the prevailing interest rate at the beginning of those intervals</li>
<li><strong>Fixed Leg</strong>: a series of fixed amount coupons paid out at predetermined intervals</li>
</ul>
<p>Hence, it is a swap of a fixed payment and a floating payment flow. The floating leg and the fixed leg coupons are paid as a percent of a notional amount.</p>
<p>Consider a 5 year interest rate swap initiated on Jan 1 2012 between Google and Baidu. Let’s say that Google prefers a fixed payment. Then, Google will pay 5% on a notional of \$1M every 6 months for 5 years. In return, Baidu pays Google the 6-month LIBOR rate on the same principal taken at the start of every 6 months for that 6 months. Hence, on Jan 1 2012, if the 6-month LIBOR rate is 2%, Baidu will pay Google \$2000 / 2 = \$1000 (since interest rate is annual. We assume away compounding complications for now) for that 6 months. This payment occurs at Jul 1 2012. On Jul 1 2012, if the 6-month LIBOR rate goes to 7%, Baidu will pay Google \$7000 / 2 = \$3500 on Jan 1 2013. For those 2 periods, Google always pays Baidu \$2500 per period.</p>
<p>In real markets, companies rarely negotiate such contracts on their own. Instead, they negotiate with a financial intermediary who charges a spread between the parties. The average of the fixed rates charged to either party is known as the <em>swap rate</em>.</p>
<h2 id="LIBOR-and-USD-Interest-Rate"><a href="#LIBOR-and-USD-Interest-Rate" class="headerlink" title="LIBOR and USD Interest Rate"></a>LIBOR and USD Interest Rate</h2><p>The LIBOR is used as the reference rate for the floating legs in interest rate swaps. LIBOR is the rate that AA rated banks borrow from each other. Over different periods (ranging from say spot to 12 months) the USD LIBOR forward curve is usually above the Treasury Yield curve with mostly the same shape. Hence, the LIBOR forward curve is often used by speculators to speculate on the underlying treasury yield curve (or the ECB rate curve if EUR denominated IRS are used instead).</p>
<h2 id="Interest-Rate-Swap-Yield-Rates-and-Speculation"><a href="#Interest-Rate-Swap-Yield-Rates-and-Speculation" class="headerlink" title="Interest Rate Swap Yield Rates and Speculation"></a>Interest Rate Swap Yield Rates and Speculation</h2><p>How IRS can be used for interest rate speculation is straightforward. Say that I am “paying fixed” (hence receiving the floating leg) for a 5 year IRS, colloquially termed a “5y”, that exchanges payments every 6 months. Then, I am essentially betting on the spot 6 month rate, forward 6 month rate in 6 months, forward 6 month rate in 1 year … and the forward 6 month rate in 4.5 years for each of the floating leg payments. If each of those rates go up, I am profitting since I am paying a lower amount (via the fixed rate I locked in). My counterparty would be losing since he’s paying a larger amount than he originally though.</p>
<p>Then, the IRS swap rate can be viewered as the “yield to maturity” of the fixed leg that makes the present value of the entire swap 0, given the forward rates estimated for the floating leg. Or, in other words, the swap rate is the discount rate that makes the present value of the fixed leg equal to the present value of the floating leg when the flaoting leg is discounted by each of the forward rates.</p>
<p>Hence, an IRS is an instrument to bet on the entire forward curve from spot rate to the year of maturity. A “5y” allows us to bet on the entire curve up to the 5 year point.</p>
<p>In terms of directions:</p>
<ul>
<li>If I pay fixed (receive float), when the yield curve goes up, I profit (since I’m paying less than I would have).</li>
<li>If I receive fixed (pay float), when the yield curve goes up, I lose (since I’m paying more).</li>
</ul>
<h3 id="Curve-Trades"><a href="#Curve-Trades" class="headerlink" title="Curve Trades"></a>Curve Trades</h3><p>Then, one can imagine a trade where:</p>
<ul>
<li>I pay fixed (receive float) on one 2 year IRS: I profit from the yield curve going up at the short end</li>
<li>I pay float (receive fixed) on one 10 year IRS: I profit from the yield curve going down at the long end</li>
</ul>
<p>What am I doing here? The fixed payments from now to year 2 cancel each other out, just as the floating payments. Hence, I am betting on the curve from year 2 to year 10. In other words, I am betting on a specific section of the curve, not just from today till the end of the curve. In particular, I am betting that the section of the curve <em>flattens</em> (going up at the short end and going down at the long end). There’s an important caveat to this: <strong>I do not hold this trade to maturity.</strong> Otherwise, this would cease to be a curve trade. The 2 year would expire and I would be left with one outstanding swap, making this a normal directional bet.</p>
<h3 id="Butterfly-Trades"><a href="#Butterfly-Trades" class="headerlink" title="Butterfly Trades"></a>Butterfly Trades</h3><p>Butterfly trades benefit from differing movements in 3 instruments. Imagine this trade:</p>
<ul>
<li>I pay fixed (receive float) on 2 year IRS: I profit from yield curve going up at the short end</li>
<li>I receive float (pay fixed) on 10 year IRS: I profit from the yield curve going down at the middle end</li>
<li>I pay fixed (receive float) on 30 year IRS: I profit from the yield curve going up at the long end</li>
</ul>
<p>I essentially betting on the curvature of the curve. An imaginative trader gave this trade the name, presumably because of the symmetric direction.</p>
<h1 id="PCA-on-Vanilla-IRS"><a href="#PCA-on-Vanilla-IRS" class="headerlink" title="PCA on Vanilla IRS"></a>PCA on Vanilla IRS</h1><p>We begin by performing PCA on single IRS rates. Here, I try to find the relationships between different IRS maturities. By doing this, I am essentially finding out similar components in movements of the yield curve between</p>
<ul>
<li>Spot to 1 year</li>
<li>Spot to 2 year</li>
<li>Spot to 3 year</li>
<li>Spot to 4 year</li>
<li>Spot to 5 year</li>
<li>Spot to 7 year</li>
<li>Spot to 10 year</li>
<li>Spot to 30 year</li>
</ul>
<p>An astute reader would realize that we are including the short end of the curve in all the time series, which is a problem we can solve by using curve trade yields instead in a later section.</p>
<h2 id="Data-Collection"><a href="#Data-Collection" class="headerlink" title="Data Collection"></a>Data Collection</h2><p>We collect data for the various time series from the St. Louis FRED using the <code>quantmod</code> package.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(quantmod)</span><br><span class="line"><span class="keyword">library</span>(downloader)</span><br><span class="line"></span><br><span class="line">terms = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> (term <span class="keyword">in</span> terms) &#123;</span><br><span class="line">  getSymbols(paste(<span class="string">'DSWP'</span>, term, sep=<span class="string">''</span>), src=<span class="string">'FRED'</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Then I select the data for year to date which leaves me with 250 yields over the past year.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">DSWP1 = DSWP1[!is.na(DSWP1)]</span><br><span class="line">DSWP2 = DSWP2[!is.na(DSWP2)]</span><br><span class="line">DSWP3 = DSWP3[!is.na(DSWP3)]</span><br><span class="line">DSWP4 = DSWP4[!is.na(DSWP4)]</span><br><span class="line">DSWP5 = DSWP5[!is.na(DSWP5)]</span><br><span class="line">DSWP7 = DSWP7[!is.na(DSWP7)]</span><br><span class="line">DSWP10 = DSWP10[!is.na(DSWP10)]</span><br><span class="line">DSWP30 = DSWP30[!is.na(DSWP30)]</span><br><span class="line"></span><br><span class="line">rates = cbind(DSWP1, DSWP2, DSWP3, DSWP4, DSWP5, DSWP7, DSWP10, DSWP30)</span><br><span class="line">rates = last(rates, <span class="number">250</span>)</span><br></pre></td></tr></table></figure>
<p>I can plot the yields for the different IRS maturities. Due to the upward sloping nature of the yield curve, yields of IRS with longer maturities are always higher</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="keyword">library</span>(reshape)</span><br></pre></td></tr></table></figure>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dataframe = data.frame(index(rates), rates)</span><br><span class="line">colnames(dataframe) = c(<span class="string">'date'</span>, <span class="string">'y1'</span>, <span class="string">'y2'</span>, <span class="string">'y3'</span>, <span class="string">'y4'</span>, <span class="string">'y5'</span>, <span class="string">'y7'</span>, <span class="string">'y10'</span>, <span class="string">'y30'</span>)</span><br><span class="line">melted = melt(dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=melted, aes(x=date, y=value, color=variable)) + geom_line() + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'IRS Yield Rate'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_12_0.svg" alt="svg"></p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>I perform PCA on the time series using the covariance matrix of the various time series.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pcadata = rates</span><br><span class="line">colnames(pcadata) = c(<span class="string">'y1'</span>, <span class="string">'y2'</span>, <span class="string">'y3'</span>, <span class="string">'y4'</span>, <span class="string">'y5'</span>, <span class="string">'y7'</span>, <span class="string">'y10'</span>, <span class="string">'y30'</span>)</span><br><span class="line">fit = princomp(pcadata, cor=<span class="literal">FALSE</span>, scores=<span class="literal">TRUE</span>)</span><br><span class="line">summary(fit)</span><br></pre></td></tr></table></figure>
<pre><code>Importance of components:
                          Comp.1    Comp.2     Comp.3      Comp.4       Comp.5
Standard deviation     0.3437851 0.1209262 0.07618897 0.019044680 0.0051760656
Proportion of Variance 0.8500517 0.1051749 0.04174988 0.002608666 0.0001926951
Cumulative Proportion  0.8500517 0.9552266 0.99697646 0.999585128 0.9997778228
                             Comp.6       Comp.7       Comp.8
Standard deviation     3.715011e-03 3.106083e-03 2.727945e-03
Proportion of Variance 9.926388e-05 6.939006e-05 5.352322e-05
Cumulative Proportion  9.998771e-01 9.999465e-01 1.000000e+00
</code></pre><p>First observation would be that the data has a high degree of covariance among the time series. This should not be surprising at all, since the short end of the curve was included in all these measurements.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">covariance_matrix = cor(pcadata)</span><br><span class="line"><span class="keyword">require</span>(corrplot)</span><br><span class="line">corrplot(covariance_matrix, method=<span class="string">'shade'</span>, type=<span class="string">'full'</span>, shade.col=<span class="literal">NA</span>, tl.col=<span class="string">'black'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_16_0.svg" alt="svg"></p>
<p>Correspondingly, I should expect the first few principal components to have a high proportion of explained variance.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggbiplot)</span><br><span class="line">ggbiplot(fit, obs.scale=<span class="number">1</span>, var.scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_18_0.svg" alt="svg"></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ggscreeplot(fit)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_19_0.svg" alt="svg"></p>
<p>Indeed, the first principal component accounts for 85.0% of variance, with the second principal component getting 10.5% and the third 4.1%. The first 3 principal components account for, cumulatively, 99.7% of all movements in the data. Hence, in terms of dimensionality reduction, the first 3 principal components are representative of the data.</p>
<p>We can plot the scores of the first 3 components across time.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scores = fit$scores</span><br><span class="line">scores_dataframe = data.frame(index(rates), scores)</span><br><span class="line">colnames(scores_dataframe) = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>, <span class="string">'pc4'</span>, <span class="string">'pc5'</span>, <span class="string">'pc6'</span>, <span class="string">'pc7'</span>, <span class="string">'pc8'</span>)</span><br><span class="line">keeps = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>)</span><br><span class="line">scores_dataframe = scores_dataframe[keeps]</span><br><span class="line">scores_melted = melt(scores_dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=scores_melted, aes(x=as.Date(date), y=value, color=variable)) + geom_line() + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'Principal Component Score'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_21_0.svg" alt="svg"></p>
<h2 id="Interpretation-of-Results"><a href="#Interpretation-of-Results" class="headerlink" title="Interpretation of Results"></a>Interpretation of Results</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loadings = with(fit, unclass(loadings))</span><br><span class="line">loadings</span><br></pre></td></tr></table></figure>
<table><br><thead><tr><th></th><th scope="col">Comp.1</th><th scope="col">Comp.2</th><th scope="col">Comp.3</th><th scope="col">Comp.4</th><th scope="col">Comp.5</th><th scope="col">Comp.6</th><th scope="col">Comp.7</th><th scope="col">Comp.8</th></tr></thead><br><tbody><br>    <tr><th scope="row">y1</th><td>-0.05693512</td><td>-0.13640484</td><td> 0.81073244</td><td>-0.16509581</td><td>-0.52010662</td><td>-0.10535402</td><td>-0.10119507</td><td>-0.04192361</td></tr><br>    <tr><th scope="row">y2</th><td>-0.16669185</td><td>-0.34625166</td><td> 0.43078043</td><td> 0.03625115</td><td> 0.62509086</td><td> 0.43345259</td><td> 0.19830580</td><td> 0.21792835</td></tr><br>    <tr><th scope="row">y3</th><td>-0.25832243</td><td>-0.41911497</td><td> 0.02728088</td><td> 0.32238835</td><td> 0.26957189</td><td>-0.50912909</td><td>-0.23991017</td><td>-0.51331798</td></tr><br>    <tr><th scope="row">y4</th><td>-0.3264334</td><td>-0.3807082</td><td>-0.1918120</td><td> 0.3024259</td><td>-0.3000946</td><td>-0.2516847</td><td> 0.2005263</td><td> 0.6531742</td></tr><br>    <tr><th scope="row">y5</th><td>-0.37780952</td><td>-0.27733220</td><td>-0.24318642</td><td> 0.00362353</td><td>-0.38673513</td><td> 0.55717635</td><td> 0.22904952</td><td>-0.45685974</td></tr><br>    <tr><th scope="row">y7</th><td>-0.43649941</td><td>-0.03879438</td><td>-0.15120515</td><td>-0.42341285</td><td> 0.05459486</td><td> 0.13634667</td><td>-0.73385353</td><td> 0.21379852</td></tr><br>    <tr><th scope="row">y10</th><td>-0.4708117505</td><td> 0.2213930338</td><td> 0.0007092894</td><td>-0.5524750953</td><td> 0.1530175357</td><td>-0.3715511987</td><td> 0.5064115711</td><td>-0.0785801970</td></tr><br>    <tr><th scope="row">y30</th><td>-0.490660311</td><td> 0.643019711</td><td> 0.193912132</td><td> 0.539919671</td><td> 0.008108114</td><td> 0.106656257</td><td>-0.072175546</td><td> 0.003512140</td></tr><br></tbody><br></table>




<p>However, I am also interested in the interpretation of the principal components. I hypothesized that the first 3 principal components should correspond to:</p>
<ul>
<li>Principal Component 1: Directional movements in the yield curve. These are movements that shift the entire yield curve up or down.</li>
<li>Principal Component 2: Slope movements in the yield curve. These are movements that steepen or flatten (change the first derivative wrt maturity) the entire yield curve.</li>
<li>Principal Component 3: Curvature movements in the yield curve. These are movements that change the curvature (or the second derivative wrt maturity) of the entire yield curve.</li>
</ul>
<p>I find that this interpretation stands. By evaluating the loadings of the principal components, I observe that</p>
<ul>
<li>Principal Component 1 (PC1): All IRS yields are weighted in the same direction (negative). Since the sign of the loadings are arbitrary, this means that PC1 reflects movements that causes IRS of all maturities to move in the same direction. This corresponds to directional movements in the yield curve – if the yield curve goes up, all yields go up be it the short end or the long end and vice versa.</li>
<li>Principal Component 2 (PC2): IRS yields on the short end of the curve (from y1 to y7) are weighted negatively and the ones reaching the long end (y10 and y30) are weighted positively. Since the signs are arbitrary, this means that PC2 reflects movements that cause the short end to go in one direction and the long end in the other. This is exactly what slope movements do – if the yield curve steepens, the short end goes down and the long end goes up and vice versa if the yield curve flattens.</li>
<li>Principal Component 3 (PC3): IRS yields on the short and long ends of the curve are weighted positively while the ones in the middle are weighted negatively. Since the signs are arbitrary, this means that PC3 reflects movements that cause the short and long end to go in one direction, and the middle to go in the other. This is exactly what curvature movements do – if the yield curve increases in curvature, the short and long end goes down while the middle goes up.</li>
</ul>
<p>Hence PC1 can be interpreted as directional movements, PC2 as slope movements, and PC3 as curvature movements.</p>
<h2 id="Shortcoming"><a href="#Shortcoming" class="headerlink" title="Shortcoming"></a>Shortcoming</h2><p>I find this analysis lacking in one striking way: we are unable to isolate portions of the curve. For example, the time series for y30 includes movements from the spot all the way to year 30. In other words, it includes movements of the y1, y2, y3 etc. In a similar way, the y3 includes movements of y1. Hence, we are unable to isolate movements in the “long end only” and are instead forced to make conclusions about yield rates “from the short end to the long end” or on the “short end” only.</p>
<p>This could be done instead by measuring yields for curve trades. This is what I will do in the next section.</p>
<h1 id="PCA-on-Curve-Trade-Rates"><a href="#PCA-on-Curve-Trade-Rates" class="headerlink" title="PCA on Curve Trade Rates"></a>PCA on Curve Trade Rates</h1><h2 id="Review-on-Curve-Trades-and-Butterfly-Trades"><a href="#Review-on-Curve-Trades-and-Butterfly-Trades" class="headerlink" title="Review on Curve Trades and Butterfly Trades"></a>Review on Curve Trades and Butterfly Trades</h2><p>Refer to the introduction for a complete breakdown of curve trades and butterfly trades. As a reminder,</p>
<ul>
<li>Curve trades are bets on the slope of a specific section of the curve</li>
<li>Butterflies are bets on the curvature of two specific sections of the curve.</li>
</ul>
<h2 id="Data-Collection-1"><a href="#Data-Collection-1" class="headerlink" title="Data Collection"></a>Data Collection</h2><p>I employ most of the same data collection methods as in the previous section.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(quantmod)</span><br><span class="line"><span class="keyword">library</span>(downloader)</span><br><span class="line"></span><br><span class="line">terms = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">30</span>)</span><br><span class="line"><span class="keyword">for</span> (term <span class="keyword">in</span> terms) &#123;</span><br><span class="line">  getSymbols(paste(<span class="string">'DSWP'</span>, term, sep=<span class="string">''</span>), src=<span class="string">'FRED'</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DSWP1 = DSWP1[!is.na(DSWP1)]</span><br><span class="line">DSWP2 = DSWP2[!is.na(DSWP2)]</span><br><span class="line">DSWP3 = DSWP3[!is.na(DSWP3)]</span><br><span class="line">DSWP4 = DSWP4[!is.na(DSWP4)]</span><br><span class="line">DSWP5 = DSWP5[!is.na(DSWP5)]</span><br><span class="line">DSWP7 = DSWP7[!is.na(DSWP7)]</span><br><span class="line">DSWP10 = DSWP10[!is.na(DSWP10)]</span><br><span class="line">DSWP30 = DSWP30[!is.na(DSWP30)]</span><br></pre></td></tr></table></figure>
<p>The yield of a curve trade is calculated as follow:</p>
<p>$$C = S_{0, t_2} - S_{0, t_1}$$</p>
<p>where $C$ is the curve trade rate, $S_{0,t_2}$ is the swap rate for an IRS of maturity $t_2$ and $S_{0, t_2}$ is the swap rate for an IRS of maturity $t_1$. Intuitively, we can think of this the forward rate from $t_1$ to $t_2$ and indeed it is. We select the following “tenors” (sections of the yield curve) to represent the whole yield curve. They are quoted as “XsYs” where we pay fix for X years and receive fix for Y years of IRS.</p>
<ul>
<li>2s1s</li>
<li>3s1s</li>
<li>4s1s</li>
<li>5s1s</li>
<li>7s1s</li>
<li>10s2s</li>
<li>10s5s</li>
<li>30s10s</li>
</ul>
<p>And select only the rates for the year to date.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2-1, 3-1, 4-1, 5-1, 7-1, 10-2, 10-5, 30-10</span></span><br><span class="line">curve2_1 = DSWP2 - DSWP1</span><br><span class="line">curve3_1 = DSWP3 - DSWP1</span><br><span class="line">curve4_1 = DSWP4 - DSWP1</span><br><span class="line">curve5_1 = DSWP5 - DSWP1</span><br><span class="line">curve7_1 = DSWP7 - DSWP1</span><br><span class="line">curve10_2 = DSWP10 - DSWP2</span><br><span class="line">curve10_5 = DSWP10 - DSWP5</span><br><span class="line">curve30_10 = DSWP30 - DSWP10</span><br><span class="line"></span><br><span class="line">rates = cbind(curve2_1, curve3_1, curve4_1, curve5_1, curve7_1, curve10_2, curve10_5, curve30_10)</span><br><span class="line">rates = last(rates, <span class="number">250</span>)</span><br><span class="line">colnames(rates) = c(<span class="string">'curve2y1y'</span>, <span class="string">'curve3y1y'</span>, <span class="string">'curve4y1y'</span>, <span class="string">'curve5y1y'</span>, <span class="string">'curve7y1y'</span>, <span class="string">'curve10y2y'</span>, <span class="string">'curve10y5y'</span>, <span class="string">'curve30y10y'</span>)</span><br></pre></td></tr></table></figure>
<p>As for the vanilla yields, I can plot a time series of the different curve rates. However, this chart isn’t very telling, since I am measuring different ends of the curve.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line"><span class="keyword">library</span>(reshape)</span><br><span class="line">dataframe = data.frame(index(rates), rates)</span><br><span class="line">colnames(dataframe) = c(<span class="string">'date'</span>, <span class="string">'curve2y1y'</span>, <span class="string">'curve3y1y'</span>, <span class="string">'curve4y1y'</span>, <span class="string">'curve5y1y'</span>, <span class="string">'curve7y1y'</span>, <span class="string">'curve10y2y'</span>, <span class="string">'curve10y5y'</span>, <span class="string">'curve30y10y'</span>)</span><br><span class="line">melted = melt(dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=melted, aes(x=as.Date(date), y=value, color=variable)) + geom_line()</span><br><span class="line">plot</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_31_0.svg" alt="svg"></p>
<h2 id="Results-1"><a href="#Results-1" class="headerlink" title="Results"></a>Results</h2><p>I perform PCA on the series as well using the covariance matrix of the time series.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pcadata = rates</span><br><span class="line">colnames(pcadata) = c(<span class="string">'curve2y1y'</span>, <span class="string">'curve3y1y'</span>, <span class="string">'curve4y1y'</span>, <span class="string">'curve5y1y'</span>, <span class="string">'curve7y1y'</span>, <span class="string">'curve10y2y'</span>, <span class="string">'curve10y5y'</span>, <span class="string">'curve30y10y'</span>)</span><br><span class="line">fit = princomp(pcadata, cor=<span class="literal">FALSE</span>, scores=<span class="literal">TRUE</span>)</span><br><span class="line">summary(fit)</span><br></pre></td></tr></table></figure>
<pre><code>Importance of components:
                          Comp.1    Comp.2      Comp.3      Comp.4       Comp.5
Standard deviation     0.2775099 0.1294640 0.028713618 0.011572150 0.0048336969
Proportion of Variance 0.8126072 0.1768567 0.008699608 0.001413032 0.0002465373
Cumulative Proportion  0.8126072 0.9894639 0.998163497 0.999576529 0.9998230661
                             Comp.6       Comp.7 Comp.8
Standard deviation     2.971792e-03 2.817212e-03      0
Proportion of Variance 9.318811e-05 8.374576e-05      0
Cumulative Proportion  9.999163e-01 1.000000e+00      1
</code></pre><p>Again, the series has a high degree of covariance among the time series. This again should not be surprising, since they are all yield rates after all (though of different tenors) hence should be driven by the same macroeconomic factors.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">covariance_matrix = cor(pcadata)</span><br><span class="line"><span class="keyword">require</span>(corrplot)</span><br><span class="line">corrplot(covariance_matrix, method=<span class="string">'shade'</span>, type=<span class="string">'full'</span>, shade.col=<span class="literal">NA</span>, tl.col=<span class="string">'black'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_35_0.svg" alt="svg"></p>
<p>However, what should be interesting to note is that some time series now have somewhat negative covariance with others. These happen to be between the far short end of the curve and the far long end (eg. 2s1s vs 30s10s). This makes sense, since the far end usually doesn’t move as much as the short end, and sometimes in the opposite direction (slope).</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggbiplot)</span><br><span class="line">ggbiplot(fit, obs.scale=<span class="number">1</span>, var.scale=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_37_0.svg" alt="svg"></p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ggscreeplot(fit)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_38_0.svg" alt="svg"></p>
<p>The first principal component accounts for 81.3% of variance, with the second principal component getting 17.7% and the third 0.87%. The first 3 principal components account for, cumulatively, 99.8% of all movements in the data. Hence, in terms of dimensionality reduction, the first 3 principal components are representative of the data.</p>
<p>We can plot the scores of the first 3 components across time.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scores = fit$scores</span><br><span class="line">scores_dataframe = data.frame(index(rates), scores)</span><br><span class="line">colnames(scores_dataframe) = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>, <span class="string">'pc4'</span>, <span class="string">'pc5'</span>, <span class="string">'pc6'</span>, <span class="string">'pc7'</span>, <span class="string">'pc8'</span>)</span><br><span class="line">keeps = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>)</span><br><span class="line">scores_dataframe = scores_dataframe[keeps]</span><br><span class="line">scores_melted = melt(scores_dataframe, id.vars=<span class="string">'date'</span>)</span><br><span class="line">plot = ggplot(data=scores_melted, aes(x=as.Date(date), y=value, color=variable)) + geom_line() + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'Principal Component Score'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_40_0.svg" alt="svg"></p>
<h2 id="Interpretation-of-Results-1"><a href="#Interpretation-of-Results-1" class="headerlink" title="Interpretation of Results"></a>Interpretation of Results</h2><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loadings = with(fit, unclass(loadings))</span><br><span class="line">loadings</span><br></pre></td></tr></table></figure>
<table><br><thead><tr><th></th><th scope="col">Comp.1</th><th scope="col">Comp.2</th><th scope="col">Comp.3</th><th scope="col">Comp.4</th><th scope="col">Comp.5</th><th scope="col">Comp.6</th><th scope="col">Comp.7</th><th scope="col">Comp.8</th></tr></thead><br><tbody><br>    <tr><th scope="row">curve2y1y</th><td>-0.171227734</td><td>-0.195448923</td><td> 0.004706401</td><td> 0.667761277</td><td> 0.255984666</td><td>-0.361642751</td><td>-0.200598804</td><td>-0.500000000</td></tr><br>    <tr><th scope="row">curve3y1y</th><td>-3.263336e-01</td><td>-2.874607e-01</td><td> 1.814160e-01</td><td> 2.487582e-01</td><td>-5.310257e-01</td><td> 5.745447e-01</td><td>-3.224754e-01</td><td> 3.785444e-13</td></tr><br>    <tr><th scope="row">curve4y1y</th><td>-4.295687e-01</td><td>-2.585274e-01</td><td> 2.043599e-01</td><td>-1.301226e-01</td><td>-4.286356e-01</td><td>-4.860891e-01</td><td> 5.195463e-01</td><td>-6.752862e-13</td></tr><br>    <tr><th scope="row">curve5y1y</th><td>-0.49071115</td><td>-0.14814235</td><td> 0.05408491</td><td>-0.21436777</td><td> 0.33797228</td><td>-0.25143465</td><td>-0.51081605</td><td> 0.50000000</td></tr><br>    <tr><th scope="row">curve7y1y</th><td>-5.385355e-01</td><td> 1.119178e-01</td><td>-1.587484e-01</td><td> 1.153416e-01</td><td> 4.549395e-01</td><td> 4.507466e-01</td><td> 4.988054e-01</td><td>-3.640491e-13</td></tr><br>    <tr><th scope="row">curve10y2y</th><td>-0.38081672</td><td> 0.58044994</td><td>-0.17867132</td><td>-0.33936332</td><td>-0.20605357</td><td>-0.06584042</td><td>-0.27234639</td><td>-0.50000000</td></tr><br>    <tr><th scope="row">curve10y5y</th><td>-0.06133330</td><td> 0.53314337</td><td>-0.22804983</td><td> 0.54276573</td><td>-0.28804119</td><td>-0.17604852</td><td> 0.03787086</td><td> 0.50000000</td></tr><br>    <tr><th scope="row">curve30y10y</th><td>7.557077e-03</td><td>3.958458e-01</td><td>9.018019e-01</td><td>7.913918e-02</td><td>1.487753e-01</td><td>3.332223e-02</td><td>2.224416e-02</td><td>5.464379e-16</td></tr><br></tbody><br></table>




<p>Earlier I confirmed my hypothesis of the interpretation of the principal components, namely that:</p>
<ul>
<li>Principal Component 1: Directional movements in the yield curve. These are movements that shift the entire yield curve up or down.</li>
<li>Principal Component 2: Slope movements in the yield curve. These are movements that steepen or flatten (change the first derivative wrt maturity) the entire yield curve.</li>
<li>Principal Component 3: Curvature movements in the yield curve. These are movements that change the curvature (or the second derivative wrt maturity) of the entire yield curve.</li>
</ul>
<p>Recall that the major shortcoming of that analysis was that we included the short end of the curve in all our time series and was unable to isolate the middle portion fo the curve individually. We are able to do that now. We see that the same interpretation of the principal components hold.</p>
<ul>
<li>Principal Component 1: Almost all the loadings are negative (with a very small positive for the 30s10s which we can ignore since it is two orders of magnitude smaller than the other loadings and would have been suppressed by <code>R</code>‘s output if not for the fact that I forced the output to be present). Since the signs of loadings are arbitrary in PCA, we can conclude that in PC1 type movement, all sections of the yield curve move in the same direction. This corresponds to directional movements in the yield curve where the entire curve shifts up or down.</li>
<li>Principal Component 2: The short end of the curve (2s1s, 3s1s, 4s1s, 5s1s) are negative while the middle (7s1s, 10s2s, 10s5s) are positive as far the far end (30s10s). Again, signs are arbitrary in PCA loadings. This means that in PC2 type movements, the far and middle end moves in opposite direction as the short end. This corresponds well with the slope interpretation.</li>
<li>Principal Component 3: The short end and the long end moves in the same direction while the middle end moves in the opposite direction. This again corresponds well with the interpretation of curvature movements.</li>
</ul>
<p>This relationship is summarized in the plot below.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">loadings = with(fit, unclass(loadings))</span><br><span class="line">loadings_dataframe = data.frame(index(loadings), loadings)</span><br><span class="line">colnames(loadings_dataframe) = c(<span class="string">'tenor'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>, <span class="string">'pc4'</span>, <span class="string">'pc5'</span>, <span class="string">'pc6'</span>, <span class="string">'pc7'</span>, <span class="string">'pc8'</span>)</span><br><span class="line">keeps = c(<span class="string">'tenor'</span>, <span class="string">'pc1'</span>, <span class="string">'pc2'</span>, <span class="string">'pc3'</span>)</span><br><span class="line">loadings_dataframe = loadings_dataframe[keeps]</span><br><span class="line">loadings_melted = melt(loadings_dataframe, id.vars=<span class="string">'tenor'</span>)</span><br><span class="line">plot = ggplot() + geom_line(data=loadings_melted, aes(x=tenor, y=value, color=variable)) + scale_x_discrete(labels=c(<span class="string">'2y1y'</span>, <span class="string">'3y1y'</span>, <span class="string">'4y1y'</span>, <span class="string">'5y1y'</span>, <span class="string">'7y1y'</span>, <span class="string">'10y2y'</span>, <span class="string">'10y5y'</span>, <span class="string">'30y10y'</span>)) + xlab(<span class="string">'Tenor'</span>) + ylab(<span class="string">'Loading of First 3 PCs'</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_44_0.svg" alt="svg"></p>
<p>To confirm this further, I can plot each of the principal components with yield movements.</p>
<h3 id="First-Principal-Component"><a href="#First-Principal-Component" class="headerlink" title="First Principal Component"></a>First Principal Component</h3><p>I plot both the scores of the first principal component and the swap rate for a 10 year IRS and find that the correlation indeed holds up, and this shows that my interpretation of the principal component holds.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span>(<span class="string">'graphing_utility.R'</span>)</span><br><span class="line">first_factor_10y = data.frame(rownames(scores), scores_dataframe$pc1, last(DSWP10, <span class="number">250</span>))</span><br><span class="line">colnames(first_factor_10y) = c(<span class="string">'date'</span>, <span class="string">'pc1'</span>, <span class="string">'y10'</span>)</span><br><span class="line">first_factor_10y$pc1 = -first_factor_10y$pc1</span><br><span class="line"></span><br><span class="line">p1 = ggplot() + geom_line(data=first_factor_10y, aes(x=as.Date(date), y=pc1), colour=gg_color_hue(<span class="number">1</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'left/red: PC1\nright/blue: 10y Yield'</span>)</span><br><span class="line">p2 = ggplot() + geom_line(data=first_factor_10y, aes(x=as.Date(date), y=y10), colour=gg_color_hue(<span class="number">2</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(panel.background = element_rect(fill = <span class="literal">NA</span>))</span><br><span class="line">g = stack_plot(p1, p2)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_46_0.svg" alt="svg"></p>
<h3 id="Second-Principal-Component"><a href="#Second-Principal-Component" class="headerlink" title="Second Principal Component"></a>Second Principal Component</h3><p>To see that the second principal component holds, I use a common curve trade: 10s2s. To see why this represents slope, one can consider the bets I made:</p>
<ul>
<li>Receive fixed for 10 year IRS: if rates go up on the long end, I lose</li>
<li>Pay fixed for 2 year IRS: if rates go up in the short end, I gain</li>
</ul>
<p>Hence, I’m making a bet on the slope of the curve. In fact, this bet is a steepener (I profit when the curve steepens). The yield rate for this trade is constructed as:</p>
<p>$$C_{2, 10} = Y_{0, 10} - Y_{0, 2}$$</p>
<p>where $C$ is the rate for curve trade, $Y$ is the IRS yield.</p>
<p>I again find a high level of correlation in the movements.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">second_factor_10y2y = data.frame(rownames(scores), scores_dataframe$pc2, last(curve10_2, <span class="number">250</span>))</span><br><span class="line">colnames(second_factor_10y2y) = c(<span class="string">'date'</span>, <span class="string">'pc2'</span>, <span class="string">'curve10y2y'</span>)</span><br><span class="line"></span><br><span class="line">p1 = ggplot() + geom_line(data=second_factor_10y2y, aes(x=as.Date(date), y=pc2), colour=gg_color_hue(<span class="number">1</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'left/red: PC2\nright/blue: 10s2s Yield'</span>)</span><br><span class="line">p2 = ggplot() + geom_line(data=second_factor_10y2y, aes(x=as.Date(date), y=curve10y2y), colour=gg_color_hue(<span class="number">2</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(panel.background = element_rect(fill = <span class="literal">NA</span>))</span><br><span class="line">g = stack_plot(p1, p2)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_48_0.svg" alt="svg"></p>
<h3 id="Third-Principal-Component"><a href="#Third-Principal-Component" class="headerlink" title="Third Principal Component"></a>Third Principal Component</h3><p>To see that the third principal component holds, I use another common trade: a butterfly of 2s10s30s. This is essentially:</p>
<ul>
<li>Receive fixed on 2 year IRS: I lose if rates go up on the short end</li>
<li>Pay fixed on two 10 year IRS: I gain if rates go up in the middle end</li>
<li>Receive fixed on 30 year IRS: I lose if rates go up in the far end</li>
</ul>
<p>The yield can be constructed as</p>
<p>$$C_{2,10,30} = \left(Y_{0,10} - Y_{0,2}\right) - \left(Y_{0,30} - Y_{0,10}\right)$$</p>
<p>Essentially, I am long two 10 year IRS, and short one 2 year IRS and one 30 year IRS. This can be seen as a bet on curvature. If the rates go up in the middle and go down in the two ends, I profit. Thus this is a curvature bet.</p>
<p>Again there is a high degree of correlation between this and the yields of a butterfly, confirming my interpretation of the third principal component.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">butterfly2_10_30 = (DSWP10 - DSWP5) - (DSWP30 - DSWP10)</span><br><span class="line">third_factor_butterfly = data.frame(rownames(scores), scores_dataframe$pc3, last(butterfly2_10_30, <span class="number">250</span>))</span><br><span class="line">colnames(third_factor_butterfly) = c(<span class="string">'date'</span>, <span class="string">'pc3'</span>, <span class="string">'butterfly2y10y30y'</span>)</span><br><span class="line">third_factor_butterfly$pc3 = -third_factor_butterfly$pc3</span><br><span class="line"></span><br><span class="line">p1 = ggplot() + geom_line(data=third_factor_butterfly, aes(x=as.Date(date), y=pc3), colour=gg_color_hue(<span class="number">1</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + xlab(<span class="string">'Date'</span>) + ylab(<span class="string">'left/red: PC3, right/blue: 2s10s30s Yield'</span>)</span><br><span class="line">p2 = ggplot() + geom_line(data=third_factor_butterfly, aes(x=as.Date(date), y=butterfly2y10y30y), colour=gg_color_hue(<span class="number">2</span>)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) + theme(panel.background = element_rect(fill = <span class="literal">NA</span>))</span><br><span class="line">g = stack_plot(p1, p2)</span><br><span class="line">grid.draw(g)</span><br></pre></td></tr></table></figure>
<p><img src="/images/pca-irs/output_50_0.svg" alt="svg"></p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/10/26/Binomial-European-Option-Pricing-in-R/"><span>Binomial European Option Pricing in R</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/26/Binomial-European-Option-Pricing-in-R/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-26T04:48:14.000Z">
          2015-10-26
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>The code for this is available at <a href="https://github.com/linanqiu/binomial-european-option-r" target="_blank" rel="external">linanqiu/binomial-european-option-r</a>.</p>
<p>This post by Intel <a href="https://software.intel.com/en-us/articles/binomial-options-pricing-model-code-for-intel-xeon-phi-coprocessor" target="_blank" rel="external">https://software.intel.com/en-us/articles/binomial-options-pricing-model-code-for-intel-xeon-phi-coprocessor</a> is a surprisingly good explanation of the theoretical background of this subject and an insanely fast CPU level implementation of this.</p>
<p>My Financial Engineering class was working on Binomial European Option Pricing, and the prof insisted that we show the entire tree matrix for the intermediate steps (and not just the final price). Turns out the packages available on <a href="https://cran.r-project.org/" target="_blank" rel="external">https://cran.r-project.org/</a> don’t seem to do that. Either way, good exercise to implement this from scratch and revise for the midterms.</p>
<p>First, let’s talk about our model.</p>
<p>Let’s say time is $T$ where $T=1$ represents a year, and $T=0.25$ represents 3 months. The number of periods we simulate is $N$. Then, the amount of time represented by each period is $\Delta t = \frac{T}{N}$.</p>
<p>We assume that in each period, the stock can go up by</p>
<p>$$U = e^{\sigma * \sqrt{\Delta t}}$$</p>
<p>where $\sigma$ is the volatility, and $\Delta t$ is $\frac{T}{N}$.</p>
<p>Then, if the stock value is $S$ at period 1, it would go up to</p>
<p>$$S_U = US = e^{\sigma * \sqrt{\Delta t}}S$$ in period 2.</p>
<p>It can also go down by</p>
<p>$$D = e^{-\sigma * \sqrt{\Delta t}}$$.</p>
<p>Astute readers will recognize this as a <strong>Geometric Brownian Motion</strong> (I will probably make another post about this next time).</p>
<p>That means, say $S=10$ and $\sigma = 0.2$, $T=1$ (1 year) and $N=2$, then $U = e^{\sigma * sqrt{\Delta t}} = 1.15191$ and $D = 0.8681234$.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">period 0: 10.0</span><br><span class="line">period 1: 8.68  11.5</span><br><span class="line">period 2: 7.54  10.0  13.3</span><br></pre></td></tr></table></figure>
<p>The number directly below represents $S_D = DS$ and the number directly above represents $S_U = US$, and the second period is calculated recursively.</p>
<p>Then, we can build a stock tree!</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">build_stock_tree = <span class="keyword">function</span>(S, sigma, delta_t, N) &#123;</span><br><span class="line">  tree = matrix(<span class="number">0</span>, nrow=N+<span class="number">1</span>, ncol=N+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  u = exp(sigma*sqrt(delta_t))</span><br><span class="line">  d = exp(-sigma*sqrt(delta_t))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:(N+<span class="number">1</span>)) &#123;</span><br><span class="line">    <span class="keyword">for</span> (j <span class="keyword">in</span> <span class="number">1</span>:i) &#123;</span><br><span class="line">      tree[i,j] = S * u^(j-<span class="number">1</span>) * d^((i-<span class="number">1</span>)-(j-<span class="number">1</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>(tree)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>To see what this gives us, let’s try it with the parameters above:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; build_stock_tree(S=10, sigma=0.2, delta_t=1/2, N=2)</span><br><span class="line">          [,1]    [,2]     [,3]</span><br><span class="line">[1,] 10.000000  0.0000  0.00000</span><br><span class="line">[2,]  8.681234 11.5191  0.00000</span><br><span class="line">[3,]  7.536383 10.0000 13.26896</span><br></pre></td></tr></table></figure>
<p>Cool! We just did what we wanted to do but way faster. In fact, we can expand the number of levels really easily. Note that when <code>N</code> changes, <code>delta_t</code> should change too. This is not too much of a problem – we’ll be calculating <code>delta_t</code> programmatically soon.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; build_stock_tree(S=<span class="number">10</span>, sigma=<span class="number">0.2</span>, delta_t=<span class="number">1</span>/<span class="number">5</span>, N=<span class="number">5</span>)</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]     [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">10.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">2</span>,]  <span class="number">9.144406</span> <span class="number">10.935647</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">3</span>,]  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.958837</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">4</span>,]  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.935647</span> <span class="number">13.07776</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">5</span>,]  <span class="number">6.992333</span>  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.95884</span> <span class="number">14.30138</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">6</span>,]  <span class="number">6.394073</span>  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.93565</span> <span class="number">13.07776</span> <span class="number">15.63948</span></span><br></pre></td></tr></table></figure>
<p>Now how do we get an option’s price from the underlier’s (stock’s) price? Let’s say that we have a <strong>call</strong> option. Then, we know that at termination, the value of the call option is $\max(S-X, 0)$ where $S$ here is the price of the stock at termination, and $X$ is the strike price. So say $X=10$, then in our example above, the various values of the call option would be</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.0000000 0.0000000 0.0000000 0.9356469 3.0777623 5.6394832</span><br></pre></td></tr></table></figure>
<p>But how do we advance up the option back to the price at the beginning? We call upon the powers of the <strong>q-measure</strong> where $q$ is the risk-neutral no-arbitrage probability which is independent of the actual probability of the stock going up or down. Finance textbooks tell us that</p>
<p>$$q \equiv \frac{R-D}{U-D}$$</p>
<p>where $R$ is $e^{r*\Delta t}$ where $r$ is the interest rate per annum continuously compounded. $R$ is then the discount factor. The derivation of $$q$$ will be left to another time.</p>
<p>Then, we can write a function to calculate $$q$$.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">q_prob = <span class="keyword">function</span>(r, delta_t, sigma) &#123;</span><br><span class="line">  u = exp(sigma*sqrt(delta_t))</span><br><span class="line">  d = exp(-sigma*sqrt(delta_t))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span>((exp(r*delta_t) - d)/(u-d))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Then, we know that</p>
<p>$$C = \frac{qC_U + (1-q)C_D}{R}$$</p>
<p>where $C$ is the price of the option in a previous time period, and $C_U$ is the value of the option when the underlier went up, and $C_D$ is the value of the option when the underlier went down.</p>
<p>That means we can derive the step above the last row of the call option. Let’s say that $r = 0.1$ for <strong>10 percent interest continuously compounded a year.</strong> First we find that</p>
<p>$$R = e^{r * \Delta t} = e^{\frac{0.1}{5}} = 1.020201$$</p>
<p>Then, $q = \frac{R-D}{U-D} = 0.5904327$ using our <code>q_prob</code> function above with <code>q_prob(0.1, 1/5, 0.2)</code>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">0.0000000 0.0000000 0.5414976 2.1568506 4.499392 0.000000</span><br><span class="line">0.0000000 0.0000000 0.0000000 0.9356469 3.077762 5.639483</span><br></pre></td></tr></table></figure>
<p>You should verify the first row using the q-measure method.</p>
<p>We can code this into a method (account for both “put” and “call”).</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">value_binomial_option = <span class="keyword">function</span>(tree, sigma, delta_t, r, X, type) &#123;</span><br><span class="line">  q = q_prob(r, delta_t, sigma)</span><br><span class="line"></span><br><span class="line">  option_tree = matrix(<span class="number">0</span>, nrow=nrow(tree), ncol=ncol(tree))</span><br><span class="line">  <span class="keyword">if</span>(type == <span class="string">'put'</span>) &#123;</span><br><span class="line">    option_tree[nrow(option_tree),] = pmax(X - tree[nrow(tree),], <span class="number">0</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    option_tree[nrow(option_tree),] = pmax(tree[nrow(tree),] - X, <span class="number">0</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> (nrow(tree)-<span class="number">1</span>):<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span>(j <span class="keyword">in</span> <span class="number">1</span>:i) &#123;</span><br><span class="line">      option_tree[i, j] = ((<span class="number">1</span>-q)*option_tree[i+<span class="number">1</span>,j] + q*option_tree[i+<span class="number">1</span>,j+<span class="number">1</span>])/exp(r*delta_t)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>(option_tree)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>This function takes in a stock tree generated in the <code>build_stock_tree</code> function, and returns an option tree. For the previous option, it would generate</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; tree = build_stock_tree(S=<span class="number">10</span>, sigma=<span class="number">0.2</span>, delta_t=<span class="number">1</span>/<span class="number">5</span>, N=<span class="number">5</span>)</span><br><span class="line">&gt; value_binomial_option(tree, sigma=<span class="number">0.2</span>, delta_t=<span class="number">1</span>/<span class="number">5</span>, r=<span class="number">0.1</span>, X=<span class="number">10</span>, type=<span class="string">'call'</span>)</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]      [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">1.3515415</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">2</span>,] <span class="number">0.6365307</span> <span class="number">1.8937675</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">3</span>,] <span class="number">0.1813700</span> <span class="number">0.9740419</span> <span class="number">2.5965507</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">4</span>,] <span class="number">0.0000000</span> <span class="number">0.3133870</span> <span class="number">1.4656468</span> <span class="number">3.4698679</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">5</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.5414976</span> <span class="number">2.1568506</span> <span class="number">4.499392</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">6</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.9356469</span> <span class="number">3.077762</span> <span class="number">5.639483</span></span><br></pre></td></tr></table></figure>
<p>Now let’s put everything together and make the output a nice little list.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">binomial_option = <span class="keyword">function</span>(type, sigma, <span class="literal">T</span>, r, X, S, N) &#123;</span><br><span class="line">  q = q_prob(r=r, delta_t=<span class="literal">T</span>/N, sigma=sigma)</span><br><span class="line">  tree = build_stock_tree(S=S, sigma=sigma, delta_t=<span class="literal">T</span>/N, N=N)</span><br><span class="line">  option = value_binomial_option(tree, sigma=sigma, delta_t=<span class="literal">T</span>/N, r=r, X=X, type=type)</span><br><span class="line">  <span class="keyword">return</span>(list(q=q, stock=tree, option=option, price=option[<span class="number">1</span>,<span class="number">1</span>], delta=delta))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Usually, there’s also something that we want to compute: the $$\Delta$$ of stocks – the amount of stocks that are required to replicate the portfolio.</p>
<p>$$\Delta = \frac{C_U - C_D}{S_U - S_D}$$</p>
<p>We code this as</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">delta = <span class="keyword">function</span>(binomial_option, row, col) &#123;</span><br><span class="line">  stock_tree = binomial_option$stock</span><br><span class="line">  option_tree = binomial_option$option</span><br><span class="line">  <span class="keyword">return</span>((option_tree[row+<span class="number">1</span>, col+<span class="number">1</span>] - option_tree[row+<span class="number">1</span>, col])/(stock_tree[row+<span class="number">1</span>, col+<span class="number">1</span>] - stock_tree[row+<span class="number">1</span>, col]))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Then, the overall function becomes</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">binomial_option = <span class="keyword">function</span>(type, sigma, <span class="literal">T</span>, r, X, S, N) &#123;</span><br><span class="line">  q = q_prob(r=r, delta_t=<span class="literal">T</span>/N, sigma=sigma)</span><br><span class="line">  tree = build_stock_tree(S=S, sigma=sigma, delta_t=<span class="literal">T</span>/N, N=N)</span><br><span class="line">  option = value_binomial_option(tree, sigma=sigma, delta_t=<span class="literal">T</span>/N, r=r, X=X, type=type)</span><br><span class="line">  delta = (option[<span class="number">2</span>,<span class="number">2</span>]-option[<span class="number">2</span>,<span class="number">1</span>])/(tree[<span class="number">2</span>,<span class="number">2</span>]-tree[<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">  <span class="keyword">return</span>(list(q=q, stock=tree, option=option, price=option[<span class="number">1</span>,<span class="number">1</span>], delta=delta))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Look how pretty the output is for our example!</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; binomial_option(type=<span class="string">'call'</span>, sigma=<span class="number">0.2</span>, <span class="literal">T</span>=<span class="number">1</span>, r=<span class="number">0.1</span>, X=<span class="number">10</span>, S=<span class="number">10</span>, N=<span class="number">5</span>)</span><br><span class="line">$q</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.5904327</span></span><br><span class="line"></span><br><span class="line">$stock</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]     [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">10.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">2</span>,]  <span class="number">9.144406</span> <span class="number">10.935647</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">3</span>,]  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.958837</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">4</span>,]  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.935647</span> <span class="number">13.07776</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">5</span>,]  <span class="number">6.992333</span>  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.95884</span> <span class="number">14.30138</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">6</span>,]  <span class="number">6.394073</span>  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.93565</span> <span class="number">13.07776</span> <span class="number">15.63948</span></span><br><span class="line"></span><br><span class="line">$option</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]      [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">1.3515415</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">2</span>,] <span class="number">0.6365307</span> <span class="number">1.8937675</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">3</span>,] <span class="number">0.1813700</span> <span class="number">0.9740419</span> <span class="number">2.5965507</span> <span class="number">0.0000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">4</span>,] <span class="number">0.0000000</span> <span class="number">0.3133870</span> <span class="number">1.4656468</span> <span class="number">3.4698679</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">5</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.5414976</span> <span class="number">2.1568506</span> <span class="number">4.499392</span> <span class="number">0.000000</span></span><br><span class="line">[<span class="number">6</span>,] <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.0000000</span> <span class="number">0.9356469</span> <span class="number">3.077762</span> <span class="number">5.639483</span></span><br><span class="line"></span><br><span class="line">$price</span><br><span class="line">[<span class="number">1</span>] <span class="number">1.351541</span></span><br><span class="line"></span><br><span class="line">$delta</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.7018805</span></span><br></pre></td></tr></table></figure>
<p>Let’s try the model for a put with the same parameters.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; binomial_option(type=<span class="string">'put'</span>, sigma=<span class="number">0.2</span>, <span class="literal">T</span>=<span class="number">1</span>, r=<span class="number">0.1</span>, X=<span class="number">10</span>, S=<span class="number">10</span>, N=<span class="number">5</span>)</span><br><span class="line">$q</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.5904327</span></span><br><span class="line"></span><br><span class="line">$stock</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]      [,<span class="number">3</span>]     [,<span class="number">4</span>]     [,<span class="number">5</span>]     [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">10.000000</span>  <span class="number">0.000000</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">2</span>,]  <span class="number">9.144406</span> <span class="number">10.935647</span>  <span class="number">0.000000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">3</span>,]  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.958837</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">4</span>,]  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.935647</span> <span class="number">13.07776</span>  <span class="number">0.00000</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">5</span>,]  <span class="number">6.992333</span>  <span class="number">8.362017</span> <span class="number">10.000000</span> <span class="number">11.95884</span> <span class="number">14.30138</span>  <span class="number">0.00000</span></span><br><span class="line">[<span class="number">6</span>,]  <span class="number">6.394073</span>  <span class="number">7.646568</span>  <span class="number">9.144406</span> <span class="number">10.93565</span> <span class="number">13.07776</span> <span class="number">15.63948</span></span><br><span class="line"></span><br><span class="line">$option</span><br><span class="line">          [,<span class="number">1</span>]      [,<span class="number">2</span>]       [,<span class="number">3</span>] [,<span class="number">4</span>] [,<span class="number">5</span>] [,<span class="number">6</span>]</span><br><span class="line">[<span class="number">1</span>,] <span class="number">0.3999157</span> <span class="number">0.0000000</span> <span class="number">0.00000000</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">2</span>,] <span class="number">0.7232877</span> <span class="number">0.1892841</span> <span class="number">0.00000000</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">3</span>,] <span class="number">1.2369985</span> <span class="number">0.3916873</span> <span class="number">0.05535867</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">4</span>,] <span class="number">1.9613263</span> <span class="number">0.7768750</span> <span class="number">0.13789428</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">5</span>,] <span class="number">2.8096541</span> <span class="number">1.4399698</span> <span class="number">0.34348430</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line">[<span class="number">6</span>,] <span class="number">3.6059268</span> <span class="number">2.3534319</span> <span class="number">0.85559356</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span></span><br><span class="line"></span><br><span class="line">$price</span><br><span class="line">[<span class="number">1</span>] <span class="number">0.3999157</span></span><br><span class="line"></span><br><span class="line">$delta</span><br><span class="line">[<span class="number">1</span>] -<span class="number">0.2981195</span></span><br></pre></td></tr></table></figure>
<p>As a sanity check, we ensure that</p>
<ol>
<li>Price of call minus price of put (long a call, short a put) equals a forward. In other words $C - P = S + \frac{X}{e^{r}}$. In our case, $1.351541 - 0.3999157 = 10 - \frac{10}{e^{0.1}} = 0.9516258$ so that’s good!</li>
<li>$\Delta_C - \Delta_P = 1$, which again is true!</li>
</ol>
<p>Woohoo!</p>
<p>What if we want to find out how option price evolves as we increase the number of periods? Well we can do that!</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">periods = seq(<span class="number">100</span>, <span class="number">120</span>)</span><br><span class="line">option_price_vary_period = <span class="keyword">function</span>(period) &#123;</span><br><span class="line">  print(period)</span><br><span class="line">  option = binomial_option(type=<span class="string">'call'</span>, sigma=<span class="number">0.2</span>, <span class="literal">T</span>=<span class="number">1</span>, r=<span class="number">0</span>, X=<span class="number">100</span>, S=<span class="number">100</span>, N=period)</span><br><span class="line">  <span class="keyword">return</span>(option$price)</span><br><span class="line">&#125;</span><br><span class="line">values = sapply(periods, option_price_vary_period)</span><br><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">data = as.data.frame(list(periods=periods, values=values))</span><br><span class="line">plot = ggplot(data=data) + geom_line(aes(x=periods, y=values)) + labs(title=<span class="string">"Call Value"</span>, x=<span class="string">"Periods"</span>, y=<span class="string">"Value"</span>)</span><br><span class="line">plot</span><br></pre></td></tr></table></figure>
<p>However, this gets really slow as we increase the number of periods. This is rather unfortunate, since we are going at $O(N^2)$. However, we can use a slightly faster parallel implementation using the library <code>parallel</code>.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(parallel)</span><br><span class="line">cl = makeCluster(<span class="number">8</span>)</span><br><span class="line">clusterEvalQ(cl, <span class="keyword">source</span>(<span class="string">'binomial.R'</span>))</span><br><span class="line">periods = seq(<span class="number">100</span>, <span class="number">1000</span>)</span><br><span class="line">periods = sample(periods)</span><br><span class="line">valuesPar = parSapply(cl=cl, periods, option_price_vary_period)</span><br><span class="line">data = as.data.frame(list(periods=periods, values=valuesPar))</span><br><span class="line">plot = ggplot(data=data) + geom_line(aes(x=periods, y=values, alpha=<span class="number">0.1</span>)) + geom_point((aes(x=periods, y=values))) + labs(title=<span class="string">"Call Value"</span>, x=<span class="string">"Periods"</span>, y=<span class="string">"Value"</span>)</span><br><span class="line">plot</span><br><span class="line">stopCluster(cl)</span><br></pre></td></tr></table></figure>
<p>This assumes that <code>binomial.R</code> is in the same folder. This should speed things up A LOT. Reason why I randomized periods in the 5th line is because the larger periods take WAY longer, so you’ll want to distribute that among the cores rather evenly (since <code>parSapply</code> segments the input into equal segments increasingly). This doesn’t affect the graphing at all, and if you want you can always sort the result.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/10/15/Finding-Quantile-Given-Weird-Density-Function/"><span>Finding Quantile Given Weird Density Function</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/15/Finding-Quantile-Given-Weird-Density-Function/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-15T20:27:46.000Z">
          2015-10-15
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>For one of my Statistical Finance homeworks, I had to solve this question.</p>
<p>Given a density function $f(x)$, where</p>
<p>$$f(x) = \int_{-\infty}^{\infty} \frac{1}{Z} \frac{|x+1|}{(x^2+1)^2} = 1$$</p>
<p>Find the quantile $y$ that satisfies the $F^{-1}(y) = 0.95$ where $F(x)$ is the cumulative ditribution function of $f(x)$ and $F^{-1}$ is the quantile function (the inverse of $F$).</p>
<p>Obviously that’d mean that $F(x) = \int f(x) \: dx$ and I should start by integrating $f(x)$ and then finding its inverse. However, upon visual inspection, one should see that $f(x)$ is a bitch to integrate.</p>
<p>Yes it is possible to integrate it by splitting the ranges for the absolute function, then splitting $(x+1) = x + 1$, then $\frac{x}{(x^2+1)^2}$ can be integrated by substitution of $u = x^2+1$ and the other portion can be done trigonometrically. Now because my integration-fu is too bad, let me solve for this numerically. So here’s the trick to (ab)use <code>R</code>.</p>
<p>First let’s solve for $Z$. Since $f(x)$ is a density function, then by definition of density functions, $\int_{-\infty}^\infty f(x) \: dx = 1$. Then,</p>
<p>$$Z = \int_{-\infty}^{\infty} \frac{|x+1|}{(x^2+1)^2} = 1.785398$$</p>
<p>Great! Now let’s move to <code>R</code>. Unfortunately, <code>R</code> does not have a function for numerical computation of quantiles for arbitrary distribution functions. However, we can build one.</p>
<p>Finding $y$ above is equivalent to the following optimization problem:</p>
<p>$$y^* = \arg\min_{y} (F(y) - 0.95)^2$$</p>
<p>Then all we need is an optimization routine to find $y$ that minimizes the squared error $F(y) - 0.95)^2$. In <code>R</code> there exists the library <code>nlminb</code> for numerical optimization. The functions are below:</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">CDF = <span class="keyword">function</span> (x, dist) &#123;</span><br><span class="line">  integrate(f = dist, lower = -<span class="literal">Inf</span>, upper = x)$value</span><br><span class="line">&#125;</span><br><span class="line">objective = <span class="keyword">function</span> (x, quantile, dist) &#123;</span><br><span class="line">  (CDF(x, dist) - quantile)^<span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line">find_quantile = <span class="keyword">function</span> (dist, quantile) &#123;</span><br><span class="line">  result = nlminb(start = <span class="number">0</span>, objective = objective, quantile = quantile, dist = dist)$par</span><br><span class="line">  <span class="keyword">return</span> (result)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">crazy_eqn = <span class="keyword">function</span> (x) &#123;</span><br><span class="line">  abs(x+<span class="number">1</span>)/((x^<span class="number">2</span>+<span class="number">1</span>)^<span class="number">2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">z = integrate(crazy_eqn, lower=-<span class="literal">Inf</span>, upper=<span class="literal">Inf</span>)</span><br><span class="line"></span><br><span class="line">crazy_eqn_to_integrate = <span class="keyword">function</span>(x) &#123;</span><br><span class="line">  z$value * (abs(x+<span class="number">1</span>)/((x^<span class="number">2</span>+<span class="number">1</span>)^<span class="number">2</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">y = find_quantile(dist = crazy_eqn_to_integrate, quantile = <span class="number">0.95</span>)</span><br></pre></td></tr></table></figure>
<p>Using this, we find that $y = 0.03161596$. Let’s check this!</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">integrate(crazy_eqn_to_integrate, lower=-<span class="literal">Inf</span>, upper=alpha)</span><br><span class="line"><span class="number">0.95</span> with absolute error &lt; <span class="number">1.8e-11</span></span><br></pre></td></tr></table></figure>
<p>Booyah. This is why I’m not a statistics major.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>



  <article class="post article">

  
  
    <h3 class="article-title"><a href="/2015/10/13/Python-on-EC2/"><span>Python on EC2</span></a></h3>
  


  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/10/13/Python-on-EC2/" rel="bookmark">
        <time class="entry-date published" datetime="2015-10-13T17:12:39.000Z">
          2015-10-13
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>Running Python on EC2 is a pain, and installing packages can be more of a pain (version clashes, permissions etc). Turns out the easiest way was just to use <code>virtualenv</code>. Here’s a helper script I created:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install gcc-c++ python27-devel atlas-sse3-devel lapack-devel</span><br><span class="line">curl -O from https://bootstrap.pypa.io/get-pip.py</span><br><span class="line">sudo python get-pip.py</span><br><span class="line">pip install virtualenv</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ~/</span><br><span class="line">mkdir ./.virtualenv</span><br><span class="line"><span class="built_in">cd</span> ./.virtualenv</span><br><span class="line">virtualenv default</span><br><span class="line"><span class="built_in">source</span> ~/.virtualenv/default/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"source ~/.virtualenv/default/bin/activate"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"></span><br><span class="line">pip install --upgrade pip</span><br><span class="line">pip install numpy</span><br><span class="line">pip install scipy</span><br><span class="line"><span class="comment"># pip install gensim</span></span><br></pre></td></tr></table></figure>
<p>This would get your <code>virtualenv</code> setup, and the default environment would be used every time you log in. It also upgrades <code>pip</code>, installs <code>numpy</code> and <code>scipy</code> as a demonstration.</p>

      
    </div>
    <footer class="article-footer">
        <div class="article-meta pull-left">
          
          
        </div>
        
    </footer>
  </div>
</article>




<nav class="pagination">
  
  
  <a href="/page/2/" class="pagination-next">Next</a>
  
</nav>
      </main>
    </article>

    <footer id="colophon" class="site-footer" role="contentinfo"><p class="site-info">
  Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
  Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
  </br>
  
  &copy; 2016 Linan Qiu
  
</p>
</footer>
    
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-66827435-1', 'auto');
    ga('send', 'pageview');

</script>

  </div>
</div>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</body>
</html>
